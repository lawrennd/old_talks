{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer Review and The NIPS Experiment\n",
    "\n",
    "### [Neil D. Lawrence](http://inverseprobability.com), University of\n",
    "\n",
    "Sheffield\n",
    "\n",
    "### 2015-09-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**: The peer review process can be difficult to navigate for\n",
    "newcomers. In this informal talk we will review the results of the NIPS\n",
    "experiment, an experiment on the repeatability of peer review conducted\n",
    "for the 2014 conference. We will try to keep the presentation\n",
    "information to ensure questions can be asked. With luck it will give\n",
    "more insight into the processes that a program committee goes through\n",
    "when selecting papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->\n",
    "\n",
    "The NIPS experiment was an experiment to determine the consistency of\n",
    "the review process. After receiving papers we selected 10% that would be\n",
    "independently rereviewed. The idea was to determine how consistent the\n",
    "decisions between the two sets of independent papers would be. In 2014\n",
    "NIPS received 1678 submissions and we selected 170 for the experiment.\n",
    "These papers are referred to below as ‘duplicated papers.’\n",
    "\n",
    "To run the experiment we created two separate committees within the NIPS\n",
    "program committee. The idea was that the two separate committees would\n",
    "review each duplicated paper independently and results compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeurIPS in Numbers\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-in-numbers.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-in-numbers.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NeurIPS Experiment\n",
    "\n",
    "-   How consistent was the process of peer review?\n",
    "-   What would happen if you independently reran it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NeurIPS Experiment\n",
    "\n",
    "-   We selected \\~10% of NeurIPS papers to be reviewed twice,\n",
    "    independently.\n",
    "-   170 papers were reviewed by two separate committees.\n",
    "    -   Each committee was 1/2 the size of the full committee.\n",
    "    -   Reviewers allocated at random\n",
    "    -   Area Chairs allocated to ensure distribution of expertise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the Timeline for NeurIPS\n",
    "\n",
    "**AC recruitment (3 waves):** 17/02/2014 08/03/2014 09/04/2014\n",
    "\n",
    "**We requested names of reviewers from ACs in two waves:** 25/03/2014\n",
    "11/04/2014\n",
    "\n",
    "**Reviewer recruitment (4 waves):** 14/04/2014 28/04/2014 09/05/2014\n",
    "10/06/2014 (note this is after deadline … lots of area chairs asked for\n",
    "reviewers after the deadline!). We invited them en-masse.\n",
    "\n",
    "06/06/2014 Submission Deadline 12/06/2014 Bidding Open For Area Chairs\n",
    "(this was *delayed* by CMT issues) 17/06/2014 Bidding Open For Reviewers\n",
    "01/07/2014 Start Reviewing 21/07/2014 Reviewing deadline 04/08/2014\n",
    "Reviews to Authors 11/08/2014 Author Rebuttal Due 25/08/2014\n",
    "Teleconferences Begin 30/08/2014 Teleconferences End 1/09/2014\n",
    "Preliminary Decisions Made 9/09/2014 Decisions Sent to Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Making Timeline\n",
    "\n",
    "Deadline 6th June 1. three weeks for paper *bidding* and allocation 2.\n",
    "three weeks for *review* 3. two weeks for discussion and\n",
    "*adding/augmenting* reviews/reviewers 4. one week for *author rebuttal*\n",
    "5. two weeks for *discussion* 6. one week for *teleconferences* and\n",
    "*final decisons* 7. one week cooling off\n",
    "\n",
    "Decisions sent 9th September"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speculation\n",
    "\n",
    "-   To check public opinion before experiment: [scicast\n",
    "    question](https://scicast.org/#!/questions/1083/comments/power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeurIPS Experiment Results\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-experiment-results.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-experiment-results.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The final results of the experiment were as follows. From 170 papers 4\n",
    "had to be withdrawn or were rejected without completing the review\n",
    "process, for the remainder, the ‘confusion matrix’ for the two\n",
    "committee’s decisions is below.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "</td>\n",
    "<td colspan=\"2\">\n",
    "\n",
    "Committee 1\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "Accept\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "Reject\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"2\">\n",
    "\n",
    "Committee 2\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "Accept\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "22\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "22\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "Reject\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "21\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "101\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "4 papers rejected or withdrawn without review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the Table\n",
    "\n",
    "There are a few ways of summarizing the numbers in this table as percent\n",
    "or probabilities. First of all, the inconsistency, the proportion of\n",
    "decisions that were not the same across the two committees. The\n",
    "decisions were inconsistent for 43 out of 166 papers or 0.259 as a\n",
    "proportion. This number is perhaps a natural way of summarizing the\n",
    "figures if you are submitting your paper and wish to know an estimate of\n",
    "what the probability is that your paper would have different decisons\n",
    "according to the different committes. Secondly, the accept precision: if\n",
    "you are attending the conference and looking at any given paper, then\n",
    "you might want to know the probability that the paper would have been\n",
    "rejected in an independent rerunning of the conference. We can estimate\n",
    "this for Committee 1’s conference as 22/(22 + 22) = 0.5 (50%) and for\n",
    "Committee 2’s conference as 21/(22+21) = 0.49 (49%). Averaging the two\n",
    "estimates gives us 49.5%. Finally, the reject precision: if your paper\n",
    "was rejected from the conference, you might like an estimate of the\n",
    "probability that the same paper would be rejected again if the review\n",
    "process had been independently rerun. That estimate is 101/(22+101) =\n",
    "0.82 (82%) for Committee 1 and 101/(21+101)=0.83 (83%) for Committee 2,\n",
    "or on average 82.5%. A final quality estimate might be the ratio of\n",
    "consistent accepts to consistent rejects, or the agreed accept rate,\n",
    "22/123 = 0.18 (18%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction After Experiment\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-experiment-reaction.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-experiment-reaction.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "There seems to have been a lot of discussion of the result, both at the\n",
    "conference and on bulletin boards since. Such discussion is to be\n",
    "encouraged, and for ease of memory, it is worth pointing out that the\n",
    "approximate proportions of papers in each category can be nicely divided\n",
    "in to eigths as follows. Accept-Accept 1 in 8 papers, Accept-Reject 3 in\n",
    "8 papers, Reject-Reject, 5 in 8 papers. This makes the statistics we’ve\n",
    "computed above: inconsistency 1 in 4 (25%) accept precision 1 in 2 (50%)\n",
    "reject precision 5 in 6 (83%) and agreed accept rate of 1 in 6 (20%).\n",
    "This compares with the accept rate of 1 in 4.\n",
    "\n",
    "-   Public reaction after experiment [documented\n",
    "    here](http://inverseprobability.com/2015/01/16/blogs-on-the-nips-experiment/)\n",
    "\n",
    "-   [Open Data\n",
    "    Science](http://inverseprobability.com/2014/07/01/open-data-science/)\n",
    "    (see Heidelberg Meeting)\n",
    "\n",
    "-   NIPS was run in a very open way.\n",
    "    [Code](https://github.com/sods/conference) and [blog\n",
    "    posts](http://inverseprobability.com/2014/12/16/the-nips-experiment/)\n",
    "    all available!\n",
    "\n",
    "-   Reaction triggered by [this blog\n",
    "    post](http://blog.mrtz.org/2014/12/15/the-nips-experiment.html).\n",
    "\n",
    "Much of the discussion speculates on the number of consistent accepts in\n",
    "the process (using the main conference accept rate as a proxy). It\n",
    "therefore produces numbers that don’t match ours above. This is because\n",
    "the computed accept rate of the individual committees is different from\n",
    "that of the main conference. This could be due to a bias for the\n",
    "duplicated papers, or statistical sampling error. We look at these\n",
    "questions below. First, to get the reader primed for thinking about\n",
    "these numbers we discuss some context for placing these numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Random Committee @ 25%\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-experiment-random-committee.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_neurips/includes/neurips-experiment-random-committee.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The first context we can place around the numbers is what would have\n",
    "happened at the ‘Random Conference’ where we simply accept a quarter of\n",
    "papers at random. In this NIPS the expected numbers of accepts would\n",
    "then have been:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "</td>\n",
    "<td colspan=\"2\">\n",
    "\n",
    "Committee 1\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "Accept\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "Reject\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"2\">\n",
    "\n",
    "Committee 2\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "Accept\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "10.4 (1 in 16)\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "31.1 (3 in 16)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "Reject\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "31.1 (3 in 16)\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "93.4 (9 in 16)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "And for this set up we would expect *inconsistency* of 3 in 8 (37.5%)\n",
    "*accept precision* of 1 in 4 (25%) and a *reject precision* of 3 in 4\n",
    "(75%) and a *agreed accept rate* of 1 in 10 (10%). The actual committee\n",
    "made improvements on these numbers, in particular the accept precision\n",
    "was markedly better with 50%: twice as many consistent accept decisions\n",
    "were made than would be expected if the process had been performed at\n",
    "random and only around two thirds as many inconsistent decisions were\n",
    "made as would have been expected if decisions were made at random.\n",
    "However, we should treat all these figures with some skepticism until\n",
    "we’ve performed some estimate of the uncertainty associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats for Random Committee\n",
    "\n",
    "For random committee we expect: \\* *inconsistency* of 3 in 8 (37.5%) \\*\n",
    "*accept precision* of 1 in 4 (25%) \\* *reject precision* of 3 in 4 (75%)\n",
    "and a \\* *agreed accept rate* of 1 in 10 (10%).\n",
    "\n",
    "Actual committee’s accept precision markedly better with 50% accept\n",
    "precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty: Accept Rate\n",
    "\n",
    "To get a handle on the uncertainty around these numbers we’ll start by\n",
    "making use of the (binomial\n",
    "distribution)\\[http://en.wikipedia.org/wiki/Binomial_distribution\\].\n",
    "First, let’s explore the fact that for the overall conference the accept\n",
    "rate was around 23%, but for the duplication committees the accept rate\n",
    "was around 25%. If we assume decisions are made according to a binomial\n",
    "distribution, then is the accept rate for the duplicated papers too\n",
    "high?\n",
    "\n",
    "Note that for all our accept probability statistics we used as a\n",
    "denominator the number of papers that were initially sent for review,\n",
    "rather than the number where a final decision was made by the program\n",
    "committee. These numbers are different because some papers are withdrawn\n",
    "before the program committee makes its decision. Most commonly this\n",
    "occurs after authors have seen their preliminary reviews: for NIPS 2014\n",
    "we provided preliminary reviews that included paper scores. So for the\n",
    "official accept probability we use the 170 as denominator. The accept\n",
    "probabilities were therefore 43 out of 170 papers (25.3%) for Committee\n",
    "1 and 44 out of 170 (25.8%) for Committee 2. This compares with the\n",
    "overall conference accept rate for papers outside the duplication\n",
    "process of 349 out of 1508 (23.1%).\n",
    "\n",
    "If the true underlying probability of an accept were actually 0.23\n",
    "independent of the paper, then the probability of generating accepts for\n",
    "any subset of the papers would be given by a binomial distribution.\n",
    "Combining across the two committees for the duplicated papers, we see\n",
    "that 87 papers in total were recommended for accept out of a total of\n",
    "340 trials. out of 166 trials would be given by a binomial distribution\n",
    "as depicted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cmtutils.plot as plot\n",
    "import mlai as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = binom(340, 0.23)\n",
    "x = np.arange(60, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize) ax.bar(x,\n",
    "rv.pmf(x)) display(HTML(’\n",
    "\n",
    "<h3>\n",
    "\n",
    "Number of Accepted Papers for p = 0.23\n",
    "\n",
    "</h3>\n",
    "\n",
    "‘)) ax.axvline(87,linewidth=4, color=’red’)\n",
    "ma.write_figure(filename=“uncertainty-accept-rate.svg,”\n",
    "directory=“./neurips”)}\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//neurips/uncertainty-accept-rate.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Number of accepted papers for $p=0.23$.</i>\n",
    "\n",
    "From the plot, we can see that whilst the accept rate was slightly\n",
    "higher for duplicated papers it doesn’t seem that we can say that it was\n",
    "statistically significant that it was higher, it falls well within the\n",
    "probability mass of the Binomial.\n",
    "\n",
    "Note that Area Chairs knew which papers were duplicates, whereas\n",
    "reviewers did not. Whilst we stipulated that duplicate papers should not\n",
    "be any given special treatment, we cannot discount the possibility that\n",
    "Area Chairs may have given slightly preferential treatment to duplicate\n",
    "papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty: Accept Precision\n",
    "\n",
    "For the accept precision, if we assume that accept decisions were drawn\n",
    "according to a binomial, then the distribution for consistent accepts is\n",
    "also binomial. Our best estimate of its parameter is 22/166 = 0.13\n",
    "(13%). If we had a binomial distribution with these parameters, then the\n",
    "distribution of consistent accepts would be as follows.\n",
    "\n",
    "-   How reliable is the consistent accept score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = binom(166, 0.13)\n",
    "x = np.arange(10, 30)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.bar(x, rv.pmf(x))\n",
    "display(HTML('<h3>Number of Consistent Accepts given p=0.13</h3>'))\n",
    "ax.axvline(22,linewidth=4, color='red') \n",
    "ma.write_figure(filename=\"uncertainty-accept-precision.svg\", directory=\"./neurips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//neurips/uncertainty-accept-rate.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Number of consistent accepts given $p=0.13$.</i>\n",
    "\n",
    "We see immediately that there is a lot of uncertainty around this\n",
    "number, for the scale of the experiment as we have it. This suggests a\n",
    "more complex analysis is required to extract our estimates with\n",
    "uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Analysis\n",
    "\n",
    "Before we start the analysis, it’s important to make some statements\n",
    "about the aims of our modelling here. We will make some simplifying\n",
    "modelling assumptions for the sake of a model that is understandable. In\n",
    "particular, we are looking to get a handle on the uncertainty associated\n",
    "with some of the probabilities associated with the NIPS experiment.\n",
    "[Some preliminary analyses have already been conducted on\n",
    "blogs](http://inverseprobability.com/2015/01/16/blogs-on-the-nips-experiment/).\n",
    "Those analyses don’t have access to information like paper scores etc.\n",
    "For that reason we also leave out such information in this preliminary\n",
    "analysis. We will focus only on the summary results from the experiment:\n",
    "how many papers were consistently accepted, consistently rejected or had\n",
    "inconsistent decisions. For the moment we disregard the information we\n",
    "have about paper scores.\n",
    "\n",
    "In our analysis there are three possible outcomes for each paper:\n",
    "consistent accept, inconsistent decision and consistent reject. So we\n",
    "need to perform the analysis with the [multinomial\n",
    "distribution](http://en.wikipedia.org/wiki/Multinomial_distribution).\n",
    "The multinomial is parameterized by the probabilities of the different\n",
    "outcomes. These are our parameters of interest, we would like to\n",
    "estimate these probabilities alongside their uncertainties. To make a\n",
    "Bayesian analysis we place a prior density over these probabilities,\n",
    "then we update the prior with the observed data, that gives us a\n",
    "posterior density, giving us an uncertainty associated with these\n",
    "probabilities.\n",
    "\n",
    "### Prior Density\n",
    "\n",
    "Choice of prior for the multinomial is typically straightforward, the\n",
    "[Dirichlet density](http://en.wikipedia.org/wiki/Dirichlet_distribution)\n",
    "is [conjugate](http://en.wikipedia.org/wiki/Conjugate_prior) and has the\n",
    "additional advantage that its parameters can be set to ensure it is\n",
    "*uninformative*, i.e. uniform across the domain of the prior.\n",
    "Combination of a multinomial likelihood and a Dirichelt prior is not\n",
    "new, and in this domain if we were to consider the mean the posterior\n",
    "density only, then the approach is known as [Laplace\n",
    "smoothing](http://en.wikipedia.org/wiki/Additive_smoothing).\n",
    "\n",
    "For our model we are assuming for our prior that the probabilities are\n",
    "drawn from a Dirichlet as follows, $$\n",
    "p \\sim \\text{Dir}(\\alpha_1, \\alpha_2, \\alpha_3),\n",
    "$$ with $\\alpha_1=\\alpha_2=\\alpha_3=1$. The Dirichlet density is\n",
    "conjugate to the [multinomial\n",
    "distribution](http://en.wikipedia.org/wiki/Multinomial_distribution),\n",
    "and we associate three different outcomes with the multinomial. For each\n",
    "of the 166 papers we expect to have a consistent accept (outcome 1), an\n",
    "inconsistent decision (outcome 2) or a consistent reject (outcome 3). If\n",
    "the counts four outcome 1, 2 and 3 are represented by $k_1$, $k_2$ and\n",
    "$k_3$ and the associated probabilities are given by $p_1$, $p_2$ and\n",
    "$p_3$ then our model is, Due to the conjugacy the posterior is tractable\n",
    "and easily computed as a Dirichlet (see e.g. [Gelman et\n",
    "al](http://www.stat.columbia.edu/~gelman/book/)), where the parameters\n",
    "of the Dirichlet are given by the original vector from the Dirichlet\n",
    "prior plus the counts associated with each outcome. $$\n",
    "\\mathbf{p}|\\mathbf{k}, \\boldsymbol{\\alpha} \\sim \\text{Dir}(\\boldsymbol{\\alpha} + \\mathbf{k})\n",
    "$$ The mean probability for each outcome is then given by, $$\n",
    "\\bar{p}_i = \\frac{\\alpha_i+k_i}{\\sum_{j=1}^3(\\alpha_j + k_j)}.\n",
    "$$ and the variance is $$\n",
    "\\mathrm{Var}[p_i] = \\frac{(\\alpha_i+k_i) (\\alpha_0-\\alpha_i + n + k_i)}{(\\alpha_0+n)^2 (\\alpha_0+n+1)},\n",
    "$$ where $n$ is the number of trials (166 in our case) and\n",
    "$\\alpha_0 = \\sum_{i=1}^3\\alpha_i$. This allows us to compute the\n",
    "expected value of the probabilities and their variances under the\n",
    "posterior as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_var(k, alpha):\n",
    "    \"\"\"Compute the mean and variance of the Dirichlet posterior.\"\"\"\n",
    "    alpha_0 = alpha.sum()\n",
    "    n = k.sum()\n",
    "    m = (k + alpha)\n",
    "    m /= m.sum()\n",
    "    v = (alpha+k)*(alpha_0 - alpha + n + k)/((alpha_0+n)**2*(alpha_0+n+1))\n",
    "    return m, v\n",
    "\n",
    "k = np.asarray([22, 43, 101])\n",
    "alpha = np.ones((3,))\n",
    "m, v = posterior_mean_var(k, alpha)\n",
    "outcome = ['consistent accept', 'inconsistent decision', 'consistent reject']\n",
    "for i in range(3):\n",
    "    display(HTML(\"<h4>Probability of \" + outcome[i] +' ' + str(m[i]) +  \"+/-\" + str(2*np.sqrt(v[i])) + \"</h4>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a probability of consistent accept as $0.136 \\pm 0.06$, the\n",
    "probability of inconsistent decision as $0.260 \\pm 0.09$ and probability\n",
    "of consistent reject as $0.60 \\pm 0.15$. Recall that if we’d selected\n",
    "papers at random (with accept rate of 1 in 4) then these values would\n",
    "have been 1 in 16 (0.0625), 3 in 8 (0.375) and 9 in 16 (0.5625).\n",
    "\n",
    "The other values we are interested in are the accept precision, reject\n",
    "precision and the agreed accept rate. Computing the probability density\n",
    "for these statistics is complex, because it involves [Ratio\n",
    "Distributions](http://en.wikipedia.org/wiki/Ratio_distribution).\n",
    "However, we can use Monte Carlo to estimate the expected accept\n",
    "precision, reject precision and agreed accept rate as well as their\n",
    "variances. We can use these results to give us error bars and histograms\n",
    "of these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_precisions(k, alpha, num_samps):\n",
    "    \"\"\"Helper function to sample from the posterior distibution of accept, \n",
    "    reject and inconsistent probabilities and compute other statistics of interest \n",
    "    from the samples.\"\"\"\n",
    "\n",
    "    k = np.random.dirichlet(k+alpha, size=num_samps)\n",
    "    # Factors of 2 appear because inconsistent decisions \n",
    "    # are being accounted for across both committees.\n",
    "    ap = 2*k[:, 0]/(2*k[:, 0]+k[:, 1])\n",
    "    rp = 2*k[:, 2]/(k[:, 1]+2*k[:, 2])\n",
    "    aa = k[:, 0]/(k[:, 0]+k[:, 2])\n",
    "    return ap, rp, aa\n",
    "\n",
    "ap, rp, aa = sample_precisions(k, alpha, 10000)\n",
    "print ap.mean(), '+/-', 2*np.sqrt(ap.var())\n",
    "print rp.mean(), '+/-', 2*np.sqrt(rp.var())\n",
    "print aa.mean(), '+/-', 2*np.sqrt(aa.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving an accept precision of $0.51 \\pm 0.13$, a reject precision of\n",
    "$0.82 \\pm 0.05$ and an agreed accept rate of $0.18 \\pm 0.07$. Note that\n",
    "the ‘random conference’ values of 1 in 4 for accept precision and 3 in 4\n",
    "for reject decisions are outside the two standard deviation error bars.\n",
    "If it is preferred medians and percentiles could also be computed from\n",
    "the samples above, but as we will see when we histogram the results the\n",
    "densities look broadly symmetric, so this is unlikely to have much\n",
    "effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Monte Carlo Results\n",
    "\n",
    "Just to ensure that the error bars are reflective of the underlying\n",
    "densities we histogram the Monte Carlo results for accept precision,\n",
    "reject precision and agreed accept below. Shown on each histogram is a\n",
    "line representing the result we would get for the ‘random committee.’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "_ = ax[0].hist(ap, 20)\n",
    "_ = ax[0].set_title('Accept Precision')\n",
    "ax[0].axvline(0.25, linewidth=4)\n",
    "_ = ax[1].hist(rp, 20)\n",
    "_ = ax[1].set_title('Reject Precision')\n",
    "ax[1].axvline(0.75, linewidth=4)\n",
    "_ = ax[2].hist(aa, 20)\n",
    "_ = ax[2].set_title('Agreed Accept Rate')\n",
    "_ = ax[2].axvline(0.10, linewidth=4)\n",
    "ma.write_figure(filename=\"random-committee-outcomes-vs-true.svg\", directory=\"./neurips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//neurips/random-committee-outcomes-vs-true.svg\" class=\"\" width=\"90%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Different statistics for the random committee oucomes versus\n",
    "the observed committee outcomes.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Choice and Prior Values\n",
    "\n",
    "In the analysis above we’ve minimized the modeling choices: we made use\n",
    "of a Bayesian analysis to capture the uncertainty in counts that can be\n",
    "arising from statistical sampling error. To this end we chose an\n",
    "uninformative prior over these probabilities. However, one might argue\n",
    "that the prior should reflect something more about the underlying\n",
    "experimental structure: for example we *know* that if the committees\n",
    "made their decisions independently it is unlikely that we’d obtain an\n",
    "inconsistency figure much greater than 37.5% because that would require\n",
    "committees to explicitly collude to make inconsistent decisions: the\n",
    "random conference is the worst case. Due to the accept rate, we also\n",
    "expect a larger number of reject decisions than reject. This also isn’t\n",
    "captured in our prior. Such questions actually move us into the realms\n",
    "of modeling the process, rather then performing a sensitivity analysis.\n",
    "However, if we wish to model the decision process as a whole we have a\n",
    "lot more information available, and we should make use of it. The\n",
    "analysis above is intended to exploit our randomized experiment to\n",
    "explore how inconsistent we expect two committees to be. It focusses on\n",
    "that single question, it doesn’t attempt to give answers on what the\n",
    "reasons for that inconsistency are and how it may be reduced. The\n",
    "additional maths was needed only to give a sense of the uncertainty in\n",
    "the figures. That uncertainty arises due to the limited number of papers\n",
    "in the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Under the simple model we have outlined, we can be confident that there\n",
    "is inconsistency between two independent committees, but the level of\n",
    "inconsistency is much less than we would find for a random committee. If\n",
    "we accept that the bias introduced by the Area Chairs knowing when they\n",
    "were dealing with duplicates was minimal, then if we were to revisit the\n",
    "NIPS 2014 conference with an independent committee then we would expect\n",
    "between **38% and 64% of the presented papers to be the same**. If the\n",
    "conference was run at random, then we would only expect 25% of the\n",
    "papers to be the same.\n",
    "\n",
    "It’s apparent from comments and speculation about what these results\n",
    "mean, that some people might be surprised by the size of this figure.\n",
    "However, it only requires a little thought to see that this figure is\n",
    "likely to be large for any highly selective conference if there is even\n",
    "a small amount of inconsistency in the decision making process. This is\n",
    "because once the conference has chosen to be ‘highly selective’ then\n",
    "because by definition only a small percentage of papers are to be\n",
    "accepted. Now if we think of a type I error as accepting a paper which\n",
    "should be rejected, such errors are easier to make because by definition\n",
    "many more papers should be rejected. Type II errors (rejecting a paper\n",
    "that should be accepted) are less likely becaue (by setting the accept\n",
    "rate low) there are fewer papers that should be accepted in the first\n",
    "place. When there is a difference of opinion between reviewers, it does\n",
    "seem that many of the arugments can be distilled down to (a subjective\n",
    "opinion) about whether controlling for type I or type II errors is more\n",
    "important. Further, normally when discussing type I and type II errors\n",
    "we believe that the underlying system of study is genuinely binary:\n",
    "e.g. diseased or not diseased. However, for conferences the\n",
    "accept/reject boundary is not a clear separation point, there is a\n",
    "continuum (or spectrum) of paper quality (as there also is for some\n",
    "diseases). And the decision boundary often falls in a region of very\n",
    "high density. To better quantify these ideas we can explore our\n",
    "duplication experiment in more detail, by introducing the paper scores,\n",
    "that’s a task we will perform in a fresh notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "-   Error types:\n",
    "    -   type I error as accepting a paper which should be rejected.\n",
    "    -   type II error rejecting a paper should be accepted.\n",
    "-   Controlling for error:\n",
    "    -   many reviewer discussions can be summarised as *subjective*\n",
    "        opinions about whether controlling for type I or type II is more\n",
    "        important.\n",
    "    -   with low accept rates, type I errors are *much* more common.\n",
    "-   Normally in such discussions we believe there is a clear underlying\n",
    "    boundary.\n",
    "-   For conferences there is no clear separation points, there is a\n",
    "    spectrum of paper quality.\n",
    "-   Should be explored alongside *paper scores*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks!\n",
    "\n",
    "For more information on these subjects and more you might want to check\n",
    "the following resources.\n",
    "\n",
    "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
    "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
    "-   newspaper: [Guardian Profile\n",
    "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
    "-   blog:\n",
    "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
