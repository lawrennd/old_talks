\ifndef{privacyLossOfControl}
\define{privacyLossOfControl}
\editme

\subsection{Privacy, Loss of Control and Marginalization}
\slides{
* Society is becoming harder to monitor
* Individual is becoming easier to monitor
}
\notes{Society is becoming harder to monitor, but the individual is becoming easier to monitor. Social media monitoring for 'hate speech' can easily be turned to monitoring of political dissent. Marketing becomes more sinister when the target of the marketing is so well understood and the digital environment of the target is so well controlled.}

\include{_ai/includes/conversation-tedx.md}

\newslide{Hate Speech or Political Dissent?}
\slides{
* social media monitoring for 'hate speech' can be easily turned to political dissent monitoring
}

\newslide{Marketing}
\slides{
* can become more sinister when the target of the marketing is well understood and the (digital) environment of the target is also so well controlled

See \addguardian{The data-driven economy will help marketers exploit us}{2015/jul/23/data-driven-economy-marketing}.
}

\newslide{Free Will}
\slides{
*  What does it mean if a computer can predict our individual behavior better than we ourselves can?
}

\notes{What does it mean for our free will if a computer can predict our individual behavior better than we ourselves can?}

\newslide{Discrimination}
\slides{
* Potential for explicit and implicit discrimination on the basis of race, religion, sexuality, health status
* All prohibited under European law, but can pass unawares, or be implicit
* GDPR: General Data Protection Regulation
}

\notes{There is potential for both explicit and implicit discrimination on the basis of race, religion, sexuality or health status. All of these are prohibited under European law, but can pass unawares or be implicit.}

\notes{The GDPR is the General Data Protection Regulation, but a better name for it would simpl by Good Data Practice Rules. It covers how to deal with discrimination which has a consequential effect on the individual. For example, entrance to University, access to loans or insurance. But the new phenomenon is dealing with a series of inconsequential decisions that taken together have a consequential effect.}

\newslide{Discrimination}
\slides{
* Potential for explicit and implicit discrimination on the basis of race, religion, sexuality, health status
* All prohibited under European law, but can pass unawares, or be implicit
* GDPR: Good Data Practice Rules
}

\newslide{Marginalization}
\slides{
* Credit scoring, insurance, medical treatment
* What if certain sectors of society are under-represented in our analysis?
* What if Silicon Valley develops everything for us?
}
\newslide{Digital Revolution and Inequality?}

\figure{\includejpg{\diagramsDir/woman-tends-house-in-village-of-uganda-africa}{60%}}{A woman tends her house in a village in Uganda.}{woman-tends-house-in-village-of-uganda-africa}

\notes{Statistics as a community is also focussed on the single consequential effect of an analysis (efficacy of drugs, or distribution of Mosquito nets). Associated with happenstance data is *happenstance decision making*.}

\notes{These algorithms behind these decisions are developed in a particular context. The so-called Silicon Valley bubble. But they are deployed across the world. To address this, a key challenge is capacity building in contexts which are remote from the Western norm.}

\include{_data-science/includes/data-science-africa.md}
\include{_health/includes/malaria-gp.md}

\include{_governance/includes/data-trusts.md}


\newslide{Amelioration}
\slides{
* Work to ensure individual retains control of their own data
* We accept privacy in our real lives, need to accept it in our digital
* Control of persona and ability to project
* Need better technological solutions: trust and algorithms.
}

\notes{Addressing challenges in privacy, loss of control and marginalization includes ensuring that the individual retains control of their own data. We accept privacy in our real loves, we need to accept it in our digital persona. This is vital for our control of persona and our ability to project ourselves.}

\notes{Fairness goes hand in hand with privacy to protect the individual. Regulations like the GDPR date from a time where the main worry was *consequential* decision making but today we also face problems from accumulation of inconsequential decisions leading to a resulting consequential effect.}

\notes{Capacity building in different contexts, empowering domain experts to solve their own problems, is one aspect to the solution. A further proposal is the use of data trusts to reintroduce control of personal data for the individual.}

\endif
