---
title: "Emulation"
venue: "Virtual GPSS"
abstract: "In this session we introduce the notion of emulation and systems modeling with Gaussian processes."
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orcid: 0000-0001-9258-1030
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_gpss/emulation.md
date: 2021-09-15
published: 2021-09-15
week: 0
session: 13
reveal: 2021-09-15-emulation.slides.html
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_gpss/emulation.md
layout: talk
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<blockquote>
<p>We may regard the present state of the universe as the effect of its past and the cause of its future. An intellect which at a certain moment would know all forces that set nature in motion, and all positions of all items of which nature is composed, …</p>
</blockquote>
<blockquote>
<p>… if this intellect were also vast enough to submit these data to analysis, it would embrace in a single formula the movements of the greatest bodies of the universe and those of the tiniest atom; for such an intellect nothing would be uncertain and the future just like the past would be present before its eyes.</p>
<p>— Pierre Simon Laplace <span class="citation" data-cites="Laplace-essai14">(Laplace, 1814)</span></p>
</blockquote>
<h2 id="game-of-life">Game of Life</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/game-of-life.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/game-of-life.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p><a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Horton Conway</a> was a mathematician who developed a game known as the Game of Life. He died in April 2020, but since he invented the game, he was in effect ‘god’ for this game. But as we will see, just inventing the rules doesn’t give you omniscience in the game.</p>
<p>The Game of Life is played on a grid of squares, or pixels. Each pixel is either on or off. The game has no players, but a set of simple rules that are followed at each turn the rules are.</p>
<h2 id="life-rules">Life Rules</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/life-rules.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/life-rules.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>John Conway’s game of life is a cellular automata where the cells obey three very simple rules. The cells live on a rectangular grid, so that each cell has 8 possible neighbors.</p>
<div class="figure">
<div id="life-rules-loneliness-figure" class="figure-frame">
<table>
<tr>
<td width="70%">
<table>
<tr>
<td width="30%">
<center>
<object class data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/life-rules-1-0.svg" width="100%" style=" ">
</object>
</center>
</td>
<td width="39%">
<center>
<em>loneliness</em>
</center>
<center>
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//util/right-arrow.svg" width="60%" style=" ">
</object>
</center>
</td>
<td width="30%">
<center>
<object class data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/life-rules-1-1.svg" width="100%" style=" ">
</object>
</center>
</td>
</tr>
</table>
</td>
<td width="30%">
<center>
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//maths/John-Conway.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
</tr>
</table>
</div>
<div id="life-rules-loneliness-magnify" class="magnify" onclick="magnifyFigure(&#39;life-rules-loneliness&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="life-rules-loneliness-caption" class="caption-frame">
<p>Figure: ‘Death’ through loneliness in Conway’s game of life. If a cell is surrounded by less than three cells, it ‘dies’ through loneliness.</p>
</div>
</div>
<p>The game proceeds in turns, and at each location in the grid is either alive or dead. Each turn, a cell counts its neighbors. If there are two or fewer neighbors, the cell ‘dies’ of ‘loneliness.’</p>
<div class="figure">
<div id="life-rules-crowding-figure" class="figure-frame">
<table>
<tr>
<td width="70%">
<table>
<tr>
<td width="30%">
<center>
<object class data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/life-rules-2-0.svg" width="100%" style=" ">
</object>
</center>
</td>
<td width="39%">
<center>
<em>overcrowding</em>
</center>
<center>
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//util/right-arrow.svg" width="60%" style=" ">
</object>
</center>
</td>
<td width="30%">
<center>
<object class data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/life-rules-2-1.svg" width="100%" style=" ">
</object>
</center>
</td>
</tr>
</table>
</td>
<td width="30%">
<center>
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//maths/John-Conway.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
</tr>
</table>
</div>
<div id="life-rules-crowding-magnify" class="magnify" onclick="magnifyFigure(&#39;life-rules-crowding&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="life-rules-crowding-caption" class="caption-frame">
<p>Figure: ‘Death’ through overpopulation in Conway’s game of life. If a cell is surrounded by more than three cells, it ‘dies’ through loneliness.</p>
</div>
</div>
<p>If there are four or more neigbors, the cell ‘dies’ from ‘overcrowding.’ If there are three neigbors, the cell persists, or if it is currently dead, a new cell is born.</p>
<div class="figure">
<div id="life-rules-crowding-figure" class="figure-frame">
<table>
<tr>
<td width="70%">
<table>
<tr>
<td width="30%">
<center>
<object class data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/life-rules-3-0.svg" width="100%" style=" ">
</object>
</center>
</td>
<td width="39%">
<center>
<em>birth</em>
</center>
<center>
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//util/right-arrow.svg" width="60%" style=" ">
</object>
</center>
</td>
<td width="30%">
<center>
<object class data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/life-rules-3-1.svg" width="100%" style=" ">
</object>
</center>
</td>
</tr>
</table>
</td>
<td width="30%">
<center>
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//maths/John-Conway.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
</tr>
</table>
</div>
<div id="life-rules-crowding-magnify" class="magnify" onclick="magnifyFigure(&#39;life-rules-crowding&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="life-rules-crowding-caption" class="caption-frame">
<p>Figure: Birth in Conway’s life. Any position surounded by precisely three live cells will give birth to a new cell at the next turn.</p>
</div>
</div>
<p>And that’s it. Those are the simple ‘physical laws’ for Conway’s game.</p>
<p>The game leads to patterns emerging, some of these patterns are static, but some oscillate in place, with varying periods. Others oscillate, but when they complete their cycle they’ve translated to a new location, in other words they move. In Life the former are known as <a href="https://conwaylife.com/wiki/Oscillator">oscillators</a> and the latter as <a href="https://conwaylife.com/wiki/Spaceship">spaceships</a>.</p>
<h2 id="loafers-and-gliders">Loafers and Gliders</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/life-glider-loafer-conway.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/life-glider-loafer-conway.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>John Horton Conway, as the creator of the game of life, could be seen somehow as the god of this small universe. He created the rules. The rules are so simple that in many senses he, and we, are all-knowing in this space. But despite our knowledge, this world can still ‘surprise’ us. From the simple rules, emergent patterns of behaviour arise. These include static patterns that don’t change from one turn to the next. They also include, oscillators, that pulse between different forms across different periods of time. A particular form of oscillator is known as a ‘spaceship,’ this is one that moves across the board as the game evolves. One of the simplest and earliest spaceships to be discovered is known as the glider.</p>
<div class="figure">
<div id="glider-loafer-conway-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<center>
<em>Glider (1969)</em>
</center>
<center>
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/Glider.gif" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
<td width="45%">
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//maths/John-Conway.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="glider-loafer-conway-magnify" class="magnify" onclick="magnifyFigure(&#39;glider-loafer-conway&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="glider-loafer-conway-caption" class="caption-frame">
<p>Figure: <em>Left</em> A Glider pattern discovered 1969 by Richard K. Guy. <em>Right</em>. John Horton Conway, creator of <em>Life</em> (1937-2020). The glider is an oscillator that moves diagonally after creation. From the simple rules of Life it’s not obvious that such an object does exist, until you do the necessary computation.</p>
</div>
</div>
<p>The glider was ‘discovered’ in 1969 by Richard K. Guy. What do we mean by discovered in this context? Well, as soon as the game of life is defined, objects such as the glider do somehow exist, but the many configurations of the game mean that it takes some time for us to see one and know it exists. This means, that despite being the creator, Conway, and despite the rules of the game being simple, and despite the rules being deterministic, we are not ‘omniscient’ in any simplistic sense. It requires computation to ‘discover’ what can exist in this universe once it’s been defined.</p>
<div class="figure">
<div id="gosper-glider-gun-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/Gosperglidergun.gif" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="gosper-glider-gun-magnify" class="magnify" onclick="magnifyFigure(&#39;gosper-glider-gun&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gosper-glider-gun-caption" class="caption-frame">
<p>Figure: The Gosper glider gun is a configuration that creates gliders. A new glider is released after every 30 turns.</p>
</div>
</div>
<p>These patterns had to be discovered, in the same way that a scientist might discover a disease, or an explorer a new land. For example, the Gosper glider gun was <a href="https://conwaylife.com/wiki/Bill_Gosper">discovered by Bill Gosper in 1970</a>. It is a pattern that creates a new glider every 30 turns of the game.</p>
<p>Despite widespread interest in Life, some of its patterns were only very recently discovered like the Loafer, discovered in 2013 by Josh Ball. So despite the game having existed for over forty years, and the rules of the game being simple, there are emergent behaviours that are unknown.</p>
<div class="figure">
<div id="the-loafer-spaceship-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<center>
<em>Loafer (2013)</em>
</center>
<center>
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/Loafer.gif" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
<td width="45%">
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//maths/John-Conway.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="the-loafer-spaceship-magnify" class="magnify" onclick="magnifyFigure(&#39;the-loafer-spaceship&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-loafer-spaceship-caption" class="caption-frame">
<p>Figure: <em>Left</em> A Loafer pattern discovered by Josh Ball in 2013. <em>Right</em>. John Horton Conway, creator of <em>Life</em> (1937-2020).</p>
</div>
</div>
<p>Once these patterns are discovered, they are combined (or engineered) to create new Life patterns that do some remarkable things. For example, there’s a life pattern that runs a Turing machine, or more remarkably there’s a Life pattern that runs Life itself.</p>
<div class="figure">
<div id="life-in-life-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/life-in-life.gif" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="life-in-life-magnify" class="magnify" onclick="magnifyFigure(&#39;life-in-life&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="life-in-life-caption" class="caption-frame">
<p>Figure: The Game of Life running in Life. The video is drawing out recursively showing pixels that are being formed by filling cells with moving spaceships. Each individual pixel in this game of life is made up of <span class="math inline">\(2048 \times 2048\)</span> pixels called an <a href="https://www.conwaylife.com/wiki/OTCA_metapixel">OTCA metapixel</a>.</p>
</div>
</div>
<p>To find out more about the Game of Life you can watch this video by Alan Zucconi or read his <a href="https://www.alanzucconi.com/2020/10/13/conways-game-of-life/">associated blog post</a>.</p>
<div class="figure">
<div id="intro-to-life-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/Kk2MH9O4pXY?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="intro-to-life-magnify" class="magnify" onclick="magnifyFigure(&#39;intro-to-life&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="intro-to-life-caption" class="caption-frame">
<p>Figure: An introduction to the Game of Life by Alan Zucconi.</p>
</div>
</div>
<p>Contrast this with our situation where in ‘real life’ we don’t know the simple rules of the game, the state space is larger, and emergent behaviors (hurricanes, earthquakes, volcanos, climate change) have direct consequences for our daily lives, and we understand why the process of ‘understanding’ the physical world is so difficult. We also see immediately how much easier we might expect the physical sciences to be than the social sciences, where the emergent behaviors are contingent on highly complex human interactions.</p>
<p>We summarize this notion as <span class="math display">\[
\text{data} + \text{model} \stackrel{\text{compute}}{\rightarrow} \text{prediction}
\]</span> As we pointed out, there is an irony in Laplace’s demon forming the cornerstone of a movement known as ‘determinism,’ because Laplace wrote about this idea in an essay on probabilities. The more important quote in the essay was</p>
<h2 id="laplaces-gremlin">Laplace’s Gremlin</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_physics/includes/laplaces-gremlin.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_physics/includes/laplaces-gremlin.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<blockquote>
<p>The curve described by a simple molecule of air or vapor is regulated in a manner just as certain as the planetary orbits; the only difference between them is that which comes from our ignorance. Probability is relative, in part to this ignorance, in part to our knowledge. We know that of three or greater number of events a single one ought to occur; but nothing induces us to believe that one of them will occur rather than the others. In this state of indecision it is impossible for us to announce their occurrence with certainty. It is, however, probable that one of these events, chosen at will, will not occur because we see several cases equally possible which exclude its occurrence, while only a single one favors it.</p>
<p>— Pierre-Simon Laplace <span class="citation" data-cites="Laplace-essai14">(Laplace, 1814)</span>, pg 5</p>
</blockquote>
<p>The representation of ignorance through probability is the true message of Laplace, I refer to this message as “Laplace’s gremlin,” because it is the gremlin of uncertainty that interferes with the demon of determinism to mean that our predictions are not deterministic.</p>
<p>Our separation of the uncertainty into the data, the model and the computation give us three domains in which our doubts can creep into our ability to predict. Over the last three lectures we’ve introduced some of the basic tools we can use to unpick this uncertainty. You’ve been introduced to, (or have yow reviewed) <em>Bayes’ rule</em>. The rule, which is a simple consequence of the product rule of probability, is the foundation of how we update our beliefs in the presence of new information.</p>
<p>The real point of Laplace’s essay was that we don’t have access to all the data, we don’t have access to a complete physical understanding, and as the example of the Game of Life shows, even if we did have access to both (as we do for “Conway’s universe”) we still don’t have access to all the compute that we need to make deterministic predictions. There is uncertainty in the system which means we can’t make precise predictions.</p>
<p>I like to call this “Laplace’s Gremlin.” Gremlins are imaginary creatures used as an explanation of failure in aircraft, causing crashes. In that sense the Gremlin represents the uncertainty that a pilot felt about what might go wrong in a plane which might be “theoretically sound” but in practice is poorly maintained or exposed to conditions that take it beyond its design criteria. Laplace’s gremlin is all the things that your model, data and ability to compute don’t account for bringing about failures in your ability to predict. Laplace’s Gremlin is the uncertainty in the system.</p>
<div class="figure">
<div id="germlins-think-its-fun-to-hurt-you-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//ai/gremlins-think-its-fun-to-hurt-you.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="germlins-think-its-fun-to-hurt-you-magnify" class="magnify" onclick="magnifyFigure(&#39;germlins-think-its-fun-to-hurt-you&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="germlins-think-its-fun-to-hurt-you-caption" class="caption-frame">
<p>Figure: Gremlins are seen as the cause of a number of challenges in this World War II poster.</p>
</div>
</div>
<h2 id="simulation-system">Simulation System</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/simulation-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/simulation-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>An example of a complex decision-making system might be a climate model, in such a system there are separate models for the atmosphere, the ocean and the land.</p>
<p>The components of these systems include flowing of currents, chemical interactions in the upper atmosphere, evaporation of water etc..</p>
<div class="figure">
<div id="carbon-cycle-noaa-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/carbon_cycle.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="carbon-cycle-noaa-magnify" class="magnify" onclick="magnifyFigure(&#39;carbon-cycle-noaa&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="carbon-cycle-noaa-caption" class="caption-frame">
<p>Figure: Representation of the Carbon Cycle from the US National Oceanic and Atmospheric Administration. While everything is interconnected in the system, we can decompose into separate models for atmosphere, ocean, land.</p>
</div>
</div>
<p>The influence of human activity also needs to be incorporated and modelled so we can make judgments about how to mitigate the effects of global warming.</p>
<div class="figure">
<div id="simulation-system-components-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/simulation-schematic.svg" width="40%" style=" ">
</object>
</div>
<div id="simulation-system-components-magnify" class="magnify" onclick="magnifyFigure(&#39;simulation-system-components&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="simulation-system-components-caption" class="caption-frame">
<p>Figure: The components of a simulation system for climate modelling.</p>
</div>
</div>
<h2 id="monolithic-system">Monolithic System</h2>
<p>The classical approach to building these systems was a ‘monolithic system.’ Built in a similar way to the successful applications software such as Excel or Word, or large operating systems, a single code base was constructed. The complexity of such code bases run to many lines.</p>
<p>In practice, shared dynamically linked libraries may be used for aspects such as user interface, or networking, but the software often has many millions of lines of code. For example, the Microsoft Office suite is said to contain over 30 million lines of code.</p>
<div class="figure">
<div id="ml-system-monolith-simulation-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/ml-system-monolith-simulation.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-monolith-simulation-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-monolith-simulation&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ml-system-monolith-simulation-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="service-oriented-architecture">Service Oriented Architecture</h2>
<p>Such software is not only difficult to develop, but also to scale when computation demands increase. For example, Amazon’s original website software (called Obidos) was a <a href="https://en.wikipedia.org/wiki/Obidos_(software)">monolithic design</a> but by the early noughties it was becoming difficult to sustain and maintain. The software was phased out in 2006 to be replaced by a modularized software known as a ‘service-oriented architecture.’</p>
<p>In Service Oriented Architecture, or “Software as a Service” the idea is that code bases are modularized and communicate with one another using network requests. A standard approach is to use a <a href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST API</a>. So, rather than a single monolithic code base, the code is developed with individual services that handle the different requests.</p>
<p>The simulation software is turned inside out to expose the individual components to the operator.</p>
<div class="figure">
<div id="ml-system-downstream-simulation-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/ml-system-downstream-simulation000.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-downstream-simulation-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-simulation&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ml-system-downstream-simulation-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<p>This is the landscape we now find ourselves in for software development. In practice, each of these services is often ‘owned’ and maintained by an individual team. The team is judged by the quality of their service provision. They work to detailed specifications on what their service should output, what its availability should be and other objectives like speed of response. This allows for conditional independence between teams and for faster development.</p>
<p>One question is to what extent is the same approach possible/desirable for scientific models? The components we listed above are already separated and often run independently. But those components themselves are made up of other sub-components that could also be exposed in a similar manner to software-as-a-service, giving us the notion of “simulation as a service.”</p>
<p>One thing about working in an industrial environment, is the way that short-term thinking actions become important. For example, in Formula One, the teams are working on a two-week cycle to digest information from the previous week’s race and incorporate updates to the car or their strategy.</p>
<p>However, businesses must also think about more medium-term horizons. For example, in Formula 1 you need to worry about next year’s car. So while you’re working on updating this year’s car, you also need to think about what will happen for next year and prioritize these conflicting needs appropriately.</p>
<p>In the Amazon supply chain, there are the equivalent demands. If we accept that an artificial intelligence is just an automated decision-making system. And if we measure in terms of money automatically spent, or goods automatically moved, then Amazon’s buying system is perhaps the world’s largest AI.</p>
<p>Those decisions are being made on short time schedules; purchases are made by the system on weekly cycles. But just as in Formula 1, there is also a need to think about what needs to be done next month, next quarter and next year. Planning meetings are held not only on a weekly basis (known as weekly business reviews), but monthly, quarterly, and then yearly meetings for planning spends and investments.</p>
<p>Amazon is known for being longer term thinking than many companies, and a lot of this is coming from the CEO. One quote from Jeff Bezos that stuck with me was the following.</p>
<blockquote>
<p>“I very frequently get the question: ‘What’s going to change in the next 10 years?’ And that is a very interesting question; it’s a very common one. I almost never get the question: ‘What’s not going to change in the next 10 years?’ And I submit to you that that second question is actually the more important of the two – because you can build a business strategy around the things that are stable in time. … [I]n our retail business, we know that customers want low prices, and I know that’s going to be true 10 years from now. They want fast delivery; they want vast selection. It’s impossible to imagine a future 10 years from now where a customer comes up and says, ‘Jeff I love Amazon; I just wish the prices were a little higher,’ [or] ‘I love Amazon; I just wish you’d deliver a little more slowly.’ Impossible. And so the effort we put into those things, spinning those things up, we know the energy we put into it today will still be paying off dividends for our customers 10 years from now. When you have something that you know is true, even over the long term, you can afford to put a lot of energy into it.”</p>
</blockquote>
<p>This quote is incredibly important for long term thinking. Indeed, it’s a failure of many of our simulations that they focus on what is going to happen, not what will not happen. In Amazon, this meant that there was constant focus on these three areas, keeping costs low, making delivery fast and improving selection. For example, shortly before I left Amazon moved its entire US network from two-day delivery to one-day delivery. This involves changing the way the entire buying system operates. Or, more recently, the company has had to radically change the portfolio of products it buys in the face of Covid19.</p>
<!--These challenges are not just there for Amazon and Formula 1. In Sheffield, we worked closely with a Chesterfield based company called Fusion Group. They make joints that fuse PTFE pipes together. These pipes are used for transporting both water and gas. Their founder, Eric Bridgstock, was an engineer who introduced PTFE piping to the UK when working for DuPont. Eric set up Fusion group to manufacture the fusion fittings. Because PTFE pipes carry water or gas at high pressure, when these fittings fail significant damage can occur. When these fittings were originally installed in the early 1980s, the job was done by a specialist, but nowadays the pipe weld is compelted by the same team that digs the hole. While costs have come down, the number of PTFE weld failures went up. Eric's company focussed on new systems for auto-->
<div class="figure">
<div id="experiment-analyze-design-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//ml/experiment-analyze-design.svg" width="50%" style=" ">
</object>
</div>
<div id="experiment-analyze-design-magnify" class="magnify" onclick="magnifyFigure(&#39;experiment-analyze-design&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="experiment-analyze-design-caption" class="caption-frame">
<p>Figure: Experiment, analyze and design is a flywheel of knowledge that is the dual of the model, data and compute. By running through this spiral, we refine our hypothesis/model and develop new experiments which can be analyzed to further refine our hypothesis.</p>
</div>
</div>
<p>From the perspective of the team that we had in the supply chain, we looked at what we most needed to focus on. Amazon moves very quickly, but we could also take a leaf out of Jeff’s book, and instead of worrying about what was going to change, remember what wasn’t going to change.</p>
<blockquote>
<p>We don’t know what science we’ll want to do in five years’ time, but we won’t want slower experiments, we won’t want more expensive experiments and we won’t want a narrower selection of experiments.</p>
</blockquote>
<p>As a result, our focus was on how to speed up the process of experiments, increase the diversity of experiments that we can do, and keep the experiments price as low as possible.</p>
<p>The faster the innovation flywheel can be iterated, then the quicker we can ask about different parts of the supply chain, and the better we can tailor systems to answering those questions.</p>
<p>We need faster, cheaper and more diverse experiments which implies we need better ecosystems for experimentation. This has led us to focus on the software frameworks we’re using to develop machine learning systems including data oriented architectures (<span class="citation" data-cites="Borchert-dataoriented20">Borchert (2020)</span>;<span class="citation" data-cites="Lawrence-doa19">(<strong>Lawrence-doa19?</strong>)</span>;<span class="citation" data-cites="Vorhemus-doa17">Vorhemus and Schikuta (2017)</span>;<span class="citation" data-cites="Joshi-doa07">Joshi (2007)</span>), data maturity assessments (<span class="citation" data-cites="Lawrence-maturity20">Lawrence et al. (2020)</span>) and data readiness levels (See this blog post on <a href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data Readiness Levels</a>. and <span class="citation" data-cites="Lawrence-drl17">Lawrence (2017)</span>;<span class="citation" data-cites="Delve-data20">The DELVE Initiative (2020)</span>)</p>
<h2 id="statistical-emulation">Statistical Emulation</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="met-office-unified-model-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="https://mlatcl.github.io/gpss/./slides/diagrams//simulation/unified_model_systems_13022018_1920.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="met-office-unified-model-magnify" class="magnify" onclick="magnifyFigure(&#39;met-office-unified-model&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="met-office-unified-model-caption" class="caption-frame">
<p>Figure: The UK Met office runs a shared code base for its simulations of climate and the weather. This plot shows the different spatial and temporal scales used.</p>
</div>
</div>
<p>In many real-world systems, decisions are made through simulating the environment. Simulations may operate at different granularities. For example, simulations are used in weather forecasts and climate forecasts. Interestingly, the UK Met office uses the same code for both, it has a <a href="https://www.metoffice.gov.uk/research/approach/modelling-systems/unified-model/index">“Unified Model” approach</a>, but they operate climate simulations at greater spatial and temporal resolutions.</p>
<div class="figure">
<div id="statistical-emulation-1-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/statistical-emulation000.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-1-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-1&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="statistical-emulation-1-caption" class="caption-frame">
<p>Figure: Real world systems consist of simulators that capture our domain knowledge about how our systems operate. Different simulators run at different speeds and granularities.</p>
</div>
</div>
<div class="figure">
<div id="statistical-emulation-2-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/statistical-emulation001.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-2-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-2&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="statistical-emulation-2-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model.</p>
</div>
</div>
<p>A statistical emulator is a data-driven model that learns about the underlying simulation. Importantly, learns with uncertainty, so it ‘knows what it doesn’t know.’ In practice, we can call the emulator in place of the simulator. If the emulator ‘doesn’t know,’ it can call the simulator for the answer.</p>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-5-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-5&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="statistical-emulation-5-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.</p>
</div>
</div>
<p>As well as reconstructing an individual simulator, the emulator can calibrate the simulation to the real world, by monitoring differences between the simulator and real data. This allows the emulator to characterize where the simulation can be relied on, i.e., we can validate the simulator.</p>
<p>Similarly, the emulator can adjudicate between simulations. This is known as <em>multi-fidelity emulation</em>. The emulator characterizes which emulations perform well where.</p>
<p>If all this modelling is done with judicious handling of the uncertainty, the <em>computational doubt</em>, then the emulator can assist in desciding what experiment should be run next to aid a decision: should we run a simulator, in which case which one, or should we attempt to acquire data from a real-world intervention.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install gpy</span></code></pre></div>
<h2 id="gpy-and-emulation">GPy and Emulation</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gpy-emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gpy-emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Let <span class="math inline">\(\mathbf{ x}\)</span> be a random variable defined over the real numbers, <span class="math inline">\(\Re\)</span>, and <span class="math inline">\(f(\cdot)\)</span> be a function mapping between the real numbers <span class="math inline">\(\Re \rightarrow \Re\)</span>.</p>
<p>The problem of <em>uncertainty propagation</em> is the study of the distribution of the random variable <span class="math inline">\(f(\mathbf{ x})\)</span>.</p>
<p>We’re going to address this problem using emulation and GPy. We will see in this section the advantage of using a model when only a few observations of <span class="math inline">\(f\)</span> are available.</p>
<p>Firstly, we’ll make use of a test function known as the Branin test function. <span class="math display">\[
f(\mathbf{ x}) = a(x_2 - bx_1^2 + cx_1 - r)^2 + s(1-t \cos(x_1)) + s
\]</span> where we are setting <span class="math inline">\(a=1\)</span>, <span class="math inline">\(b=5.1/(4\pi^2)\)</span>, <span class="math inline">\(c=5/\pi\)</span>, <span class="math inline">\(r=6\)</span>, <span class="math inline">\(s=10\)</span> and <span class="math inline">\(t=1/(8\pi)\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> branin(X):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> ((X[:,<span class="dv">1</span>]<span class="op">-</span><span class="fl">5.1</span><span class="op">/</span>(<span class="dv">4</span><span class="op">*</span>np.pi<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>X[:,<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span><span class="op">+</span><span class="dv">5</span><span class="op">*</span>X[:,<span class="dv">0</span>]<span class="op">/</span>np.pi<span class="op">-</span><span class="dv">6</span>)<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> <span class="dv">10</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">8</span><span class="op">*</span>np.pi))<span class="op">*</span>np.cos(X[:,<span class="dv">0</span>])<span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(y)</span></code></pre></div>
<p>We’ll define a grid of twenty-five observations over [−5, 10] × [0, 15] and a set of 25 observations.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training set defined as a 5*5 grid:</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>xg1 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>xg2 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">15</span>,<span class="dv">5</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.zeros((xg1.size <span class="op">*</span> xg2.size,<span class="dv">2</span>))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,x1 <span class="kw">in</span> <span class="bu">enumerate</span>(xg1):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j,x2 <span class="kw">in</span> <span class="bu">enumerate</span>(xg2):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        X[i<span class="op">+</span>xg1.size<span class="op">*</span>j,:] <span class="op">=</span> [x1,x2]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> branin(X)[:,np.newaxis]</span></code></pre></div>
<p>The task here will be to consider the distribution of <span class="math inline">\(f(U)\)</span>, where <span class="math inline">\(U\)</span> is a random variable with uniform distribution over the input space of <span class="math inline">\(f\)</span>. We focus on the computaiton of two quantities, the expectation of <span class="math inline">\(f(U)\)</span>, <span class="math inline">\(\left\langle f(U)\right\rangle\)</span>, and the probability that the value is greater than 200.</p>
<h2 id="computation-of-leftlangle-furightrangle">Computation of <span class="math inline">\(\left\langle f(U)\right\rangle\)</span></h2>
<p>The expectation of <span class="math inline">\(f(U )\)</span> is given by <span class="math inline">\(\int_\mathbf{ x}f( \mathbf{ x})\text{d}\mathbf{ x}\)</span>. A basic approach to approximate this integral is to compute the mean of the 25 observations: <code>np.mean(Y)</code>. Since the points are distributed on a grid, this can be seen as the approximation of the integral by a rough Riemann sum.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Estimate of the expectation is given by: </span><span class="sc">{mean}</span><span class="st">&#39;</span>.<span class="bu">format</span>(mean<span class="op">=</span>Y.mean()))</span></code></pre></div>
<p>The result can be compared with the actual mean of the Branin function which is 54.31.</p>
<p>Alternatively, we can fit a GP model and compute the integral of the best predictor by Monte Carlo sampling.</p>
<p>Firstly, we create the covariance function. Here we’re going to use an exponentiated quadratic, but we’ll augment it with the ‘bias’ covariance function. This covariance function represents a single fixed bias that is added to the overall covariance. It allows us to deal with non-zero-mean emulations.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an exponentiated quadratic plus bias covariance function</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>kern_eq <span class="op">=</span> GPy.kern.RBF(input_dim<span class="op">=</span><span class="dv">2</span>, ARD <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>kern_bias <span class="op">=</span> GPy.kern.Bias(input_dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>kern <span class="op">=</span> kern_eq <span class="op">+</span> kern_bias</span></code></pre></div>
<p>Now we construct the Gaussian process regression model in GPy.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a GP model</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPy.models.GPRegression(X,Y,kern)</span></code></pre></div>
<p>In the sinusoid example above, we learnt the variance of the process. But in this example, we are fitting an emulator to a function we know is noise-free. However, we don’t fix the noise value to precisely zero, as this can lead to some numerical errors. Instead, we fix the variance of the Gaussian noise to a very small value.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix the noise variance</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>model.likelihood.variance.fix(<span class="fl">1e-5</span>)</span></code></pre></div>
<p>Now we fit the model. Note, that the initial values for the length scale are not appropriate. So first set the length scale of the model needs to be reset.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>kern.rbf.lengthscale <span class="op">=</span> np.asarray([<span class="dv">3</span>, <span class="dv">3</span>])</span></code></pre></div>
<p>It’s a common error in Gaussian process fitting to initialize the length scale too small or too big. The challenge is that the error surface is normally multimodal, and the final solution can be very sensitive to this initialization. If the length scale is initialized too small, the solution can converge on an place where the signal isn’t extracted by the covariance function. If the length scale is initialized too large, then the variations of the function are often missing. Here the length scale is set for each dimension of inputs as 3. Now that’s done, we can optimize the model.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomize the model and optimize</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>model.optimize(messages<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="figure">
<div id="branin-gp-optimized-fit-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/branin-gp-optimized-fit.svg" width="80%" style=" ">
</object>
</div>
<div id="branin-gp-optimized-fit-magnify" class="magnify" onclick="magnifyFigure(&#39;branin-gp-optimized-fit&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="branin-gp-optimized-fit-caption" class="caption-frame">
<p>Figure: A Gaussian process fit to the Branin test function, used to assess the mean of the function by emulation.</p>
</div>
</div>
<p>Finally, we can compute the mean of the model predictions using very many Monte Carlo samples.</p>
<p>Note, that in this example, because we’re using a test function, we could simply have done the Monte Carlo estimation directly on the Branin function. However, imagine instead that we were trying to understand the results of a complex computational fluid dynamics simulation, where each run of the simulation (which is equivalent to our test function) took many hours. In that case the advantage of the emulator is clear.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the mean of model prediction on 1e5 Monte Carlo samples</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>Xp <span class="op">=</span> np.random.uniform(size<span class="op">=</span>(<span class="bu">int</span>(<span class="fl">1e5</span>),<span class="dv">2</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>Xp[:,<span class="dv">0</span>] <span class="op">=</span> Xp[:,<span class="dv">0</span>]<span class="op">*</span><span class="dv">15</span><span class="op">-</span><span class="dv">5</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>Xp[:,<span class="dv">1</span>] <span class="op">=</span> Xp[:,<span class="dv">1</span>]<span class="op">*</span><span class="dv">15</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>mu, var <span class="op">=</span> model.predict(Xp)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The estimate of the mean of the Branin function is </span><span class="sc">{mean}</span><span class="st">&#39;</span>.<span class="bu">format</span>(mean<span class="op">=</span>np.mean(mu)))</span></code></pre></div>
<h3 id="exercise-1">Exercise 1</h3>
<p>Now think about how to make use of the variance estimation from the Gaussian process to obtain error bars around your estimate.</p>
<h3 id="exercise-2">Exercise 2</h3>
<p>You’ve seen how the Monte Carlo estimates work with the Gaussian process. Now make your estimate of the probability that the Branin function is greater than 200 with the uniform random inputs.</p>
<h2 id="uncertainty-quantification-and-design-of-experiments">Uncertainty Quantification and Design of Experiments</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/uq-sampling-history-doe.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/uq-sampling-history-doe.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>We’re introducing you to the optimization and analysis of real-world models through emulation, this domain is part of a broader field known as surrogate modelling.</p>
<p>Although we’re approaching this from the machine learning perspective, with a computer-scientist’s approach, you won’t be surprised to find out that this field is not new and there are a range of research groups interested in this domain.</p>
<p>We’ve also been mainly focussing on <em>active</em> experimental design. In particular the case where we are sequentially selecting points to run our simulation based on previous results.</p>
<p>Here, we pause for a moment and cover approaches to <em>passive</em> experimental design. Almost all the emulation examples we’ve looked at so far need some initial points to ‘seed’ the emulator. Selecting these is also a task of experimental design, but one we perform without running our simulator.</p>
<p>This type of challenge, of where to run the simulation to get the answer you require is an old challenge. One classic paper, <span class="citation" data-cites="McKay-selecting79">McKay et al. (1979)</span>, reviews three different methods for designing these inputs. They are <em>random sampling</em>, <em>stratified sampling</em> and <em>Latin hypercube sampling</em>.</p>
<blockquote>
<p>Let the input values <span class="math inline">\(\mathbf{ x}_1, \dots, \mathbf{ x}_n\)</span> be a random sample from <span class="math inline">\(f(\mathbf{ x})\)</span>. This method of sampling is perhaps the most obvious, and an entire body of statistical literature may be used in making inferences regarding the distribution of <span class="math inline">\(Y(t)\)</span>.</p>
</blockquote>
<blockquote>
<p>Using stratified sampling, all areas of the sample space of <span class="math inline">\(\mathbf{ x}\)</span> are represented by input values. Let the sample space <span class="math inline">\(S\)</span> of <span class="math inline">\(\mathbf{ x}\)</span> be partitioned into <span class="math inline">\(I\)</span> disjoint strata <span class="math inline">\(S_t\)</span>. Let <span class="math inline">\(\pi = P(\mathbf{ x}\in S_i)\)</span> represent the size of <span class="math inline">\(S_i\)</span>. Obtain a random sample <span class="math inline">\(\mathbf{ x}_{ij}\)</span>, <span class="math inline">\(j = 1, \dots, n\)</span> from <span class="math inline">\(S_i\)</span>. Then of course the <span class="math inline">\(n_i\)</span> sum to <span class="math inline">\(n\)</span>. If <span class="math inline">\(I = 1\)</span>, we have random sampling over the entire sample space.</p>
</blockquote>
<blockquote>
<p>The same reasoning that led to stratified sampling, ensuring that all portions of <span class="math inline">\(S\)</span> were sampled, could lead further. If we wish to ensure also that each of the input variables <span class="math inline">\(\mathbf{ x}_k\)</span> has all portions of its distribution represented by input values, we can divide the range of each <span class="math inline">\(\mathbf{ x}_k\)</span> into <span class="math inline">\(n\)</span> strata of equal marginal probability <span class="math inline">\(1/n\)</span>, and sample once from each stratum. Let this sample be <span class="math inline">\(\mathbf{ x}_{kj}\)</span>, <span class="math inline">\(j = 1, \dots, n\)</span>. These form the <span class="math inline">\(\mathbf{ x}_k\)</span> component, <span class="math inline">\(k = 1, \dots , K\)</span>, in <span class="math inline">\(\mathbf{ x}_i\)</span>, <span class="math inline">\(i = 1, \dots, n\)</span>. The components of the various <span class="math inline">\(\mathbf{ x}_k\)</span>’s are matched at random. This method of selecting input values is an extension of quota sampling (Steinberg 1963), and can be viewed as a <span class="math inline">\(K\)</span>-dimensional extension of Latin square sampling (Raj 1968).</p>
</blockquote>
<p>The paper’s rather dated reference to “Output from a Computer Code” does carry forward through this literature, which has continued to be a focus of interest for statisticians. <a href="http://www.tonyohagan.co.uk/academic/">Tony O’Hagan</a>, who was a colleague in Sheffield but is also one of the pioneers of Gaussian process models was developing these methods when I first arrived there <span class="citation" data-cites="Kennedy-bayesian01">(Kennedy and O’Hagan, 2001)</span>, and continued with a large EPSRC funded project for managing uncertainty in computational models, <a href="http://www.mucm.ac.uk/" class="uri">http://www.mucm.ac.uk/</a>. You can see a list of <a href="http://www.mucm.ac.uk/Pages/Dissemination/TechnicalReports.html">their technical reports here</a>.</p>
<p>Another important group based in France is the “MASCOT-NUM Research Group,” <a href="https://www.gdr-mascotnum.fr/" class="uri">https://www.gdr-mascotnum.fr/</a>. These researchers bring together statisticians, applied mathematicians and engineers in solving these problems.</p>
<h1 id="emukit">Emukit</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/emukit-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/emukit-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip0">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Javier Gonzalez
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/javier-gonzalez.png" clip-path="url(#clip0)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip1">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Andrei Paleyes
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/andrei-paleyes.jpg" clip-path="url(#clip1)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip2">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Mark Pullin
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/mark-pullin.jpg" clip-path="url(#clip2)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip3">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Maren Mahsereci
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/maren-mahsereci.png" clip-path="url(#clip3)"/>
</svg>
</div>
<p>The Emukit software we will be using across the next part of this module is a python software library that facilitates emulation of systems. The software’s origins go back to work done by <a href="https://javiergonzalezh.github.io/">Javier Gonzalez</a> as part of his post-doctoral project at the University of Sheffield. Javier led the design and build of a Bayesian optimization software. The package <code>GPyOpt</code> worked with the SheffieldML software GPy for performing Bayesian optimization.</p>
<p><code>GPyOpt</code> has a modular design that allows the user to provide their own surrogate models, the package is build with <code>GPy</code> as a surrogate model in mind, but other surrogate models can also be wrapped and integrated.</p>
<p>However, <code>GPyOpt</code> doesn’t allow the full flexibility of surrogate modelling for domains like experimental design, sensitivity analysis etc.</p>
<p>Emukit <span class="citation" data-cites="Paleyes-emulation19">(Paleyes et al., 2019)</span> was designed and built for a more general approach. The software is MIT licensed and its design and implementation was led by Javier Gonzalez and <a href="https://www.linkedin.com/in/andreipaleyes">Andrei Paleyes</a> at Amazon. Building on the experience of <code>GPyOpt</code>, the aim with Emukit was to use the modularisation ideas embedded in <code>GPyOpt</code>, but to extend them beyond the modularisation of the surrogate models to modularisation of the acquisition function.</p>
<div class="figure">
<div id="emukit-software-page-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//uq/emukit-software-page.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-software-page-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-software-page&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-software-page-caption" class="caption-frame">
<p>Figure: The Emukit software is a set of software tools for emulation and surrogate modeling. <a href="https://emukit.github.io/emukit/" class="uri">https://emukit.github.io/emukit/</a></p>
</div>
</div>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pyDOE</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install emukit</span></code></pre></div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip4">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Javier Gonzalez
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/javier-gonzalez.png" clip-path="url(#clip4)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip5">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Andrei Paleyes
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/andrei-paleyes.jpg" clip-path="url(#clip5)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip6">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Mark Pullin
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/mark-pullin.jpg" clip-path="url(#clip6)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:10%">
<defs> <clipPath id="clip7">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Maren Mahsereci
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/maren-mahsereci.png" clip-path="url(#clip7)"/>
</svg>
</div>
<p>The software was initially built by the team in Amazon. As well as Javier Gonzalez (ML side) and Andrei Paleyes (Software Engineering) included Mark Pullin, Maren Mahsereci, Alex Gessner, Aaron Klein, Henry Moss, David-Elias Künstle as well as management input from Cliff McCollum and myself.</p>
<h1 id="emukit-vision">Emukit Vision</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-vision.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-vision.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<h2 id="emulation-in-emukit">Emulation in Emukit</h2>
<p>We see emulation comprising of three main parts:</p>
<p><strong>Models</strong>. This is a probabilistic data-driven representation of the process/simulator that the user is working with. There is normally a modelling framework that is used to create a model. Examples: neural network, Gaussian process, random forest.</p>
<p><strong>Methods</strong>. Relatively low-level techniques that are aimed that either understanding, quantifying or using uncertainty that the model provides. Examples: Bayesian optimization, experimental design.</p>
<p><strong>Tasks</strong>. High level goals that owners of the process/simulator might be actually interested in. Examples: measure quality of a simulator, explain complex system behavior.</p>
<p>Typical workflow that we envision for a user interested in emulation is:</p>
<ol type="1">
<li><p>Figure out which questions/tasks are important for them in regard to their process/simulation.</p></li>
<li><p>Understand which emulation techniques are needed to accomplish the chosen task.</p></li>
<li><p>Build an emulator of the process. That can be a very involved step, that may include a lot of fine tuning and validation.</p></li>
</ol>
<p>Feed the emulator to the chosen technique and use it to answer the question/complete the task.</p>
<h2 id="emukit-and-emulation">Emukit and Emulation</h2>
<div class="figure">
<div id="emukit-vision-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/emukit-vision.svg" width="60%" style=" ">
</object>
</div>
<div id="emukit-vision-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-vision&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-vision-caption" class="caption-frame">
<p>Figure: The emukit approach to the three parts of emulation.</p>
</div>
</div>
<h2 id="methods">Methods</h2>
<p>This is the main focus of Emukit. Emukit defines a general sctructure of a decision making method, called OuterLoop, and then offers implementations of few such methods: Bayesian optimization, experimental design. In addition to provide a framework for decision making Emukit provide other tools, like sensitivity analysis, that help to debug and interpret emulators. All methods in Emukit are model-agnostic.</p>
<h2 id="models">Models</h2>
<p>Generally speaking, Emukit does not provide modelling capabilities, instead expecting users to bring their own models. Because of the variety of modelling frameworks out there, Emukit does not mandate or make any assumptions about a particular modelling technique or a library. Instead it suggests to implement a subset of defined model interfaces required to use a particular method. Nevertheless, there are a few model-related functionalities in Emukit: - Example models, which give users something to play with to explore Emukit. - Model wrappers, which are designed to help adapting models in particular modelling frameworks to Emukit interfaces. - Multi-fidelity models, implemented based on GPy.</p>
<h2 id="tasks">Tasks</h2>
<p>Emukit does not contribute much to this part at the moment. However Emukit team are on lookout for typical use cases for Emukit, and if a reoccuring pattern emerges, it may become a part of the library.</p>
<pre><code>while stopping condition is not met:
    optimize acquisition function
    evaluate user function
    update model with new observation</code></pre>
<p>Emukit is build in a modular way so that each component in this loop can be swapped out. This means that scientists, applied mathematicians, machine learnings, statisticians can swap out the relavant part of their method and build on the undelrying structure. You just need to pick out the part that requires implementation.</p>
<h2 id="loop">Loop</h2>
<p>The <code>emukit.core.loop.OuterLoop</code> class is the abstract loop where the different components come together. There are more specific loops for Bayesian optimization and experimental design that construct some of the component parts for you.</p>
<h2 id="model">Model</h2>
<p>All <code>Emukit</code> loops need a probabilistic model of the underlying system. Emukit does not provide functionality to build models as there are already many good modelling frameworks available in python. Instead, we provide a way of interfacing third part modelling libraries with Emukit. We already provide a wrapper for using a model created with <code>GPy</code>. For instructions on how to include your own model please <a href="https://emukit.readthedocs.io/en/latest/notebooks/Emukit-tutorial-custom-model.html">see this notebook</a>.</p>
<p>Different models and modelling frameworks will provide different functionality. For instance a Gaussian process will usually have derivatives of the predictions available but random forests will not. These different functionalities are represented by a set of interfaces which a model implements. The basic interface that all models must implement is <code>IModel</code>, which implements functionality to make predictions and update the model but a model may implement any number of other interfaces such as <code>IDifferentiable</code> which indicates a model has prediction derivatives available.</p>
<h2 id="candidate-point-calculator">Candidate Point Calculator</h2>
<p>This class decides which point to evaluate next. The simplest implementation, <code>SequentialPointCalculator</code>, collects one point at a time by finding where the acquisition is a maximum by applying the acquisition optimizer to the acquisition function. More complex implementations will enable batches of points to be collected so that the user function can be evaluated in parallel.</p>
<h2 id="acquisition">Acquisition</h2>
<p>The acquisition is a heuristic quantification of how valuable collecting a future point might be. It is used by the candidate point calculator to decide which point(s) to collect next.</p>
<h2 id="acquisition-optimizer">Acquisition Optimizer</h2>
<p>The <code>AcquisitionOptimizer</code> optimizes the acquisition function to find the point at which the acquisition is a maximum. This will use the acquisition function gradients if they are available. If gradients of the acquisition function are not available it will either estimate them numerically or use a gradient free optimizer.</p>
<h2 id="user-function">User Function</h2>
<p>This is the function that we are trying to reason about. It can be either evaluated by the user or it can be passed into the loop and evaluated by Emukit.</p>
<h2 id="model-updater">Model Updater</h2>
<p>The <code>ModelUpdater</code> class updates the model with new training data after a new point is observed and optimizes any hyper-parameters of the model. It can decide whether hyper-parameters need updating based on some internal logic.</p>
<h2 id="stopping-condition">Stopping Condition</h2>
<p>The <code>StoppingCondition</code> class chooses when we should stop collecting points. The most commonly used example is to stop when a set number of iterations have been reached.</p>
<h2 id="emukit-playground">Emukit Playground</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-playground.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-playground.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip8">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Leah Hirst
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/person-placeholder.jpg" clip-path="url(#clip8)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip9">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Cliff McCollum
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/cliff-mccollum.jpg" clip-path="url(#clip9)"/>
</svg>
</div>
<p>Emukit playground is a software toolkit for exploring the use of statistical emulation as a tool. It was built by <a href="https://www.linkedin.com/in/leahhirst/">Leah Hirst</a>, during her software engineering internship at Amazon and supervised by <a href="https://www.linkedin.com/in/cliffmccollum/">Cliff McCollum</a>.</p>
<div class="figure">
<div id="emukit-playground-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//uq/emukit-playground.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-playground-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-playground&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-playground-caption" class="caption-frame">
<p>Figure: Emukit playground is a tutorial for understanding the simulation/emulation relationship. <a href="https://amzn.github.io/emukit-playground/" class="uri">https://amzn.github.io/emukit-playground/</a></p>
</div>
</div>
<div class="figure">
<div id="emukit-playground-bayes-opt-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="https://mlatcl.github.io/gpss/./slides/diagrams//uq/emukit-playground-bayes-opt.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-playground-bayes-opt-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-playground-bayes-opt&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-playground-bayes-opt-caption" class="caption-frame">
<p>Figure: Tutorial on Bayesian optimization of the number of taxis deployed from Emukit playground. <a href="https://amzn.github.io/emukit-playground/#!/learn/bayesian_optimization" class="uri">https://amzn.github.io/emukit-playground/#!/learn/bayesian_optimization</a></p>
</div>
</div>
<p>You can explore Bayesian optimization of a taxi simulation.</p>
<h2 id="emukit-tutorial">Emukit Tutorial</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-tutorial.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-tutorial.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install mlai</span></code></pre></div>
<p>Set up the python imports that Emukit will use.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<p>Now set up Emukit to run.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.experimental_design.experimental_design_loop <span class="im">import</span> ExperimentalDesignLoop</span></code></pre></div>
<p>Let’s check the help function for the experimental design loop. This is the outer loop that provides all the decision making parts of Emukit.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>ExperimentalDesignLoop?</span></code></pre></div>
<p>Now let’s load in the model wrapper for our probabilistic model. In this case, instead of using GPy, we’ll make use of a simple model wrapper Emukit provides for a basic form of Gaussian process.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.model_wrappers <span class="im">import</span> SimpleGaussianProcessModel</span></code></pre></div>
<p>Let’s have a quick look at how the included GP model works.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>SimpleGaussianProcessModel?</span></code></pre></div>
<p>Now let’s create the data.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>x_min <span class="op">=</span> <span class="op">-</span><span class="fl">30.0</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>x_max <span class="op">=</span> <span class="fl">30.0</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.uniform(x_min, x_max, (<span class="dv">10</span>, <span class="dv">1</span>))</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.sin(x) <span class="op">+</span> np.random.randn(<span class="dv">10</span>, <span class="dv">1</span>) <span class="op">*</span> <span class="fl">0.05</span></span></code></pre></div>
<p>To learn about how to include your own model in Emukit, check <a href="https://github.com/EmuKit/emukit/blob/master/notebooks/Emukit-tutorial-custom-model.ipynb">this notebook</a> which shows how to include a <code>sklearn</code> GP model.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>emukit_model <span class="op">=</span> SimpleGaussianProcessModel(x, y)</span></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core <span class="im">import</span> ParameterSpace, ContinuousParameter</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core.loop <span class="im">import</span> UserFunctionWrapper</span></code></pre></div>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> ContinuousParameter(<span class="st">&#39;c&#39;</span>, x_min, x_max)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>space <span class="op">=</span> ParameterSpace([p])</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>loop <span class="op">=</span> ExperimentalDesignLoop(space, emukit_model)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>loop.run_loop(np.sin, <span class="dv">30</span>)</span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plot_min <span class="op">=</span> <span class="op">-</span><span class="fl">40.0</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>plot_max <span class="op">=</span> <span class="fl">40.0</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>real_x <span class="op">=</span> np.arange(plot_min, plot_max, <span class="fl">0.2</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>real_y <span class="op">=</span> np.sin(real_x)</span></code></pre></div>
<div class="figure">
<div id="emukit-sine-function-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/emukit-sine-function.svg" width="80%" style=" ">
</object>
</div>
<div id="emukit-sine-function-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-sine-function&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-sine-function-caption" class="caption-frame">
<p>Figure: Experimental design in Emukit using the <code>ExperimentalDesignLoop</code>: learning function <span class="math inline">\(\sin(x)\)</span> with Emukit.</p>
</div>
</div>
<p>Computer the predictions from the Emukit model.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>predicted_y <span class="op">=</span> []</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>predicted_std <span class="op">=</span> []</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> real_x:</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    y, var <span class="op">=</span> emukit_model.predict(np.array([[x]]))</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> np.sqrt(var)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    predicted_y.append(y)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    predicted_std.append(std)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>predicted_y <span class="op">=</span> np.array(predicted_y).flatten()</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>predicted_std <span class="op">=</span> np.array(predicted_std).flatten()</span></code></pre></div>
<div class="figure">
<div id="emukit-sine-function-fit-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/emukit-sine-function-fit.svg" width="80%" style=" ">
</object>
</div>
<div id="emukit-sine-function-fit-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-sine-function-fit&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-sine-function-fit-caption" class="caption-frame">
<p>Figure: The fit to the sine function after runnning the Emukit <code>ExperimentalDesignLoop</code>.</p>
</div>
</div>
<h3 id="exercise-3">Exercise 3</h3>
<p>Repeat the above experiment but using the Gaussian process model from <code>sklearn</code>. You can see step by step instructions on how to do this in <a href="https://github.com/EmuKit/emukit/blob/master/notebooks/Emukit-tutorial-custom-model.ipynb">this notebook</a>.</p>
<h2 id="emukit-overview-summary">Emukit Overview Summary</h2>
<p>The aim is to provide a suite where different approaches to emulation are assimilated under one roof. The current version of Emukit includes <em>multi-fidelity emulation</em> for build surrogate models when data is obtained from multiple information sources that have different fidelity and/or cost; <em>Bayesian optimisation</em> for optimising physical experiments and tune parameters of machine learning algorithms or other computational simulations; <em>experimental design and active learning</em>: design the most informative experiments and perform active learning with machine learning models; <em>sensitivity analysis</em>: analyse the influence of inputs on the outputs of a given system; and <em>Bayesian quadrature</em>: efficiently compute the integrals of functions that are expensive to evaluate. But it’s easy to extend.</p>
<h2 id="emukit-sensitivity-analysis">Emukit Sensitivity Analysis</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-sensitivity-analysis.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-sensitivity-analysis.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>This introduction is based on <a href="https://github.com/EmuKit/emukit/blob/master/notebooks/Emukit-tutorial-sensitivity-montecarlo.ipynb">Introduction to Global Sensitivity Analysis with Emukit</a> written by Mark Pullin, Javier Gonzalez, Juan Emmanuel Johnson and Andrei Paleyes. Some references include <span class="citation" data-cites="Kennedy-predicting00 Sobol-sensitivity90 Sobol-global01 Saltelli-sensitivity04 Saltelli-global08 Saltelli-variance10">(Kennedy and O’Hagan, 2000; Saltelli et al., 2010, 2008, 2004; Sobol, 2001, 1990)</span></p>
<blockquote>
<p>A possible definition of sensitivity analysis is the following: The study of how uncertainty in the output of a model (numerical or otherwise) can be apportioned to different sources of uncertainty in the model input <span class="citation" data-cites="Saltelli-sensitivity04">(Saltelli et al., 2004)</span>. A related practice is ‘uncertainty analysis,’ which focuses rather on quantifying uncertainty in model output. Ideally, uncertainty and sensitivity analyses should be run in tandem, with uncertainty analysis preceding in current practice.</p>
<p>In Chapter 1 of <span class="citation" data-cites="Saltelli-global08">Saltelli et al. (2008)</span></p>
</blockquote>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> colors <span class="im">as</span> mcolors</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pyDOE</span></code></pre></div>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai.plot <span class="im">as</span> plot</span></code></pre></div>
<p>Sensitivity analysis is a statistical technique widely used to test the reliability of real systems. Imagine a simulator of taxis picking up customers in a city like the one showed in the <a href="https://github.com/amzn/emukit-playground">Emukit playground</a>. The profit of the taxi company depends on factors like the number of taxis on the road and the price per trip. In this example, a global sensitivity analysis of the simulator could be useful to decompose the variance of the profit in a way that can be assigned to the input variables of the simulator.</p>
<p>There are different ways of doing a sensitivity analysis of the variables of a simulator. In this notebook we will start with an approach based on Monte Carlo sampling that is useful when evaluating the simulator is cheap. If evaluating the simulator is expensive, emulators can then be used to speed up computations. We will show this in the last part of the notebook. Next, we start with a few formal definitions and literature review so we can understand the basics of Sensitivity Analysis and how it can be performed with Emukit.</p>
<h2 id="local-sensitivity">Local Sensitivity</h2>
<p>Given any function, <span class="math inline">\(g(\cdot)\)</span>, we might be interested in how sensitive that function is to variations in its input space. One route to determining this is to compute the partial derivatives of that function with respect to its inputs, <span class="math display">\[
\frac{\partial}{\partial x_i} g(\mathbf{ x}).
\]</span> The matrix of all these partial derivatives is known as the Jacobian.</p>
<p>These types of local sensitivity analysis can be used for determining the effect of changing an input variable around an operating point. But they don’t give us an understanding of the response of the target function to variations in the input across the domain of inputs. For this, we need to look to <em>global sensitivity analysis</em>.</p>
<h2 id="global-sensitivity-analysis">Global Sensitivity Analysis</h2>
<p>In global sensitivity analysis, rather than looking around a single operating point, we’re interested in the overall sensitivity of a function to its inputs, or combinations of inputs, across its entire domain. The key tool in determining this sensitivity is known as the ANOVA decomposition, or the <em>Hoeffding-Sobol decomposition</em>.</p>
<p>For global sensitivity analysis, we need to make an assumption about how inputs are going to vary to create different values of the function. The fundamental object we’re interested in is the total variance of the function, <span class="math display">\[
\text{var}\left(g(\mathbf{ x})\right) = \left\langle g(\mathbf{ x})^2 \right\rangle _{p(\mathbf{ x})} - \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})}^2,
\]</span> where <span class="math display">\[
\left\langle h(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})} = \int_\mathbf{ x}h(\mathbf{ x}) p(\mathbf{ x}) \text{d}\mathbf{ x}
\]</span> is the expectation of the function <span class="math inline">\(h(\mathbf{ x})\)</span> under the density <span class="math inline">\(p(\mathbf{ x})\)</span>, which represents the probability distribution of inputs we’re interested in.</p>
<p>The total variance of the function gives us the overall variation of the function across the domain of inputs, as represented by the probability density, <span class="math inline">\(p(\mathbf{ x})\)</span>. Normally, we perform analysis by assuming that, <span class="math display">\[
p(\mathbf{ x}) = \prod_{i=1}^pp(x_i)
\]</span> and that each <span class="math inline">\(p(x_i)\)</span> is <em>uniformly distributed</em> across its input domain. Assuming we scale the input domain down to the interval <span class="math inline">\([0, 1]\)</span>, that gives us <span class="math display">\[
x_i \sim \mathcal{U}\left(0,1\right).
\]</span></p>
<h2 id="hoeffding-sobol-decomposition">Hoeffding-Sobol Decomposition</h2>
<p>The Hoeffding-Sobol, or ANOVA, decomposition of a function allows us to write it as, <span class="math display">\[
\begin{align*}
g(\mathbf{ x}) = &amp; g_0 + \sum_{i=1}^pg_i(x_i) + \sum_{i&lt;j}^{p} g_{ij}(x_i,x_j) + \cdots \\
&amp; + g_{1,2,\dots,p}(x_1,x_2,\dots,x_p),
\end{align*}
\]</span> where <span class="math display">\[
g_0 = \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})}
\]</span> and <span class="math display">\[
g_i(x_i) = \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x}_{\sim i})} - g_0,
\]</span> where we’re using the notation <span class="math inline">\(p(\mathbf{ x}_{\sim i})\)</span> to represent the input distribution with the <span class="math inline">\(i\)</span>th variable marginalised, <span class="math display">\[
p(\mathbf{ x}_{\sim i}) = \int p(\mathbf{ x}) \text{d}x_i
\]</span> Higher order terms in the decomposition represent interactions between inputs, <span class="math display">\[
g_{i,j}(x_i, x_j) = \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x}_{\sim i,j})} - g_i(x_i) - g_j(x_j) - g_0
\]</span> and similar expressions can be written for higher order terms up to <span class="math inline">\(g_{1,2,\dots,p}(\mathbf{ x})\)</span>.</p>
<p>Note that to compute each of these individual terms, you need to first compute the low order terms, and then compute the high order terms. This can be problematic when <span class="math inline">\(p\)</span> is large.</p>
<p>We’re interested in the variance of the function <span class="math inline">\(g\)</span>, so implicitly we’re assuming that the square of this function is integrable across its domain, i.e., we’re assuming that <span class="math inline">\(\left\langle g(\mathbf{ x})^2 \right\rangle _{p(\mathbf{ x})}\)</span> exists and is finite.</p>
<p>The Sobol decomposition has some important properties, in particular, its components are orthogonal, so this means that when we substitute it in to the variance, we have, <span class="math display">\[
\begin{align*}
\text{var}(g) = &amp; \left\langle g(\mathbf{ x})^2  \right\rangle _{p(\mathbf{ x})} - \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})}^2 \\
 = &amp; \left\langle g(\mathbf{ x})^2  \right\rangle _{p(\mathbf{ x})} - g_0^2\\
 = &amp; \sum_{i=1}^p\text{var}\left(g_i(x_i)\right) + \sum_{i&lt;j}^{p} \text{var}\left(g_{ij}(x_i,x_j)\right)  + \cdots \\ &amp; + \text{var}\left(g_{1,2,\dots,p}(x_1,x_2,\dots,x_p)\right).
\end{align*}
\]</span> So, this decomposition gives us a decomposition of the function in terms of variances. It’s for this reason that it’s sometimes known as an ANOVA decomposition. ANOVA stands a for <em>analysis of variance</em>. The ANOVA decomposition decomposes the function into additive variance parts that are each stemming from interactions between different inputs.</p>
<p>As is common in various analyses of variance, we can rescale the components with the <em>total variance</em> of the function. These rescaled components are known as <em>Sobol indicies</em>. <span class="math display">\[
S_\ell = \frac{\text{var}\left(g(\mathbf{ x}_\ell)\right)}{\text{var}\left(g(\mathbf{ x})\right)},
\]</span> where the <span class="math inline">\(\ell\)</span> represents the relevent set of indices for the different combinations of inputs.</p>
<p>In practice, for an elegant approach that exploits a particular covariance function structure to perform global sensitivity analysis see <span class="citation" data-cites="Durrande-anova13">Durrande et al. (2013)</span>.</p>
<h1 id="example-the-ishigami-function">Example: the Ishigami function</h1>
<p>We illustrate the exact calculation of the Sobol indices with the three-dimensional Ishigami function of <span class="citation" data-cites="Ishigami-importance90">(Ishigami and Homma, 1989)</span>.</p>
<h3 id="ishigami-function">Ishigami Function</h3>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/ishigami-function.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/ishigami-function.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The Ishigami function <span class="citation" data-cites="Ishigami-importance90">(Ishigami and Homma, 1989)</span> is a well-known test function for uncertainty and sensitivity analysis methods because of its strong nonlinearity and peculiar dependence on <span class="math inline">\(x_3\)</span>. More details of this function can be found in <span class="citation" data-cites="Sobol-variance99">(Sobol and Levitan, 1999)</span>.</p>
<p>Mathematically, the form of the Ishigami function is <span class="math display">\[
g(\textbf{x}) = \sin(x_1) + a \sin^2(x_2) + b x_3^4 \sin(x_1). 
\]</span> We will set the parameters to be <span class="math inline">\(a = 5\)</span> and <span class="math inline">\(b=0.1\)</span> . The input variables are sampled randomly <span class="math inline">\(x_i \sim \mathcal{U}\left(-\pi,\pi\right)\)</span>.</p>
<p>Next, we create the function object and visualize its shape marginally for each one of its three inputs.</p>
<p>Load the Ishigami function</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.test_functions.sensitivity <span class="im">import</span> Ishigami</span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>ishigami <span class="op">=</span> Ishigami(a<span class="op">=</span><span class="dv">5</span>, b<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>target_function <span class="op">=</span> ishigami.fidelity1</span></code></pre></div>
<p>That gives us the target function, next we define the input space for the simulator.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core <span class="im">import</span> ContinuousParameter, ParameterSpace</span></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>variable_domain <span class="op">=</span> (<span class="op">-</span>np.pi,np.pi)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>           </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>space <span class="op">=</span> ParameterSpace(</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>          [ContinuousParameter(<span class="st">&#39;x1&#39;</span>, <span class="op">*</span>variable_domain), </span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;x2&#39;</span>, <span class="op">*</span>variable_domain),</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;x3&#39;</span>, <span class="op">*</span>variable_domain)])</span></code></pre></div>
<p>Before moving to any further analysis, we first plot the non-zero components <span class="math inline">\(g(\mathbf{ x})\)</span>. These components are <span class="math display">\[
\begin{align*}
g_1(x_1) &amp; = \sin(x_1) \\
g_2(x_2) &amp; = a \sin^2 (x_2) \\
g_{13}(x_1,x_3) &amp; = b x_3^4 \sin(x_1) 
\end{align*}
\]</span></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>x_grid <span class="op">=</span> np.linspace(<span class="op">*</span>variable_domain,<span class="dv">100</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>target_simulator <span class="op">=</span> ishigami.fidelity1</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> ishigami.f1(x_grid)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> ishigami.f2(x_grid)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>F13 <span class="op">=</span> ishigami.f13(np.array([x_grid,x_grid]).T)[:,np.newaxis]</span></code></pre></div>
<div class="figure">
<div id="non-zero-sobol-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/non-zero-sobol-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="non-zero-sobol-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;non-zero-sobol-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="non-zero-sobol-ishigami-caption" class="caption-frame">
<p>Figure: The non-zero components of the Ishigami function.</p>
</div>
</div>
<h2 id="total-variance">Total Variance</h2>
<p>The total variance <span class="math inline">\(\text{var}(y)\)</span> in this example is</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ishigami.variance_total)</span></code></pre></div>
<p>which is the sum of the variance of <span class="math inline">\(\text{var}\left(g_1(x_1)\right)\)</span>, <span class="math inline">\(\text{var}\left(g_2(x_2)\right)\)</span> and <span class="math inline">\(\text{var}\left(g_{1,3}(x_{1,3})\right)\)</span></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ishigami.variance_x1, ishigami.variance_x2, ishigami.variance_x13)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ishigami.variance_x1 <span class="op">+</span> ishigami.variance_x2 <span class="op">+</span> ishigami.variance_x13)</span></code></pre></div>
<h2 id="first-order-sobol-indices-using-monte-carlo">First Order Sobol Indices using Monte Carlo</h2>
<p>The first order Sobol indices are a measure of “first order sensitivity” of each input variable. They account for the proportion of variance of <span class="math inline">\(y\)</span> explained by changing each variable alone while marginalizing over the rest. Recall that the Sobol index of the <span class="math inline">\(i\)</span>th variable is computed as <span class="math display">\[
S_i = \frac{\text{var}\left(g_i(x_i)\right)}{\text{var}\left(g(\mathbf{ x})\right)}.
\]</span> This value is standardized using the total variance, so it is possible to account for a fractional contribution of each variable to the total variance of the output.</p>
<p>The Sobol indices for higher order interactions <span class="math inline">\(S_{i,j}\)</span> are computed similarly. Due to the normalization by the total variance, the the sum of all Sobol indices equals to one.</p>
<p>In most cases we are interested in the first order indices. The Ishigami function has the benefit that these can be computed analytically. In <code>EmuKit</code> you can extract these values with the code.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>ishigami.main_effects</span></code></pre></div>
<p>But in general, these indices need to be sampled using Monte Carlo or one of the quasi-Monte Carlo methods we’ve seen in the model-free experimental design. Details are given in <span class="citation" data-cites="Sobol-global01">(Sobol, 2001)</span>.</p>
<p>With Emukit, the first-order Sobol indices can be easily computed. We first need to define the space where the target simulator is analyzed.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.sensitivity.monte_carlo <span class="im">import</span> ModelFreeMonteCarloSensitivity</span></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)  <span class="co"># for reproducibility</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>num_monte_carlo_points <span class="op">=</span> <span class="dv">10000</span>  <span class="co"># Number of MC samples</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>senstivity_ishigami <span class="op">=</span> ModelFreeMonteCarloSensitivity(target_simulator, space)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>main_effects, total_effects, _ <span class="op">=</span> senstivity_ishigami.compute_effects(num_monte_carlo_points <span class="op">=</span> num_monte_carlo_points)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(main_effects)</span></code></pre></div>
<p>We compare the true effects with the Monte Carlo effects in a bar-plot. The total effects are discussed later.</p>
<div class="figure">
<div id="first-order-sobol-indices-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/first-order-sobol-indices-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="first-order-sobol-indices-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;first-order-sobol-indices-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="first-order-sobol-indices-ishigami-caption" class="caption-frame">
<p>Figure: The non-zero components of the Ishigami function.</p>
</div>
</div>
<h2 id="total-effects-using-monte-carlo">Total Effects Using Monte Carlo</h2>
<p>Computing high order sensitivity indices can be computationally very demanding in high dimensional scenarios and measuring the total influence of each variable on the variance of the output is infeasible. To solve this issue the <em>total</em> indices are used which account for the contribution to the output variance of <span class="math inline">\(x_i\)</span> including all variance caused by the variable alone and all its interactions of any order.</p>
<p>The total effect for <span class="math inline">\(x_i\)</span> is given by: <span class="math display">\[ 
S_{Ti} = \frac{\left\langle \text{var}_{x_i} (y\mid \mathbf{ x}_{\sim i}) \right\rangle _{p(\mathbf{ x}_{\sim i})}}{\text{var}\left(g(\mathbf{ x})\right)} = 1 - \frac{\text{var}_{\mathbf{ x}_{\sim i}} \left\langle y\mid \mathbf{ x}_{\sim i} \right\rangle _{p(\mathbf{ x}_{\sim i})}}{\text{var}\left(g(\mathbf{ x})\right)}
\]</span></p>
<p>Note that the sum of <span class="math inline">\(S_{Ti}\)</span> is not necessarily one in this case unless the model is additive. In the Ishigami example the value of the total effects is</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>ishigami.total_effects</span></code></pre></div>
<p>As in the previous example, the total effects can be computed with Monte Carlo. In the next plot we show the comparison with the true total effects.</p>
<div class="figure">
<div id="total-effects-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/total-effects-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="total-effects-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;total-effects-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="total-effects-ishigami-caption" class="caption-frame">
<p>Figure: The total effects from the Ishigami function as computed via Monte Carlo estimate alongside the true total effects for the Ishigami function.</p>
</div>
</div>
<h2 id="computing-the-sensitivity-indices-using-the-output-of-a-model">Computing the Sensitivity Indices Using the Output of a Model</h2>
<p>In the example used above the Ishigami function is very cheap to evaluate. However, in most real scenarios the functions of interest are expensive, and we need to limit ourselves to a few number of evaluations. Using Monte Carlo methods is infeasible in these scenarios as a large number of samples are typically required to provide good estimates of the Sobol indices.</p>
<p>An alternative in these cases is to use Gaussaian process emulator of the function of interest trained on a few inputs and outputs <span class="citation" data-cites="Marrel-sobol09">(Marrel et al., 2009)</span>. If the model is properly trained, its mean prediction which is cheap to evaluate, can be used to compute the Monte Carlo estimates of the Sobol indices, the variance from the GP emulator can also be used to assess our uncertainty about the Sobol indices. Let’s see how we can do this in Emukit.</p>
<p>We start by generating 100 samples in the input domain. Note that this a just 1% of the number of samples that we used to compute the Sobol coefficients using Monte Carlo.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core.initial_designs <span class="im">import</span> RandomDesign</span></code></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>design <span class="op">=</span> RandomDesign(space)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> design.get_samples(<span class="dv">500</span>)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> ishigami.fidelity1(x)[:,np.newaxis]</span></code></pre></div>
<p>Now, we fit a standard Gaussian process to the samples, and we wrap it as an Emukit model.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> GPy.models <span class="im">import</span> GPRegression</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.model_wrappers <span class="im">import</span> GPyModelWrapper</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.sensitivity.monte_carlo <span class="im">import</span> MonteCarloSensitivity</span></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>model_gpy <span class="op">=</span> GPRegression(x,y)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>model_emukit <span class="op">=</span> GPyModelWrapper(model_gpy)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>model_emukit.optimize()</span></code></pre></div>
<p>The final step is to compute the coefficients using the class <code>ModelBasedMonteCarloSensitivity</code> which directly calls the model and uses its predictive mean to compute the Monte Carlo estimates of the Sobol indices. We plot the true estimates, those computed using 10000 direct evaluations of the object using Monte Carlo and those computed using a Gaussian process model trained on 100 evaluations.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>num_mc <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>senstivity_ishigami_gpbased <span class="op">=</span> MonteCarloSensitivity(model <span class="op">=</span> model_emukit, input_domain <span class="op">=</span> space)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>main_effects_gp, total_effects_gp, _ <span class="op">=</span> senstivity_ishigami_gpbased.compute_effects(num_monte_carlo_points <span class="op">=</span> num_mc)</span></code></pre></div>
<div class="figure">
<div id="first-order-sobol-indices-gp-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/first-order-sobol-indices-gp-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="first-order-sobol-indices-gp-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;first-order-sobol-indices-gp-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="first-order-sobol-indices-gp-ishigami-caption" class="caption-frame">
<p>Figure: First order Sobol indices as estimated by Monte Carlo and GP-emulator based Monte Carlo.</p>
</div>
</div>
<div class="figure">
<div id="total-effects-sobol-indices-gp-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/total-effects-sobol-indices-gp-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="total-effects-sobol-indices-gp-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;total-effects-sobol-indices-gp-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="total-effects-sobol-indices-gp-ishigami-caption" class="caption-frame">
<p>Figure: Total effects as estimated by Monte Carlo and GP based Monte Carlo.</p>
</div>
</div>
<p>We observe some discrepancies with respect to the real value of the Sobol index when using the Gaussian process, but we get a fairly good approximation with a very reduced number of evaluations of the original target function.</p>
<h2 id="conclusions">Conclusions</h2>
<p>The Sobol indices are a tool for explaining the variance of the output of a function as components of the input variables. Monte Carlo is an approach for computing these indices if the function is cheap to evaluate. Other approaches are needed when <span class="math inline">\(g(\cdot)\)</span> is expensive to compute.</p>
<h2 id="catapult-simulation">Catapult Simulation</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-simulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-simulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip10">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Nicolas Durrande
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/gpss/./slides/diagrams//people/nicolas-durrande2.jpg" clip-path="url(#clip10)"/>
</svg>
<p>As a worked example we’re going to introduce a catapult simulation written by Nicolas Durrande, <a href="https://durrande.shinyapps.io/catapult/" class="uri">https://durrande.shinyapps.io/catapult/</a>.</p>
<div class="figure">
<div id="catapult-simulation-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//uq/catapult-simulation.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="catapult-simulation-magnify" class="magnify" onclick="magnifyFigure(&#39;catapult-simulation&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="catapult-simulation-caption" class="caption-frame">
<p>Figure: A catapult simulation for experimenting with surrogate models, kindly provided by Nicolas Durrande</p>
</div>
</div>
<p>The simulator allows you to set various parameters of the catapult including the axis of rotation, <code>roation_axis</code>, the position of the arm stop, <code>arm_stop</code>, and the location of the two bindings of the catapult’s spring, <code>spring_binding_1</code> and <code>spring_binding_2</code>.</p>
<p>These parameters are then collated in a vector, <span class="math display">\[
\mathbf{ x}_i = \begin{bmatrix}
\texttt{rotation_axis} \\
\texttt{arm_stop} \\
\texttt{spring_binding_1} \\
\texttt{spring_binding_2}
\end{bmatrix}
\]</span></p>
<p>Having set those parameters, you can run an experiment, by firing the catapult. This will show you how far it goes.</p>
<p>Because you will need to operate the catapult yourself, we’ll create a function to query you about the result of an individual firing.</p>
<p>We can also set the parameter space for the model. Each of these variables is scaled to operate <span class="math inline">\(\in [0, 1]\)</span>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core <span class="im">import</span> ContinuousParameter, ParameterSpace</span></code></pre></div>
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>variable_domain <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">1</span>]</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>           </span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>space <span class="op">=</span> ParameterSpace(</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>          [ContinuousParameter(<span class="st">&#39;rotation_axis&#39;</span>, <span class="op">*</span>variable_domain), </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;arm_stop&#39;</span>, <span class="op">*</span>variable_domain),</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;spring_binding_1&#39;</span>, <span class="op">*</span>variable_domain),</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;spring_binding_2&#39;</span>, <span class="op">*</span>variable_domain)])</span></code></pre></div>
<p>Before we perform sensitivity analysis, we need to build an emulator of the catapulter, which we do using our experimental design process.</p>
<h2 id="experimental-design-for-the-catapult">Experimental Design for the Catapult</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-experimental-design.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-experimental-design.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Now we will build an emulator for the catapult using the experimental design loop.</p>
<p>We’ll start with a small model-free design, we’ll use a random design for initializing our model.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core.initial_designs <span class="im">import</span> RandomDesign</span></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>design <span class="op">=</span> RandomDesign(space)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> design.get_samples(<span class="dv">5</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> catapult_distance(x)</span></code></pre></div>
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> GPy.models <span class="im">import</span> GPRegression</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.model_wrappers <span class="im">import</span> GPyModelWrapper</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.sensitivity.monte_carlo <span class="im">import</span> MonteCarloSensitivity</span></code></pre></div>
<p>Set up the GPy model. The variance of the RBF kernel is set to <span class="math inline">\(150^2\)</span> because that’s roughly the square of the range of the catapult. We set the noise variance to a small value.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>model_gpy <span class="op">=</span> GPRegression(x,y)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>model_gpy.kern.variance <span class="op">=</span> <span class="dv">150</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>model_gpy.likelihood.variance.fix(<span class="fl">1e-5</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>display(model_gpy)</span></code></pre></div>
<p>Wrap the model for EmuKit.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>model_emukit <span class="op">=</span> GPyModelWrapper(model_gpy)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>model_emukit.optimize()</span></code></pre></div>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>display(model_gpy)</span></code></pre></div>
<p>Now we set up the model loop. We’ll use integrated variance reduction as the acquisition function for our model-based design loop.</p>
<p><em>Warning</em>: This loop runs much slower on Google <code>colab</code> than on a local machine.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.experimental_design.experimental_design_loop <span class="im">import</span> ExperimentalDesignLoop</span></code></pre></div>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.experimental_design.acquisitions <span class="im">import</span> IntegratedVarianceReduction, ModelVariance</span></code></pre></div>
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>integrated_variance <span class="op">=</span> IntegratedVarianceReduction(space<span class="op">=</span>space,</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>                                                  model<span class="op">=</span>model_emukit)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>ed <span class="op">=</span> ExperimentalDesignLoop(space<span class="op">=</span>space, </span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>                            model<span class="op">=</span>model_emukit, </span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>                            acquisition <span class="op">=</span> integrated_variance)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>ed.run_loop(catapult_distance, <span class="dv">10</span>)</span></code></pre></div>
<h2 id="sensitivity-analysis-of-a-catapult-simulation">Sensitivity Analysis of a Catapult Simulation</h2>
<p>The final step is to compute the coefficients using the class <code>ModelBasedMonteCarloSensitivity</code> which directly calls the model and uses its predictive mean to compute the Monte Carlo estimates of the Sobol indices. We plot the estimates of the Sobol indices computed using a Gaussian process model trained on the observations we’ve acquired.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>num_mc <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>senstivity <span class="op">=</span> MonteCarloSensitivity(model <span class="op">=</span> model_emukit, input_domain <span class="op">=</span> space)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>main_effects_gp, total_effects_gp, _ <span class="op">=</span> senstivity.compute_effects(num_monte_carlo_points <span class="op">=</span> num_mc)</span></code></pre></div>
<div class="figure">
<div id="first-order-sobol-indices-gp-catapult-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/first-order-sobol-indices-gp-catapult.svg" width="80%" style=" ">
</object>
</div>
<div id="first-order-sobol-indices-gp-catapult-magnify" class="magnify" onclick="magnifyFigure(&#39;first-order-sobol-indices-gp-catapult&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="first-order-sobol-indices-gp-catapult-caption" class="caption-frame">
<p>Figure: First Order sobol indices as estimated by GP-emulator based Monte Carlo on the catapult.</p>
</div>
</div>
<div class="figure">
<div id="total-effects-sobol-indices-gp-catapult-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//uq/total-effects-sobol-indices-gp-catapult.svg" width="80%" style=" ">
</object>
</div>
<div id="total-effects-sobol-indices-gp-catapult-magnify" class="magnify" onclick="magnifyFigure(&#39;total-effects-sobol-indices-gp-catapult&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="total-effects-sobol-indices-gp-catapult-caption" class="caption-frame">
<p>Figure: Total effects as estimated by GP based Monte Carlo on the catapult.</p>
</div>
</div>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Borchert-dataoriented20" class="csl-entry" role="doc-biblioentry">
Borchert, T., 2020. Milan: An evolution of data-oriented programming.
</div>
<div id="ref-Durrande-anova13" class="csl-entry" role="doc-biblioentry">
Durrande, N., Ginsbourger, D., Olivier, Carraro, L., 2013. <span>ANOVA</span> kernels and <span>RKHS</span> of zero mean functions for model-based sensitivity analysis. Journal of Multivariate Analysis 115, 57–67. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2012.08.016">https://doi.org/10.1016/j.jmva.2012.08.016</a>
</div>
<div id="ref-Ishigami-importance90" class="csl-entry" role="doc-biblioentry">
Ishigami, T., Homma, T., 1989. An importance quantification technique in uncertainty analysis for computer models. [1990] Proceedings. First International Symposium on Uncertainty Modeling and Analysis 398–403.
</div>
<div id="ref-Joshi-doa07" class="csl-entry" role="doc-biblioentry">
Joshi, R., 2007. A loosely-coupled real-time SOA. Real-Time Innovations Inc.
</div>
<div id="ref-Kennedy-bayesian01" class="csl-entry" role="doc-biblioentry">
Kennedy, M.C., O’Hagan, A., 2001. Bayesian calibration of computer models. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 63, 425–464. <a href="https://doi.org/10.1111/1467-9868.00294">https://doi.org/10.1111/1467-9868.00294</a>
</div>
<div id="ref-Kennedy-predicting00" class="csl-entry" role="doc-biblioentry">
Kennedy, M.C., O’Hagan, A., 2000. Predicting the output from a complex computer code when fast approximations are available. Biometrika 87, 1–13.
</div>
<div id="ref-Laplace-essai14" class="csl-entry" role="doc-biblioentry">
Laplace, P.S., 1814. Essai philosophique sur les probabilités, 2nd ed. Courcier, Paris.
</div>
<div id="ref-Lawrence-drl17" class="csl-entry" role="doc-biblioentry">
Lawrence, N.D., 2017. Data readiness levels. ArXiv.
</div>
<div id="ref-Lawrence-maturity20" class="csl-entry" role="doc-biblioentry">
Lawrence, N.D., Montgomery, J., Paquet, U., 2020. Organisational data maturity. The Royal Society.
</div>
<div id="ref-Marrel-sobol09" class="csl-entry" role="doc-biblioentry">
Marrel, A., Iooss, B., Laurent, B., Roustant, O., 2009. Calculations of <span>S</span>obol indices for the <span>G</span>aussian process metamodel. Reliability Engineering &amp; System Safety 94, 742–751. https://doi.org/<a href="https://doi.org/10.1016/j.ress.2008.07.008">https://doi.org/10.1016/j.ress.2008.07.008</a>
</div>
<div id="ref-McKay-selecting79" class="csl-entry" role="doc-biblioentry">
McKay, M.D., Beckman, R.J., Conover, W.J., 1979. A comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics 21, 239–245.
</div>
<div id="ref-Paleyes-emulation19" class="csl-entry" role="doc-biblioentry">
Paleyes, A., Pullin, M., Mahsereci, M., McCollum, C., Lawrence, N.D., Gonzalez, J., 2019. Emulation of physical processes with emukit, in: Second Workshop on Machine Learning and the Physical Sciences, NeuRIPS 2019.
</div>
<div id="ref-Saltelli-variance10" class="csl-entry" role="doc-biblioentry">
Saltelli, A., Annoni, P., Azzini, I., Campolongo, F., Ratto, M., Tarantola, S., 2010. Variance based sensitivity analysis of model output. Design and estimator for the total sensitivity index. Computer Physics Communications 181, 259–270. <a href="https://doi.org/10.1016/j.cpc.2009.09.018">https://doi.org/10.1016/j.cpc.2009.09.018</a>
</div>
<div id="ref-Saltelli-global08" class="csl-entry" role="doc-biblioentry">
Saltelli, A., Ratto, M., Andres, T., Campolongo, F., Cariboni, J., Gatelli, D., Saisana, M., Tarantola, S., 2008. Global sensitivity analysis: The primer. wiley.
</div>
<div id="ref-Saltelli-sensitivity04" class="csl-entry" role="doc-biblioentry">
Saltelli, A., Tarantola, S., Campolongo, F., Ratto, M., 2004. Sensitivity analysis in practice: A guide to assessing scientific methods. wiley.
</div>
<div id="ref-Sobol-global01" class="csl-entry" role="doc-biblioentry">
Sobol, I.M., 2001. Global sensitivity indices for nonlinear mathematical models and their <span>M</span>onte <span>C</span>arlo estimates. Mathematics and Computers in Simulation 55, 271–280. <a href="https://doi.org/10.1016/S0378-4754(00)00270-6">https://doi.org/10.1016/S0378-4754(00)00270-6</a>
</div>
<div id="ref-Sobol-sensitivity90" class="csl-entry" role="doc-biblioentry">
Sobol, I.M., 1990. On sensitivity estimation for nonlinear mathematical models. Matematicheskoe Modelirovanie 2, 112–118.
</div>
<div id="ref-Sobol-variance99" class="csl-entry" role="doc-biblioentry">
Sobol, I.M., Levitan, Y.L., 1999. On the use of variance reducing multipliers in <span>M</span>onte <span>C</span>arlo computations of a global sensitivity index. Computer Physics Communications 117, 52–61. <a href="https://doi.org/10.1016/S0010-4655(98)00156-8">https://doi.org/10.1016/S0010-4655(98)00156-8</a>
</div>
<div id="ref-Delve-data20" class="csl-entry" role="doc-biblioentry">
The DELVE Initiative, 2020. Data readiness: Lessons from an emergency. The Royal Society.
</div>
<div id="ref-Vorhemus-doa17" class="csl-entry" role="doc-biblioentry">
Vorhemus, C., Schikuta, E., 2017. A data-oriented architecture for loosely coupled real-time information systems, in: Proceedings of the 19th International Conference on Information Integration and Web-Based Applications &amp; Services, iiWAS ’17. Association for Computing Machinery, New York, NY, USA, pp. 472–481. <a href="https://doi.org/10.1145/3151759.3151770">https://doi.org/10.1145/3151759.3151770</a>
</div>
</div>

