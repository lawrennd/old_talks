---
title: "Communication and Remote Working"
venue: "FPE Meeting, McGrath Centre, University of Cambridge"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
date: 2020-01-23
published: 2020-01-23
reveal: 2020-01-23-communication-and-remote-working.slides.html
pptx: 2020-01-23-communication-and-remote-working.pptx
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Front matter -->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!--Back matter-->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<h1 id="introduction">Introduction</h1>
<h2 id="embodiment-factors-edit">Embodiment Factors <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/embodiment-factors-tedx.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/embodiment-factors-tedx.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="embodiment-factors-table-figure" class="figure-frame">
<table>
<tr>
<td>
</td>
<td align="center">
<object class="svgplot " data="../slides/diagrams/computer.svg" width="100%" style=" ">
</object>
</td>
<td align="center">
<object class="svgplot " data="../slides/diagrams/human.svg" width="100%" style=" ">
</object>
</td>
<td align="center">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Jean-Dominique_Bauby.jpg" width="150%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
<tr>
<td>
bits/min
</td>
<td align="center">
billions
</td>
<td align="center">
2000
</td>
<td align="center">
6
</td>
</tr>
<tr>
<td>
billion<br>calculations/s
</td>
<td align="center">
~100
</td>
<td align="center">
a billion
</td>
<td align="center">
a billion
</td>
</tr>
<tr>
<td>
embodiment
</td>
<td align="center">
20 minutes
</td>
<td align="center">
5 billion years
</td>
<td align="center">
15 trillion years
</td>
</tr>
</table>
</div>
<div id="embodiment-factors-table-magnify" class="magnify" onclick="magnifyFigure(&#39;embodiment-factors-table&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="embodiment-factors-table-caption" class="caption-frame">
<p>Figure: Embodiment factors are the ratio between our ability to compute and our ability to communicate. Jean Dominique Bauby suffered from locked-in syndrome. The embodiment factors show that relative to the machine we are also locked in. In the table we represent embodiment as the length of time it would take to communicate one second’s worth of computation. For computers it is a matter of minutes, but for a human, whether locked in or not, it is a matter of many millions of years.</p>
</div>
</div>
<p>Let me explain what I mean. Claude Shannon introduced a mathematical concept of information for the purposes of understanding telephone exchanges.</p>
<p>Information has many meanings, but mathematically, Shannon defined a bit of information to be the amount of information you get from tossing a coin.</p>
<p>If I toss a coin, and look at it, I know the answer. You don’t. But if I now tell you the answer I communicate to you 1 bit of information. Shannon defined this as the fundamental unit of information.</p>
<p>If I toss the coin twice, and tell you the result of both tosses, I give you two bits of information. Information is additive.</p>
<p>Shannon also estimated the average information associated with the English language. He estimated that the average information in any word is 12 bits, equivalent to twelve coin tosses.</p>
<p>So every two minutes Bauby was able to communicate 12 bits, or six bits per minute.</p>
<p>This is the information transfer rate he was limited to, the rate at which he could communicate.</p>
<p>Compare this to me, talking now. The average speaker for TEDX speaks around 160 words per minute. That’s 320 times faster than Bauby or around a 2000 bits per minute. 2000 coin tosses per minute.</p>
<p>But, just think how much thought Bauby was putting into every sentence. Imagine how carefully chosen each of his words was. Because he was communication constrained he could put more thought into each of his words. Into thinking about his audience.</p>
<p>So, his intelligence became locked in. He thinks as fast as any of us, but can communicate slower. Like the tree falling in the woods with no one there to hear it, his intelligence is embedded inside him.</p>
<p>Two thousand coin tosses per minute sounds pretty impressive, but this talk is not just about us, it’s about our computers, and the type of intelligence we are creating within them.</p>
<p>So how does two thousand compare to our digital companions? When computers talk to each other, they do so with billions of coin tosses per minute.</p>
<p>Let’s imagine for a moment, that instead of talking about communication of information, we are actually talking about money. Bauby would have 6 dollars. I would have 2000 dollars, and my computer has billions of dollars.</p>
<p>The internet has interconnected computers and equipped them with extremely high transfer rates.</p>
<p>However, by our very best estimates, computers actually think slower than us.</p>
<p>How can that be? You might ask, computers calculate much faster than me. That’s true, but underlying your conscious thoughts there are a lot of calculations going on.</p>
<p>Each thought involves many thousands, millions or billions of calculations. How many exactly, we don’t know yet, because we don’t know how the brain turns calculations into thoughts.</p>
<p>Our best estimates suggest that to simulate your brain a computer would have to be as large as the UK Met Office machine here in Exeter. That’s a 250 million pound machine, the fastest in the UK. It can do 16 billion billon calculations per second.</p>
<p>It simulates the weather across the word every day, that’s how much power we think we need to simulate our brains.</p>
<p>So, in terms of our computational power we are extraordinary, but in terms of our ability to explain ourselves, just like Bauby, we are locked in.</p>
<p>For a typical computer, to communicate everything it computes in one second, it would only take it a couple of minutes. For us to do the same would take 15 billion years.</p>
<p>If intelligence is fundamentally about processing and sharing of information. This gives us a fundamental constraint on human intelligence that dictates its nature.</p>
<p>I call this ratio between the time it takes to compute something, and the time it takes to say it, the embodiment factor <span class="citation" data-cites="Lawrence:embodiment17">(Lawrence 2017)</span>. Because it reflects how embodied our cognition is.</p>
<p>If it takes you two minutes to say the thing you have thought in a second, then you are a computer. If it takes you 15 billion years, then you are a human.</p>
<h2 id="human-communication-edit">Human Communication <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/conversation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/conversation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>For human conversation to work, we require an internal model of who we are speaking to. We model each other, and combine our sense of who they are, who they think we are, and what has been said. This is our approach to dealing with the limited bandwidth connection we have. Empathy and understanding of intent. Mental dispositional concepts are used to augment our limited communication bandwidth.</p>
<p>Fritz Heider referred to the important point of a conversation as being that they are happenings that are “<em>psychologically represented</em> in each of the participants” (his emphasis) <span class="citation" data-cites="Heider:interpersonal58">(Heider 1958)</span></p>
<h3 id="bandwidth-constrained-conversations">Bandwidth Constrained Conversations</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">import</span> pods</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="im">from</span> ipywidgets <span class="im">import</span> IntSlider</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1">pods.notebook.display_plots(<span class="st">&#39;anne-bob-conversation</span><span class="sc">{sample:0&gt;3}</span><span class="st">.svg&#39;</span>, </a>
<a class="sourceLine" id="cb2-2" data-line-number="2">                            <span class="st">&#39;../slides/diagrams&#39;</span>,  sample<span class="op">=</span>IntSlider(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">1</span>))</a></code></pre></div>
<div class="figure">
<div id="anne-bob-conversation-civil-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-bob-conversation006.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-conversation-civil-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-bob-conversation-civil&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="anne-bob-conversation-civil-caption" class="caption-frame">
<p>Figure: Conversation relies on internal models of other individuals.</p>
</div>
</div>
<div class="figure">
<div id="anne-bob-conversation-argument-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-bob-conversation007.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-conversation-argument-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-bob-conversation-argument&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="anne-bob-conversation-argument-caption" class="caption-frame">
<p>Figure: Misunderstanding of context and who we are talking to leads to arguments.</p>
</div>
</div>
<p>Embodiment factors imply that, in our communication between humans, what is <em>not</em> said is, perhaps, more important than what is said. To communicate with each other we need to have a model of who each of us are.</p>
<p>To aid this, in society, we are required to perform roles. Whether as a parent, a teacher, an employee or a boss. Each of these roles requires that we conform to certain standards of behaviour to facilitate communication between ourselves.</p>
<p>Control of self is vitally important to these communications.</p>
<p>The high availability of data available to humans undermines human-to-human communication channels by providing new routes to undermining our control of self.</p>
<h3 id="a-six-word-novel-edit">A Six Word Novel <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/baby-shoes.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/baby-shoes.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h3>
<div class="figure">
<div id="classic-baby-shoes-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Classic_baby_shoes.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<center>
For sale: baby shoes, never worn
</center>
</div>
<div id="classic-baby-shoes-magnify" class="magnify" onclick="magnifyFigure(&#39;classic-baby-shoes&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="classic-baby-shoes-caption" class="caption-frame">
<p>Figure: Consider the six word novel, apocraphally credited to Ernest Hemingway, “For sale: baby shoes, never worn”. To understand what that means to a human, you need a great deal of additional context. Context that is not directly accessible to a machine that has not got both the evolved and contextual understanding of our own condition to realize both the implication of the advert and what that implication means emotionally to the previous owner.</p>
</div>
</div>
<p>But this is a very different kind of intelligence than ours. A computer cannot understand the depth of the Ernest Hemingway’s apocryphal six word novel: “For Sale, Baby Shoes, Never worn”, because it isn’t equipped with that ability to model the complexity of humanity that underlies that statement.</p>
<h3 id="heider-and-simmel-1944-edit">Heider and Simmel (1944) <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/heider-simmel.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/heider-simmel.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h3>
<div class="figure">
<div id="heider-simmel-shapes-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/8FIEZXMUM2I?start=7" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="heider-simmel-shapes-magnify" class="magnify" onclick="magnifyFigure(&#39;heider-simmel-shapes&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="heider-simmel-shapes-caption" class="caption-frame">
<p>Figure: Fritz Heider and Marianne Simmel’s video of shapes from <span class="citation" data-cites="Heider:experimental44">Heider and Simmel (1944)</span>.</p>
</div>
</div>
<p><a href="https://en.wikipedia.org/wiki/Fritz_Heider">Fritz Heider</a> and <a href="https://en.wikipedia.org/wiki/Marianne_Simmel">Marianne Simmel</a>’s experiments with animated shapes from 1944 <span class="citation" data-cites="Heider:experimental44">(Heider and Simmel 1944)</span>. Our interpretation of these objects as showing motives and even emotion is a combination of our desire for narrative, a need for understanding of each other, and our ability to empathise. At one level, these are crudely drawn objects, but in another key way, the animator has communicated a story through simple facets such as their relative motions, their sizes and their actions. We apply our psychological representations to these faceless shapes in an effort to interpret their actions.</p>
<h2 id="computer-conversations-edit">Computer Conversations <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/conversation-computer.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/conversation-computer.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="im">import</span> pods</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="im">from</span> ipywidgets <span class="im">import</span> IntSlider</a></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1">pods.notebook.display_plots(<span class="st">&#39;anne-bob-conversation</span><span class="sc">{sample:0&gt;3}</span><span class="st">.svg&#39;</span>, </a>
<a class="sourceLine" id="cb4-2" data-line-number="2">                            <span class="st">&#39;../slides/diagrams&#39;</span>,  sample<span class="op">=</span>IntSlider(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">1</span>))</a></code></pre></div>
<div class="figure">
<div id="anne-computer-conversation-6-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-computer-conversation006.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-6-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-computer-conversation-6&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="anne-computer-conversation-6-caption" class="caption-frame">
<p>Figure: Conversation relies on internal models of other individuals.</p>
</div>
</div>
<div class="figure">
<div id="anne-computer-conversation-8-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-computer-conversation007.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-8-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-computer-conversation-8&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="anne-computer-conversation-8-caption" class="caption-frame">
<p>Figure: Misunderstanding of context and who we are talking to leads to arguments.</p>
</div>
</div>
<p>Similarly, we find it difficult to comprehend how computers are making decisions. Because they do so with more data than we can possibly imagine.</p>
<p>In many respects, this is not a problem, it’s a good thing. Computers and us are good at different things. But when we interact with a computer, when it acts in a different way to us, we need to remember why.</p>
<p>Just as the first step to getting along with other humans is understanding other humans, so it needs to be with getting along with our computers.</p>
<p>Embodiment factors explain why, at the same time, computers are so impressive in simulating our weather, but so poor at predicting our moods. Our complexity is greater than that of our weather, and each of us is tuned to read and respond to one another.</p>
<p>Their intelligence is different. It is based on very large quantities of data that we cannot absorb. Our computers don’t have a complex internal model of who we are. They don’t understand the human condition. They are not tuned to respond to us as we are to each other.</p>
<p>Embodiment factors encapsulate a profound thing about the nature of humans. Our locked in intelligence means that we are striving to communicate, so we put a lot of thought into what we’re communicating with. And if we’re communicating with something complex, we naturally anthropomorphize them.</p>
<p>We give our dogs, our cats and our cars human motivations. We do the same with our computers. We anthropomorphize them. We assume that they have the same objectives as us and the same constraints. They don’t.</p>
<p>This means, that when we worry about artificial intelligence, we worry about the wrong things. We fear computers that behave like more powerful versions of ourselves that will struggle to outcompete us.</p>
<p>In reality, the challenge is that our computers cannot be human enough. They cannot understand us with the depth we understand one another. They drop below our cognitive radar and operate outside our mental models.</p>
<p>The real danger is that computers don’t anthropomorphize. They’ll make decisions in isolation from us without our supervision, because they can’t communicate truly and deeply with us.</p>
<h1 id="the-mind-is-flat-edit">The Mind is Flat <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_cognitive-science/includes/the-mind-is-flat.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_cognitive-science/includes/the-mind-is-flat.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h1>
<div class="figure">
<div id="mind-is-flat-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/cognitive-science/the-mind-is-flat.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="mind-is-flat-magnify" class="magnify" onclick="magnifyFigure(&#39;mind-is-flat&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mind-is-flat-caption" class="caption-frame">
<p>Figure: <a href="https://www.amazon.co.uk/dp/B077Y95D6V/">The Mind is Flat Nick Chater</a> relates the extent to which how we are is determined by the data we see.</p>
</div>
</div>
<p><span class="citation" data-cites="Chater:mindisflat19">(Chater 2019)</span></p>
<!--locked in

conversation

kappenball

Mind is flat (who you are is determined by who is around you)-->
<h1 id="references" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Chater:mindisflat19">
<p>Chater, Nick. 2019. <em>The Mind Is Flat</em>. Penguin.</p>
</div>
<div id="ref-Heider:interpersonal58">
<p>Heider, Fritz. 1958. <em>The Psychology of Interpersonal Relations</em>. John Wiley.</p>
</div>
<div id="ref-Heider:experimental44">
<p>Heider, F., and M. Simmel. 1944. “An Experimental Study of Apparent Behavior.” <em>The American Journal of Psychology</em> 57: 243–59.</p>
</div>
<div id="ref-Lawrence:embodiment17">
<p>Lawrence, Neil D. 2017. “Living Together: Mind and Machine Intelligence.” arXiv. <a href="https://arxiv.org/abs/1705.07996" class="uri">https://arxiv.org/abs/1705.07996</a>.</p>
</div>
</div>


