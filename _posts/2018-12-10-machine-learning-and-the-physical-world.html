---
title: "Machine Learning and the Physical World"
venue: "Center for Statistics and Machine Learning, Princeton"
abstract: "Machine learning is a data driven endeavour, but real world systems are physical and mechanistic. In this talk we will review approaches to integrating machine learning with real world systems. Our focus will be on emulation (otherwise known as surrogate modeling)."
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: Amazon Cambridge and University of Sheffield
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
date: 2018-12-10
published: 2018-12-10
reveal: 2018-12-10-machine-learning-and-the-physical-world.slides.html
ipynb: 2018-12-10-machine-learning-and-the-physical-world.ipynb
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Front matter -->
<!-- Front matter -->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!--Back matter-->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<h2 id="the-centrifugal-governor-edit">The Centrifugal Governor <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/centrifugal-governor.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/centrifugal-governor.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="science-holborn-viaduct-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/science-holborn-viaduct.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="science-holborn-viaduct-magnify" class="magnify" onclick="magnifyFigure(&#39;science-holborn-viaduct&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="science-holborn-viaduct-caption" class="caption-frame">
<p>Figure: Centrifugal governor as held by “Science” on Holborn Viaduct</p>
</div>
</div>
<h2 id="boulton-and-watts-steam-engine-edit">Boulton and Watt’s Steam Engine <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/watt-steam-engine.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/watt-steam-engine.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="steam-engine-boulton-watt-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/SteamEngine_Boulton&Watt_1784.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="steam-engine-boulton-watt-magnify" class="magnify" onclick="magnifyFigure(&#39;steam-engine-boulton-watt&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="steam-engine-boulton-watt-caption" class="caption-frame">
<p>Figure: Watt’s Steam Engine which made Steam Power Efficient and Practical.</p>
</div>
</div>
<p>James Watt’s steam engine contained an early machine learning device. In the same way that modern systems are component based, his engine was composed of components. One of which is a speed regulator sometimes known as <em>Watt’s governor</em>. The two balls in the center of the image, when spun fast, rise, and through a linkage mechanism.</p>
<p>The centrifugal governor was made famous by Boulton and Watt when it was deployed in the steam engine. Studying stability in the governor is the main subject of James Clerk Maxwell’s paper on the theoretical analysis of governors <span class="citation" data-cites="Maxwell:governors1867">(Maxwell 1867)</span>. This paper is a founding paper of control theory. In an acknowledgment of its influence, Wiener used the name <a href="https://en.wikipedia.org/wiki/Cybernetics"><em>cybernetics</em></a> to describe the field of control and communication in animals and the machine <span class="citation" data-cites="Wiener:cybernetics48">(Wiener 1948)</span>. Cybernetics is the Greek word for governor, which comes from the latin for helmsman.</p>
<p>A governor is one of the simplest artificial intelligence systems. It senses the speed of an engine, and acts to change the position of the valve on the engine to slow it down.</p>
<p>Although it’s a mechanical system a governor can be seen as automating a role that a human would have traditionally played. It is an early example of artificial intelligence.</p>
<p>The centrifugal governor has several parameters, the weight of the balls used, the length of the linkages and the limits on the balls movement.</p>
<p>Two principle differences exist between the centrifugal governor and artificial intelligence systems of today.</p>
<ol type="1">
<li>The centrifugal governor is a physical system and it is an integral part of a wider physical system that it regulates (the engine).</li>
<li>The parameters of the governor were set by hand, our modern artificial intelligence systems have their parameters set by <em>data</em>.</li>
</ol>
<div class="figure">
<div id="centrifugal-governor-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/Centrifugal_governor.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="centrifugal-governor-magnify" class="magnify" onclick="magnifyFigure(&#39;centrifugal-governor&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="centrifugal-governor-caption" class="caption-frame">
<p>Figure: The centrifugal governor, an early example of a decision making system. The parameters of the governor include the lengths of the linkages (which effect how far the throttle opens in response to movement in the balls), the weight of the balls (which effects inertia) and the limits of to which the balls can rise.</p>
</div>
</div>
<p>This has the basic components of sense and act that we expect in an intelligent system, and this system saved the need for a human operator to manually adjust the system in the case of overspeed. Overspeed has the potential to destroy an engine, so the governor operates as a safety device.</p>
<p>The first wave of automation did bring about sabotoage as a worker’s response. But if machinery was sabotaged, for example, if the linkage between sensor (the spinning balls) and action (the valve closure) was broken, this would be obvious to the engine operator at start up time. The machine could be repaired before operation.</p>
<h2 id="what-is-machine-learning-edit">What is Machine Learning? <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-2.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-2.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Machine learning allows us to extract knowledge from data to form a prediction.</p>
<p><br /><span class="math display">$$\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}$$</span><br /></p>
<p>A machine learning prediction is made by combining a model with data to form the prediction. The manner in which this is done gives us the machine learning <em>algorithm</em>.</p>
<p>Machine learning models are <em>mathematical models</em> which make weak assumptions about data, e.g. smoothness assumptions. By combining these assumptions with the data, we observe we can interpolate between data points or, occasionally, extrapolate into the future.</p>
<p>Machine learning is a technology which strongly overlaps with the methodology of statistics. From a historical/philosophical view point, machine learning differs from statistics in that the focus in the machine learning community has been primarily on accuracy of prediction, whereas the focus in statistics is typically on the interpretability of a model and/or validating a hypothesis through data collection.</p>
<p>The rapid increase in the availability of compute and data has led to the increased prominence of machine learning. This prominence is surfacing in two different but overlapping domains: data science and artificial intelligence.</p>
<h2 id="from-model-to-decision-edit">From Model to Decision <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-end-to-end.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-end-to-end.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>The real challenge, however, is end-to-end decision making. Taking information from the environment and using it to drive decision making to achieve goals.</p>
<!-- first drone delivery vNySOrI2Ny8 -->
<div class="figure">
<div id="amazon-drone-delivery-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/3HJtmx5f1Fc?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="amazon-drone-delivery-magnify" class="magnify" onclick="magnifyFigure(&#39;amazon-drone-delivery&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="amazon-drone-delivery-caption" class="caption-frame">
<p>Figure: Amazon’s proposed drone delivery system.</p>
</div>
</div>
<h2 id="artificial-intelligence-and-data-science-edit">Artificial Intelligence and Data Science <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/ai-vs-data-science-2.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/ai-vs-data-science-2.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Artificial intelligence has the objective of endowing computers with human-like intelligent capabilities. For example, understanding an image (computer vision) or the contents of some speech (speech recognition), the meaning of a sentence (natural language processing) or the translation of a sentence (machine translation).</p>
<h3 id="supervised-learning-for-ai">Supervised Learning for AI</h3>
<p>The machine learning approach to artificial intelligence is to collect and annotate a large data set from humans. The problem is characterized by input data (e.g. a particular image) and a label (e.g. is there a car in the image yes/no). The machine learning algorithm fits a mathematical function (I call this the <em>prediction function</em>) to map from the input image to the label. The parameters of the prediction function are set by minimizing an error between the function’s predictions and the true data. This mathematical function that encapsulates this error is known as the <em>objective function</em>.</p>
<p>This approach to machine learning is known as <em>supervised learning</em>. Various approaches to supervised learning use different prediction functions, objective functions or different optimization algorithms to fit them.</p>
<p>For example, <em>deep learning</em> makes use of <em>neural networks</em> to form the predictions. A neural network is a particular type of mathematical function that allows the algorithm designer to introduce invariances into the function.</p>
<p>An invariance is an important way of including prior understanding in a machine learning model. For example, in an image, a car is still a car regardless of whether it’s in the upper left or lower right corner of the image. This is known as translation invariance. A neural network encodes translation invariance in <em>convolutional layers</em>. Convolutional neural networks are widely used in image recognition tasks.</p>
<p>An alternative structure is known as a recurrent neural network (RNN). RNNs neural networks encode temporal structure. They use auto regressive connections in their hidden layers, they can be seen as time series models which have non-linear auto-regressive basis functions. They are widely used in speech recognition and machine translation.</p>
<p>Machine learning has been deployed in Speech Recognition (e.g. Alexa, deep neural networks, convolutional neural networks for speech recognition), in computer vision (e.g. Amazon Go, convolutional neural networks for person recognition and pose detection).</p>
<p>The field of data science is related to AI, but philosophically different. It arises because we are increasingly creating large amounts of data through <em>happenstance</em> rather than active collection. In the modern era data is laid down by almost all our activities. The objective of data science is to extract insights from this data.</p>
<p>Classically, in the field of statistics, data analysis proceeds by assuming that the question (or scientific hypothesis) comes before the data is created. E.g., if I want to determine the effectiveness of a particular drug, I perform a <em>design</em> for my data collection. I use foundational approaches such as randomization to account for confounders. This made a lot of sense in an era where data had to be actively collected. The reduction in cost of data collection and storage now means that many data sets are available which weren’t collected with a particular question in mind. This is a challenge because bias in the way data was acquired can corrupt the insights we derive. We can perform randomized control trials (or A/B tests) to verify our conclusions, but the opportunity is to use data science techniques to better guide our question selection or even answer a question without the expense of a full randomized control trial (referred to as A/B testing in modern internet parlance).</p>
<ul>
<li>There is a gap between the world of data science and AI.</li>
<li>The mapping of the virtual onto the physical world.</li>
<li>E.g. Causal understanding.</li>
</ul>
<h2 id="supply-chain-edit">Supply Chain <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/supply-chain.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/supply-chain.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="packhorse-bridge-burbage-brook-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/packhorse-bridge-burbage-brook.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="packhorse-bridge-burbage-brook-magnify" class="magnify" onclick="magnifyFigure(&#39;packhorse-bridge-burbage-brook&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="packhorse-bridge-burbage-brook-caption" class="caption-frame">
<p>Figure: Packhorse Bridge under Burbage Edge. This packhorse route climbs steeply out of Hathersage and heads towards Sheffield. Packhorses were the main route for transporting goods across the Peak District. The high cost of transport is one driver of the ‘smith’ model, where there is a local skilled person responsible for assembling or creating goods (e.g. a blacksmith).</p>
</div>
</div>
<p>On Sunday mornings in Sheffield, I often used to run across Packhorse Bridge in Burbage valley. The bridge is part of an ancient network of trails crossing the Pennines that, before Turnpike roads arrived in the 18th century, was the main way in which goods were moved. Given that the moors around Sheffield were home to sand quarries, tin mines, lead mines and the villages in the Derwent valley were known for nail and pin manufacture, this wasn’t simply movement of agricultural goods, but it was the infrastructure for industrial transport.</p>
<p>The profession of leading the horses was known as a Jagger and leading out of the village of Hathersage is Jagger’s Lane, a trail that headed underneath Stanage Edge and into Sheffield.</p>
<p>The movement of goods from regions of supply to areas of demand is fundamental to our society. The physical infrastructure of supply chain has evolved a great deal over the last 300 years.</p>
<h2 id="cromford-edit">Cromford <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/cromford.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/cromford.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="cromford-mill-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/cromford-mill.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="cromford-mill-magnify" class="magnify" onclick="magnifyFigure(&#39;cromford-mill&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="cromford-mill-caption" class="caption-frame">
<p>Figure: Richard Arkwright is regarded of the founder of the modern factory system. Factories exploit distribution networks to centralize production of goods. Arkwright located his factory in Cromford due to proximity to Nottingham Weavers (his market) and availability of water power from the tributaries of the Derwent river. When he first arrived there was almost no transportation network. Over the following 200 years The Cromford Canal (1790s), a Turnpike (now the A6, 1816-18) and the High Peak Railway (now closed, 1820s) were all constructed to improve transportation access as the factory blossomed.</p>
</div>
</div>
<p>Richard Arkwright is known as the father of the modern factory system. In 1771 he set up a <a href="https://en.wikipedia.org/wiki/Cromford_Mill">Mill</a> for spinning cotton yarn in the village of Cromford, in the Derwent Valley. The Derwent valley is relatively inaccessible. Raw cotton arrived in Liverpool from the US and India. It needed to be transported on packhorse across the bridleways of the Pennines. But Cromford was a good location due to proximity to Nottingham, where weavers where consuming the finished thread, and the availability of water power from small tributaries of the Derwent river for Arkwright’s <a href="https://en.wikipedia.org/wiki/Spinning_jenny">water frames</a> which automated the production of yarn from raw cotton.</p>
<p>By 1794 the <a href="https://en.wikipedia.org/wiki/Cromford_Canal">Cromford Canal</a> was opened to bring coal in to Cromford and give better transport to Nottingham. The construction of the canals was driven by the need to improve the transport infrastructure, facilitating the movement of goods across the UK. Canals, roads and railways were initially constructed by the economic need for moving goods. To improve supply chain.</p>
<p>The A6 now does pass through Cromford, but at the time he moved there there was merely a track. The High Peak Railway was opened in 1832, it is now converted to the High Peak Trail, but it remains the highest railway built in Britain.</p>
<p><span class="citation" data-cites="Cooper:transformation91">Cooper (1991)</span></p>
<h2 id="containerization-edit">Containerization <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/containerisation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/containerisation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="container-2539942_1920-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/container-2539942_1920.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="container-2539942_1920-magnify" class="magnify" onclick="magnifyFigure(&#39;container-2539942_1920&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="container-2539942_1920-caption" class="caption-frame">
<p>Figure: The container is one of the major drivers of globalization, and arguably the largest agent of social change in the last 100 years. It reduces the cost of transportation, significantly changing the appropriate topology of distribution networks. The container makes it possible to ship goods halfway around the world for cheaper than it costs to process those goods, leading to an extended distribution topology.</p>
</div>
</div>
<p>Containerization has had a dramatic effect on global economics, placing many people in the developing world at the end of the supply chain.</p>
<div class="figure">
<div id="wild-alaskan-cod-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/wild-alaskan-cod.jpg" width="90%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="45%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/wild-alaskan-cod-made-in-china.jpg" width="90%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="wild-alaskan-cod-magnify" class="magnify" onclick="magnifyFigure(&#39;wild-alaskan-cod&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="wild-alaskan-cod-caption" class="caption-frame">
<p>Figure: Wild Alaskan Cod, being solid in the Pacific Northwest, that is a product of China. It is cheaper to ship the deep frozen fish thousands of kilometers for processing than to process locally.</p>
</div>
</div>
<p>For example, you can buy Wild Alaskan Cod fished from Alaska, processed in China, sold in North America. This is driven by the low cost of transport for frozen cod vs the higher relative cost of cod processing in the US versus China. Similarly, <a href="https://www.telegraph.co.uk/news/uknews/1534286/12000-mile-trip-to-have-seafood-shelled.html" target="_blank" >Scottish prawns are also processed in China for sale in the UK.</a></p>
<p>This effect on cost of transport vs cost of processing is the main driver of the topology of the modern supply chain and the associated effect of globalization. If transport is much cheaper than processing, then processing will tend to agglomerate in places where processing costs can be minimized.</p>
<p>Large scale global economic change has principally been driven by changes in the technology that drives supply chain.</p>
<p>Supply chain is a large-scale automated decision making network. Our aim is to make decisions not only based on our models of customer behavior (as observed through data), but also by accounting for the structure of our fulfilment center, and delivery network.</p>
<p>Many of the most important questions in supply chain take the form of counterfactuals. E.g. “What would happen if we opened a manufacturing facility in Cambridge?” A counter factual is a question that implies a mechanistic understanding of a system. It goes beyond simple smoothness assumptions or translation invariants. It requires a physical, or <em>mechanistic</em> understanding of the supply chain network. For this reason, the type of models we deploy in supply chain often involve simulations or more mechanistic understanding of the network.</p>
<p>In supply chain Machine Learning alone is not enough, we need to bridge between models that contain real mechanisms and models that are entirely data driven.</p>
<p>This is challenging, because as we introduce more mechanism to the models we use, it becomes harder to develop efficient algorithms to match those models to data.</p>
<!--include{_ml/includes/or-control-econometrics-statistics-ml.md}-->
<p>Machine learning aims to replicate processes through the direct use of data. When deployed in the domain of ‘artificial intelligence’, the processes that it is replicating, or <em>emulating</em>, are cognitive processes.</p>
<p>The first trick in machine learning is to convert the process itself into a <em>mathematical function</em>. That function has a set of parameters which control its behaviour. What we call learning is the adaption of these parameters to change the behavior of the function. The choice of mathematical function we use is a vital component of the model.</p>
<h2 id="emukit-playground-edit">Emukit Playground <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-playground.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-playground.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Emukit playground is a software toolkit for exploring the use of statistical emulation as a tool. It was built by <a href="https://twitter.com/_AdamHirst">Adam Hirst</a>, during his software engineering internship at Amazon and supervised by Cliff McCollum.</p>
<div class="figure">
<div id="emukit-playground-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/uq/emukit-playground.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-playground-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-playground&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="emukit-playground-caption" class="caption-frame">
<p>Figure: Emukit playground is a tutorial for understanding the simulation/emulation relationship. <a href="https://amzn.github.io/emukit-playground/" class="uri">https://amzn.github.io/emukit-playground/</a></p>
</div>
</div>
<div class="figure">
<div id="emukit-playground-bayes-opt-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/uq/emukit-playground-bayes-opt.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-playground-bayes-opt-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-playground-bayes-opt&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="emukit-playground-bayes-opt-caption" class="caption-frame">
<p>Figure: Tutorial on Bayesian optimization of the number of taxis deployed from Emukit playground. <a href="https://amzn.github.io/emukit-playground/#!/learn/bayesian_optimization" class="uri">https://amzn.github.io/emukit-playground/#!/learn/bayesian_optimization</a></p>
</div>
</div>
<p>You can explore Bayesian optimization of a taxi simulation.</p>
<h2 id="uncertainty-quantification-edit">Uncertainty Quantification <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/uq-intro.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/uq-intro.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<blockquote>
<p>Uncertainty quantification (UQ) is the science of quantitative characterization and reduction of uncertainties in both computational and real world applications. It tries to determine how likely certain outcomes are if some aspects of the system are not exactly known.</p>
</blockquote>
<p>We will to illustrate different concepts of <a href="https://en.wikipedia.org/wiki/Uncertainty_quantification">Uncertainty Quantification</a> (UQ) and the role that Gaussian processes play in this field. Based on a simple simulator of a car moving between a valley and a mountain, we are going to illustrate the following concepts:</p>
<ul>
<li><p><strong>Systems emulation</strong>. Many real world decisions are based on simulations that can be computationally very demanding. We will show how simulators can be replaced by <em>emulators</em>: Gaussian process models fitted on a few simulations that can be used to replace the <em>simulator</em>. Emulators are cheap to compute, fast to run, and always provide ways to quantify the uncertainty of how precise they are compared the original simulator.</p></li>
<li><p><strong>Emulators in optimization problems</strong>. We will show how emulators can be used to optimize black-box functions that are expensive to evaluate. This field is also called Bayesian Optimization and has gained an increasing relevance in machine learning as emulators can be used to optimize computer simulations (and machine learning algorithms) quite efficiently.</p></li>
<li><p><strong>Multi-fidelity emulation methods</strong>. In many scenarios we have simulators of different quality about the same measure of interest. In these cases the goal is to merge all sources of information under the same model so the final emulator is cheaper and more accurate than an emulator fitted only using data from the most accurate and expensive simulator.</p></li>
</ul>
<h2 id="mountain-car-simulator-edit">Mountain Car Simulator <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/mountain-car-simulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/mountain-car-simulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>To illustrate the above mentioned concepts we we use the <a href="https://github.com/openai/gym/wiki/MountainCarContinuous-v0">mountain car simulator</a>. This simulator is widely used in machine learning to test reinforcement learning algorithms. The goal is to define a control policy on a car whose objective is to climb a mountain. Graphically, the problem looks as follows:</p>
<div class="figure">
<div id="mountain-car-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/uq/mountaincar.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="mountain-car-magnify" class="magnify" onclick="magnifyFigure(&#39;mountain-car&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mountain-car-caption" class="caption-frame">
<p>Figure: The mountain car simulation from the Open AI gym.</p>
</div>
</div>
<p>The goal is to define a sequence of actions (push the car right or left with certain intensity) to make the car reach the flag after a number <span class="math inline"><em>T</em></span> of time steps.</p>
<p>At each time step <span class="math inline"><em>t</em></span>, the car is characterized by a vector <span class="math inline">$\inputVector_{t} = (p_t,v_t)$</span> of states which are respectively the the position and velocity of the car at time <span class="math inline"><em>t</em></span>. For a sequence of states (an episode), the dynamics of the car is given by</p>
<p><br /><span class="math display">$$\inputVector_{t+1} = \mappingFunction(\inputVector_{t},\textbf{u}_{t})$$</span><br /></p>
<p>where <span class="math inline"><strong>u</strong><sub><em>t</em></sub></span> is the value of an action force, which in this example corresponds to push car to the left (negative value) or to the right (positive value). The actions across a full episode are represented in a policy <span class="math inline">$\textbf{u}_{t} = \pi(\inputVector_{t},\theta)$</span> that acts according to the current state of the car and some parameters <span class="math inline"><em>θ</em></span>. In the following examples we will assume that the policy is linear which allows us to write <span class="math inline">$\pi(\inputVector_{t},\theta)$</span> as</p>
<p><br /><span class="math display">$$\pi(\inputVector,\theta)= \theta_0 + \theta_p p + \theta_vv.$$</span><br /></p>
<p>For <span class="math inline"><em>t</em> = 1, …, <em>T</em></span> now given some initial state <span class="math inline">$\inputVector_{0}$</span> and some some values of each <span class="math inline"><strong>u</strong><sub><em>t</em></sub></span>, we can <strong>simulate</strong> the full dynamics of the car for a full episode using <a href="https://gym.openai.com/envs/">Gym</a>. The values of <span class="math inline"><strong>u</strong><sub><em>t</em></sub></span> are fully determined by the parameters of the linear controller.</p>
<p>After each episode of length <span class="math inline"><em>T</em></span> is complete, a reward function <span class="math inline"><em>R</em><sub><em>T</em></sub>(<em>θ</em>)</span> is computed. In the mountain car example the reward is computed as 100 for reaching the target of the hill on the right hand side, minus the squared sum of actions (a real negative to push to the left and a real positive to push to the right) from start to goal. Note that our reward depend on <span class="math inline"><em>θ</em></span> as we make it dependent on the parameters of the linear controller.</p>
<h2 id="emulate-the-mountain-car">Emulate the Mountain Car</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">import</span> gym</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1">env <span class="op">=</span> gym.make(<span class="st">&#39;MountainCarContinuous-v0&#39;</span>)</a></code></pre></div>
<p>Our goal in this section is to find the parameters <span class="math inline"><em>θ</em></span> of the linear controller such that</p>
<p><br /><span class="math display"><em>θ</em><sup>*</sup> = <em>a</em><em>r</em><em>g</em>max<sub><em>θ</em></sub><em>R</em><sub><em>T</em></sub>(<em>θ</em>).</span><br /></p>
<p>In this section, we directly use Bayesian optimization to solve this problem. We will use <a href="https://sheffieldml.github.io/GPyOpt/">GPyOpt</a> so we first define the objective function:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="im">import</span> mountain_car <span class="im">as</span> mc</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="im">import</span> GPyOpt</a></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1">obj_func <span class="op">=</span> <span class="kw">lambda</span> x: mc.run_simulation(env, x)[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">objective <span class="op">=</span> GPyOpt.core.task.SingleObjective(obj_func)</a></code></pre></div>
<p>For each set of parameter values of the linear controller we can run an episode of the simulator (that we fix to have a horizon of <span class="math inline"><em>T</em> = 500</span>) to generate the reward. Using as input the parameters of the controller and as outputs the rewards we can build a Gaussian process emulator of the reward.</p>
<p>We start defining the input space, which is three-dimensional:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co">## --- We define the input space of the emulator</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">space<span class="op">=</span> [{<span class="st">&#39;name&#39;</span>:<span class="st">&#39;postion_parameter&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="fl">1.2</span>, <span class="op">+</span><span class="dv">1</span>)},</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;velocity_parameter&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="fl">0.07</span>, <span class="op">+</span><span class="dv">1</span><span class="op">/</span><span class="fl">0.07</span>)},</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;constant&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="op">+</span><span class="dv">1</span>)}]</a>
<a class="sourceLine" id="cb5-6" data-line-number="6"></a>
<a class="sourceLine" id="cb5-7" data-line-number="7">design_space <span class="op">=</span> GPyOpt.Design_space(space<span class="op">=</span>space)</a></code></pre></div>
<p>Now we initizialize a Gaussian process emulator.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1">model <span class="op">=</span> GPyOpt.models.GPModel(optimize_restarts<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="va">False</span>, exact_feval<span class="op">=</span><span class="va">True</span>, ARD<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<p>In Bayesian optimization an acquisition function is used to balance exploration and exploitation to evaluate new locations close to the optimum of the objective. In this notebook we select the expected improvement (EI). For further details have a look to the review paper of <a href="http://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf">Shahriari et al (2015)</a>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" data-line-number="1">aquisition_optimizer <span class="op">=</span> GPyOpt.optimization.AcquisitionOptimizer(design_space)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">acquisition <span class="op">=</span> GPyOpt.acquisitions.AcquisitionEI(model, design_space, optimizer<span class="op">=</span>aquisition_optimizer)</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">evaluator <span class="op">=</span> GPyOpt.core.evaluators.Sequential(acquisition) <span class="co"># Collect points sequentially, no parallelization.</span></a></code></pre></div>
<p>To initalize the model we start sampling some initial points (25) for the linear controler randomly.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="im">from</span> GPyOpt.experiment_design.random_design <span class="im">import</span> RandomDesign</a></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" data-line-number="1">n_initial_points <span class="op">=</span> <span class="dv">25</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">random_design <span class="op">=</span> RandomDesign(design_space)</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">initial_design <span class="op">=</span> random_design.get_samples(n_initial_points)</a></code></pre></div>
<p>Before we start any optimization, lets have a look to the behavior of the car with the first of these initial points that we have selected randomly.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb11-1" data-line-number="1">random_controller <span class="op">=</span> initial_design[<span class="dv">0</span>,:]</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">_, _, _, frames <span class="op">=</span> mc.run_simulation(env, np.atleast_2d(random_controller), render<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3">anim<span class="op">=</span>mc.animate_frames(frames, <span class="st">&#39;Random linear controller&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="im">from</span> IPython.core.display <span class="im">import</span> HTML</a></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb13-1" data-line-number="1">HTML(anim.to_jshtml())</a></code></pre></div>
<div class="figure">
<div id="mountain-car-random-figure" class="figure-frame">
<iframe src="../slides/diagrams/uq/mountain_car_random.html" width="800px" height="600px" allowtransparency="true" frameborder="0">
</iframe>
</div>
<div id="mountain-car-random-magnify" class="magnify" onclick="magnifyFigure(&#39;mountain-car-random&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mountain-car-random-caption" class="caption-frame">
<p>Figure: Random linear controller for the Mountain car. It fails to move the car to the top of the mountain.</p>
</div>
</div>
<p>As we can see the random linear controller does not manage to push the car to the top of the mountain. Now, let’s optimize the regret using Bayesian optimization and the emulator for the reward. We try 50 new parameters chosen by the EI.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb14-1" data-line-number="1">max_iter <span class="op">=</span> <span class="dv">50</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2">bo <span class="op">=</span> GPyOpt.methods.ModularBayesianOptimization(model, design_space, objective, acquisition, evaluator, initial_design)</a>
<a class="sourceLine" id="cb14-3" data-line-number="3">bo.run_optimization(max_iter <span class="op">=</span> max_iter )</a></code></pre></div>
<p>Now we visualize the result for the best controller that we have found with Bayesian optimization.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb15-1" data-line-number="1">_, _, _, frames <span class="op">=</span> mc.run_simulation(env, np.atleast_2d(bo.x_opt), render<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb15-2" data-line-number="2">anim<span class="op">=</span>mc.animate_frames(frames, <span class="st">&#39;Best controller after 50 iterations of Bayesian optimization&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb16-1" data-line-number="1">HTML(anim.to_jshtml())</a></code></pre></div>
<div class="figure">
<div id="mountain-car-similated-bayes-opt-figure" class="figure-frame">
<iframe src="../slides/diagrams/uq/mountain_car_simulated.html" width="800px" height="600px" allowtransparency="true" frameborder="0">
</iframe>
</div>
<div id="mountain-car-similated-bayes-opt-magnify" class="magnify" onclick="magnifyFigure(&#39;mountain-car-similated-bayes-opt&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mountain-car-similated-bayes-opt-caption" class="caption-frame">
<p>Figure: Mountain car simulator trained using Bayesian optimization and the simulator of the dynamics. Fifty iterations of Bayesian optimization are used to optimize the controler.</p>
</div>
</div>
<p>he car can now make it to the top of the mountain! Emulating the reward function and using the EI helped as to find a linear controller that solves the problem.</p>
<h2 id="data-efficient-emulation-edit">Data Efficient Emulation <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/mountain-car-data-efficient.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/mountain-car-data-efficient.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>In the previous section we solved the mountain car problem by directly emulating the reward but no considerations about the dynamics <span class="math inline">$\inputVector_{t+1} = \mappingFunction(\inputVector_{t},\textbf{u}_{t})$</span> of the system were made. Note that we had to run 75 episodes of 500 steps each to solve the problem, which required to call the simulator <span class="math inline">500 × 75 = 37500</span> times. In this section we will show how it is possible to reduce this number by building an emulator for <span class="math inline"><em>f</em></span> that can later be used to directly optimize the control.</p>
<p>The inputs of the model for the dynamics are the velocity, the position and the value of the control so create this space accordingly.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="im">import</span> gym</a></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb18-1" data-line-number="1">env <span class="op">=</span> gym.make(<span class="st">&#39;MountainCarContinuous-v0&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="im">import</span> GPyOpt</a></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb20-1" data-line-number="1">space_dynamics <span class="op">=</span> [{<span class="st">&#39;name&#39;</span>:<span class="st">&#39;position&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:[<span class="op">-</span><span class="fl">1.2</span>, <span class="fl">+0.6</span>]},</a>
<a class="sourceLine" id="cb20-2" data-line-number="2">                  {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;velocity&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:[<span class="op">-</span><span class="fl">0.07</span>, <span class="fl">+0.07</span>]},</a>
<a class="sourceLine" id="cb20-3" data-line-number="3">                  {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;action&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:[<span class="op">-</span><span class="dv">1</span>, <span class="op">+</span><span class="dv">1</span>]}]</a>
<a class="sourceLine" id="cb20-4" data-line-number="4">design_space_dynamics <span class="op">=</span> GPyOpt.Design_space(space<span class="op">=</span>space_dynamics)</a></code></pre></div>
<p>The outputs are the velocity and the position. Indeed our model will capture the change in position and velocity on time. That is, we will model</p>
<p><br /><span class="math display"><em>Δ</em><em>v</em><sub><em>t</em> + 1</sub> = <em>v</em><sub><em>t</em> + 1</sub> − <em>v</em><sub><em>t</em></sub></span><br /></p>
<p><br /><span class="math display"><em>Δ</em><em>x</em><sub><em>t</em> + 1</sub> = <em>p</em><sub><em>t</em> + 1</sub> − <em>p</em><sub><em>t</em></sub></span><br /></p>
<p>with Gaussian processes with prior mean <span class="math inline"><em>v</em><sub><em>t</em></sub></span> and <span class="math inline"><em>p</em><sub><em>t</em></sub></span> respectively. As a covariance function, we use a Matern52. We need therefore two models to capture the full dynamics of the system.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb21-1" data-line-number="1">position_model <span class="op">=</span> GPyOpt.models.GPModel(optimize_restarts<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="va">False</span>, exact_feval<span class="op">=</span><span class="va">True</span>, ARD<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2">velocity_model <span class="op">=</span> GPyOpt.models.GPModel(optimize_restarts<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="va">False</span>, exact_feval<span class="op">=</span><span class="va">True</span>, ARD<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<p>Next, we sample some input parameters and use the simulator to compute the outputs. Note that in this case we are not running the full episodes, we are just using the simulator to compute <span class="math inline">$\inputVector_{t+1}$</span> given <span class="math inline">$\inputVector_{t}$</span> and <span class="math inline"><strong>u</strong><sub><em>t</em></sub></span>.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb22-2" data-line-number="2"><span class="im">from</span> GPyOpt.experiment_design.random_design <span class="im">import</span> RandomDesign</a>
<a class="sourceLine" id="cb22-3" data-line-number="3"><span class="im">import</span> mountain_car <span class="im">as</span> mc</a></code></pre></div>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="co">### --- Random locations of the inputs</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2">n_initial_points <span class="op">=</span> <span class="dv">500</span></a>
<a class="sourceLine" id="cb23-3" data-line-number="3">random_design_dynamics <span class="op">=</span> RandomDesign(design_space_dynamics)</a>
<a class="sourceLine" id="cb23-4" data-line-number="4">initial_design_dynamics <span class="op">=</span> random_design_dynamics.get_samples(n_initial_points)</a></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co">### --- Simulation of the (normalized) outputs</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2">y <span class="op">=</span> np.zeros((initial_design_dynamics.shape[<span class="dv">0</span>], <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb24-3" data-line-number="3"><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(initial_design_dynamics.shape[<span class="dv">0</span>]):</a>
<a class="sourceLine" id="cb24-4" data-line-number="4">    y[i, :] <span class="op">=</span> mc.simulation(initial_design_dynamics[i, :])</a>
<a class="sourceLine" id="cb24-5" data-line-number="5"></a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="co"># Normalize the data from the simulation</span></a>
<a class="sourceLine" id="cb24-7" data-line-number="7">y_normalisation <span class="op">=</span> np.std(y, axis<span class="op">=</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb24-8" data-line-number="8">y_normalised <span class="op">=</span> y<span class="op">/</span>y_normalisation</a></code></pre></div>
<p>In general we might use much smarter strategies to design our emulation of the simulator. For example, we could use the variance of the predictive distributions of the models to collect points using uncertainty sampling, which will give us a better coverage of the space. For simplicity, we move ahead with the 500 randomly selected points.</p>
<p>Now that we have a data set, we can update the emulators for the location and the velocity.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb25-1" data-line-number="1">position_model.updateModel(initial_design_dynamics, y[:, [<span class="dv">0</span>]], <span class="va">None</span>, <span class="va">None</span>)</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">velocity_model.updateModel(initial_design_dynamics, y[:, [<span class="dv">1</span>]], <span class="va">None</span>, <span class="va">None</span>)</a></code></pre></div>
<p>We can now have a look to how the emulator and the simulator match. First, we show a contour plot of the car aceleration for each pair of can position and velocity. You can use the bar bellow to play with the values of the controler to compare the emulator and the simulator.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="im">from</span> IPython.html.widgets <span class="im">import</span> interact</a></code></pre></div>
<p>We can see how the emulator is doing a fairly good job approximating the simulator. On the edges, however, it struggles to captures the dynamics of the simulator.</p>
<p>Given some input parameters of the linear controlling, how do the dynamics of the emulator and simulator match? In the following figure we show the position and velocity of the car for the 500 time steps of an episode in which the parameters of the linear controller have been fixed beforehand. The value of the input control is also shown.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb27-1" data-line-number="1">controller_gains <span class="op">=</span> np.atleast_2d([<span class="dv">0</span>, <span class="fl">.6</span>, <span class="dv">1</span>])  <span class="co"># change the valus of the linear controller to observe the trayectories.</span></a></code></pre></div>
<div class="figure">
<div id="emu-sim-comparison-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/emu_sim_comparison.svg" width="80%" style=" ">
</object>
</div>
<div id="emu-sim-comparison-magnify" class="magnify" onclick="magnifyFigure(&#39;emu-sim-comparison&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="emu-sim-comparison-caption" class="caption-frame">
<p>Figure: Comparison between the mountain car simulator and the emulator.</p>
</div>
</div>
<p>We now make explicit use of the emulator, using it to replace the simulator and optimize the linear controller. Note that in this optimization, we don’t need to query the simulator anymore as we can reproduce the full dynamics of an episode using the emulator. For illustrative purposes, in this example we fix the initial location of the car.</p>
<p>We define the objective reward function in terms of the simulator.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="co">### --- Optimize control parameters with emulator</span></a>
<a class="sourceLine" id="cb28-2" data-line-number="2">car_initial_location <span class="op">=</span> np.asarray([<span class="op">-</span><span class="fl">0.58912799</span>, <span class="dv">0</span>]) </a>
<a class="sourceLine" id="cb28-3" data-line-number="3"></a>
<a class="sourceLine" id="cb28-4" data-line-number="4"><span class="co">### --- Reward objective function using the emulator</span></a>
<a class="sourceLine" id="cb28-5" data-line-number="5">obj_func_emulator <span class="op">=</span> <span class="kw">lambda</span> x: mc.run_emulation([position_model, velocity_model], x, car_initial_location)[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb28-6" data-line-number="6">objective_emulator <span class="op">=</span> GPyOpt.core.task.SingleObjective(obj_func_emulator)</a></code></pre></div>
<p>And as before, we use Bayesian optimization to find the best possible linear controller.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="co">### --- Elements of the optimization that will use the multi-fidelity emulator</span></a>
<a class="sourceLine" id="cb29-2" data-line-number="2">model <span class="op">=</span> GPyOpt.models.GPModel(optimize_restarts<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="va">False</span>, exact_feval<span class="op">=</span><span class="va">True</span>, ARD<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<p>The design space is the three continuous variables that make up the linear controller.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb30-1" data-line-number="1">space<span class="op">=</span> [{<span class="st">&#39;name&#39;</span>:<span class="st">&#39;linear_1&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="fl">1.2</span>, <span class="op">+</span><span class="dv">1</span>)},</a>
<a class="sourceLine" id="cb30-2" data-line-number="2">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;linear_2&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="fl">0.07</span>, <span class="op">+</span><span class="dv">1</span><span class="op">/</span><span class="fl">0.07</span>)},</a>
<a class="sourceLine" id="cb30-3" data-line-number="3">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;constant&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="op">+</span><span class="dv">1</span>)}]</a>
<a class="sourceLine" id="cb30-4" data-line-number="4"></a>
<a class="sourceLine" id="cb30-5" data-line-number="5">design_space         <span class="op">=</span> GPyOpt.Design_space(space<span class="op">=</span>space)</a>
<a class="sourceLine" id="cb30-6" data-line-number="6">aquisition_optimizer <span class="op">=</span> GPyOpt.optimization.AcquisitionOptimizer(design_space)</a>
<a class="sourceLine" id="cb30-7" data-line-number="7"></a>
<a class="sourceLine" id="cb30-8" data-line-number="8">random_design <span class="op">=</span> RandomDesign(design_space)</a>
<a class="sourceLine" id="cb30-9" data-line-number="9">initial_design <span class="op">=</span> random_design.get_samples(<span class="dv">25</span>)</a></code></pre></div>
<p>We set the acquisition function to be expected improvement using <code>GPyOpt</code>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb31-1" data-line-number="1">acquisition          <span class="op">=</span> GPyOpt.acquisitions.AcquisitionEI(model, design_space, optimizer<span class="op">=</span>aquisition_optimizer)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2">evaluator            <span class="op">=</span> GPyOpt.core.evaluators.Sequential(acquisition)</a></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb32-1" data-line-number="1">bo_emulator <span class="op">=</span> GPyOpt.methods.ModularBayesianOptimization(model, design_space, objective_emulator, acquisition, evaluator, initial_design)</a>
<a class="sourceLine" id="cb32-2" data-line-number="2">bo_emulator.run_optimization(max_iter<span class="op">=</span><span class="dv">50</span>)</a></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb33-1" data-line-number="1">_, _, _, frames <span class="op">=</span> mc.run_simulation(env, np.atleast_2d(bo_emulator.x_opt), render<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb33-2" data-line-number="2">anim<span class="op">=</span>mc.animate_frames(frames, <span class="st">&#39;Best controller using the emulator of the dynamics&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="im">from</span> IPython.core.display <span class="im">import</span> HTML</a></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb35-1" data-line-number="1">HTML(anim.to_jshtml())</a></code></pre></div>
<div class="figure">
<div id="mountain-car-emulated-figure" class="figure-frame">
<iframe src="../slides/diagrams/uq/mountain_car_emulated.html" width="800px" height="600px" allowtransparency="true" frameborder="0">
</iframe>
</div>
<div id="mountain-car-emulated-magnify" class="magnify" onclick="magnifyFigure(&#39;mountain-car-emulated&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mountain-car-emulated-caption" class="caption-frame">
<p>Figure: Mountain car controller learnt through emulation. Here 500 calls to the simulator are used to fit the controller rather than 37,500 calls to the simulator required in the standard learning.</p>
</div>
</div>
<p>And the problem is again solved, but in this case we have replaced the simulator of the car dynamics by a Gaussian process emulator that we learned by calling the simulator only 500 times. Compared to the 37500 calls that we needed when applying Bayesian optimization directly on the simulator this is a great gain.</p>
<h2 id="multi-fidelity-emulation-edit">Multi-Fidelity Emulation <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/mountain-car-multi-fidelity.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/mountain-car-multi-fidelity.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>In some scenarios we have simulators of the same environment that have different fidelities, that is that reflect with different level of accuracy the dynamics of the real world. Running simulations of the different fidelities also have a different cost: hight fidelity simulations are more expensive the cheaper ones. If we have access to these simulators we can combine high and low fidelity simulations under the same model.</p>
<p>So let’s assume that we have two simulators of the mountain car dynamics, one of high fidelity (the one we have used) and another one of low fidelity. The traditional approach to this form of multi-fidelity emulation is to assume that</p>
<p><br /><span class="math display">$$\mappingFunction_i\left(\inputVector\right) = \rho\mappingFunction_{i-1}\left(\inputVector\right) + \delta_i\left(\inputVector \right)$$</span><br /></p>
<p>where <span class="math inline">$\mappingFunction_{i-1}\left(\inputVector\right)$</span> is a low fidelity simulation of the problem of interest and <span class="math inline">$\mappingFunction_i\left(\inputVector\right)$</span> is a higher fidelity simulation. The function <span class="math inline">$\delta_i\left(\inputVector \right)$</span> represents the difference between the lower and higher fidelity simulation, which is considered additive. The additive form of this covariance means that if <span class="math inline">$\mappingFunction_{0}\left(\inputVector\right)$</span> and <span class="math inline">$\left\{\delta_i\left(\inputVector \right)\right\}_{i=1}^m$</span> are all Gaussian processes, then the process over all fidelities of simuation will be a joint Gaussian process.</p>
<p>But with Deep Gaussian processes we can consider the form</p>
<p><br /><span class="math display">$$\mappingFunction_i\left(\inputVector\right) = \mappingFunctionTwo_{i}\left(\mappingFunction_{i-1}\left(\inputVector\right)\right) + \delta_i\left(\inputVector \right),$$</span><br /></p>
<p>where the low fidelity representation is non linearly transformed by <span class="math inline">$\mappingFunctionTwo(\cdot)$</span> before use in the process. This is the approach taken in <span class="citation" data-cites="Perdikaris:multifidelity17">Perdikaris et al. (2017)</span>. But once we accept that these models can be composed, a highly flexible framework can emerge. A key point is that the data enters the model at different levels, and represents different aspects. For example these correspond to the two fidelities of the mountain car simulator.</p>
<p>We start by sampling both of them at 250 random input locations.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb36-1" data-line-number="1"><span class="im">import</span> gym</a></code></pre></div>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb37-1" data-line-number="1">env <span class="op">=</span> gym.make(<span class="st">&#39;MountainCarContinuous-v0&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb38-1" data-line-number="1"><span class="im">import</span> GPyOpt</a></code></pre></div>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="co">### --- Collect points from low and high fidelity simulator --- </span><span class="al">###</span></a>
<a class="sourceLine" id="cb39-2" data-line-number="2"></a>
<a class="sourceLine" id="cb39-3" data-line-number="3">space <span class="op">=</span> GPyOpt.Design_space([</a>
<a class="sourceLine" id="cb39-4" data-line-number="4">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;position&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="fl">1.2</span>, <span class="op">+</span><span class="dv">1</span>)},</a>
<a class="sourceLine" id="cb39-5" data-line-number="5">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;velocity&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="fl">0.07</span>, <span class="fl">+0.07</span>)},</a>
<a class="sourceLine" id="cb39-6" data-line-number="6">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;action&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="op">+</span><span class="dv">1</span>)}])</a>
<a class="sourceLine" id="cb39-7" data-line-number="7"></a>
<a class="sourceLine" id="cb39-8" data-line-number="8">n_points <span class="op">=</span> <span class="dv">250</span></a>
<a class="sourceLine" id="cb39-9" data-line-number="9">random_design <span class="op">=</span> GPyOpt.experiment_design.RandomDesign(space)</a>
<a class="sourceLine" id="cb39-10" data-line-number="10">x_random <span class="op">=</span> random_design.get_samples(n_points)</a></code></pre></div>
<p>Next, we evaluate the high and low fidelity simualtors at those locations.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb40-2" data-line-number="2"><span class="im">import</span> mountain_car <span class="im">as</span> mc</a></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb41-1" data-line-number="1">d_position_hf <span class="op">=</span> np.zeros((n_points, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb41-2" data-line-number="2">d_velocity_hf <span class="op">=</span> np.zeros((n_points, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb41-3" data-line-number="3">d_position_lf <span class="op">=</span> np.zeros((n_points, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb41-4" data-line-number="4">d_velocity_lf <span class="op">=</span> np.zeros((n_points, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb41-5" data-line-number="5"></a>
<a class="sourceLine" id="cb41-6" data-line-number="6"><span class="co"># --- Collect high fidelity points</span></a>
<a class="sourceLine" id="cb41-7" data-line-number="7"><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n_points):</a>
<a class="sourceLine" id="cb41-8" data-line-number="8">    d_position_hf[i], d_velocity_hf[i] <span class="op">=</span> mc.simulation(x_random[i, :])</a>
<a class="sourceLine" id="cb41-9" data-line-number="9"></a>
<a class="sourceLine" id="cb41-10" data-line-number="10"><span class="co"># --- Collect low fidelity points  </span></a>
<a class="sourceLine" id="cb41-11" data-line-number="11"><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n_points):</a>
<a class="sourceLine" id="cb41-12" data-line-number="12">    d_position_lf[i], d_velocity_lf[i] <span class="op">=</span> mc.low_cost_simulation(x_random[i, :])</a></code></pre></div>
<p>It is time to build the multi-fidelity model for both the position and the velocity.</p>
<p>As we did in the previous section we use the emulator to optimize the simulator. In this case we use the high fidelity output of the emulator.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb42-1" data-line-number="1"><span class="co">### --- Optimize controller parameters </span></a>
<a class="sourceLine" id="cb42-2" data-line-number="2">obj_func <span class="op">=</span> <span class="kw">lambda</span> x: mc.run_simulation(env, x)[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb42-3" data-line-number="3">obj_func_emulator <span class="op">=</span> <span class="kw">lambda</span> x: mc.run_emulation([position_model, velocity_model], x, car_initial_location)[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb42-4" data-line-number="4">objective_multifidelity <span class="op">=</span> GPyOpt.core.task.SingleObjective(obj_func)</a></code></pre></div>
<p>And we optimize using Bayesian optimzation.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="im">from</span> GPyOpt.experiment_design.random_design <span class="im">import</span> RandomDesign</a></code></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb44-1" data-line-number="1">model <span class="op">=</span> GPyOpt.models.GPModel(optimize_restarts<span class="op">=</span><span class="dv">5</span>, verbose<span class="op">=</span><span class="va">False</span>, exact_feval<span class="op">=</span><span class="va">True</span>, ARD<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb44-2" data-line-number="2">space<span class="op">=</span> [{<span class="st">&#39;name&#39;</span>:<span class="st">&#39;linear_1&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="fl">1.2</span>, <span class="op">+</span><span class="dv">1</span>)},</a>
<a class="sourceLine" id="cb44-3" data-line-number="3">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;linear_2&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="fl">0.07</span>, <span class="op">+</span><span class="dv">1</span><span class="op">/</span><span class="fl">0.07</span>)},</a>
<a class="sourceLine" id="cb44-4" data-line-number="4">        {<span class="st">&#39;name&#39;</span>:<span class="st">&#39;constant&#39;</span>, <span class="st">&#39;type&#39;</span>:<span class="st">&#39;continuous&#39;</span>, <span class="st">&#39;domain&#39;</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="op">+</span><span class="dv">1</span>)}]</a>
<a class="sourceLine" id="cb44-5" data-line-number="5"></a>
<a class="sourceLine" id="cb44-6" data-line-number="6">design_space <span class="op">=</span> GPyOpt.Design_space(space<span class="op">=</span>space)</a>
<a class="sourceLine" id="cb44-7" data-line-number="7">aquisition_optimizer <span class="op">=</span> GPyOpt.optimization.AcquisitionOptimizer(design_space)</a>
<a class="sourceLine" id="cb44-8" data-line-number="8"></a>
<a class="sourceLine" id="cb44-9" data-line-number="9">n_initial_points <span class="op">=</span> <span class="dv">25</span></a>
<a class="sourceLine" id="cb44-10" data-line-number="10">random_design <span class="op">=</span> RandomDesign(design_space)</a>
<a class="sourceLine" id="cb44-11" data-line-number="11">initial_design <span class="op">=</span> random_design.get_samples(n_initial_points)</a>
<a class="sourceLine" id="cb44-12" data-line-number="12">acquisition <span class="op">=</span> GPyOpt.acquisitions.AcquisitionEI(model, design_space, optimizer<span class="op">=</span>aquisition_optimizer)</a>
<a class="sourceLine" id="cb44-13" data-line-number="13">evaluator <span class="op">=</span> GPyOpt.core.evaluators.Sequential(acquisition)</a></code></pre></div>
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb45-1" data-line-number="1">bo_multifidelity <span class="op">=</span> GPyOpt.methods.ModularBayesianOptimization(model, design_space, objective_multifidelity, acquisition, evaluator, initial_design)</a>
<a class="sourceLine" id="cb45-2" data-line-number="2">bo_multifidelity.run_optimization(max_iter<span class="op">=</span><span class="dv">50</span>)</a></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb46-1" data-line-number="1">_, _, _, frames <span class="op">=</span> mc.run_simulation(env, np.atleast_2d(bo_multifidelity.x_opt), render<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb46-2" data-line-number="2">anim<span class="op">=</span>mc.animate_frames(frames, <span class="st">&#39;Best controller with multi-fidelity emulator&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="im">from</span> IPython.core.display <span class="im">import</span> HTML</a></code></pre></div>
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb48-1" data-line-number="1">HTML(anim.to_jshtml())</a></code></pre></div>
<h3 id="best-controller-with-multi-fidelity-emulator">Best Controller with Multi-Fidelity Emulator</h3>
<div class="figure">
<div id="mountain-car-multi-fidelity-figure" class="figure-frame">
<iframe src="../slides/diagrams/uq/mountain_car_multi_fidelity.html" width="800px" height="600px" allowtransparency="true" frameborder="0">
</iframe>
</div>
<div id="mountain-car-multi-fidelity-magnify" class="magnify" onclick="magnifyFigure(&#39;mountain-car-multi-fidelity&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mountain-car-multi-fidelity-caption" class="caption-frame">
<p>Figure: Mountain car learnt with multi-fidelity model. Here 250 observations of the high fidelity simulator and 250 observations of the low fidelity simulator are used to learn the controller.</p>
</div>
</div>
<p>And problem solved! We see how the problem is also solved with 250 observations of the high fidelity simulator and 250 of the low fidelity simulator.</p>
<h2 id="emukit-edit">Emukit <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="emukit-software-page-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/uq/emukit-software-page.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-software-page-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-software-page&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="emukit-software-page-caption" class="caption-frame">
<p>Figure: The Emukit software is a set of software tools for emulation and surrogate modeling. <a href="https://amzn.github.io/emukit/" class="uri">https://amzn.github.io/emukit/</a></p>
</div>
</div>
<p>The aim is to provide a suite where different approaches to emulation are assimilated under one roof. The current version of Emukit includes <em>multi-fidelity emulation</em> for build surrogate models when data is obtained from multiple information sources that have different fidelity and/or cost; <em>Bayesian optimisation</em> for optimising physical experiments and tune parameters of machine learning algorithms or other computational simulations; <em>experimental design and active learning</em>: design the most informative experiments and perform active learning with machine learning models; <em>sensitivity analysis</em>: analyse the influence of inputs on the outputs of a given system; and <em>Bayesian quadrature</em>: efficiently compute the integrals of functions that are expensive to evaluate.</p>
<h2 id="mxfusion-modular-probabilistic-programming-on-mxnet-edit">MXFusion: Modular Probabilistic Programming on MXNet <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/mxfusion-intro.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/mxfusion-intro.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>One challenge for practitioners in Gaussian processes, is flexible software that allows the construction of the relevant GP modle. With this in mind, the Amazon Cambridge team has developed MXFusion. It is a modular probabilistic programming language focussed on efficient implementation of hybrid GP-neural network models, but with additional probabilistic programming capabilities.</p>
<div class="figure">
<div id="mxfusion-software-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/mxfusion.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="mxfusion-software-magnify" class="magnify" onclick="magnifyFigure(&#39;mxfusion-software&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mxfusion-software-caption" class="caption-frame">
<p>Figure: MXFusion is a probabilistic programming language targeted specifically at Gaussian process models and combining them with probaiblistic neural network. It is available through the MIT license and we welcome contributions throguh the Github repository <a href="https://github.com/amzn/MXFusion" class="uri">https://github.com/amzn/MXFusion</a>.</p>
</div>
</div>
<p>We developed the framework for greater ease of transitioning models from ‘science’ to ‘production’, our aim was to have code that could be created by scientists, but deployed in our systems through solutions such as AWS SageMaker.</p>
<div class="figure">
<div id="mxfusion-software-logo-figure" class="figure-frame">
<table>
<tr>
<td width="70%">
<ul>
<li>Work by Eric Meissner and Zhenwen Dai.</li>
<li>Probabilistic programming.</li>
<li>Available on <a href="https://github.com/amzn/mxfusion">Github</a></li>
</ul>
</td>
<td width="30%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/mxfusion-logo.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="mxfusion-software-logo-magnify" class="magnify" onclick="magnifyFigure(&#39;mxfusion-software-logo&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="mxfusion-software-logo-caption" class="caption-frame">
<p>Figure: The MXFusion software.</p>
</div>
</div>
<h2 id="mxfusion">MxFusion</h2>
<h2 id="why-another-framework">Why another framework?</h2>
<h2 id="key-requirements">Key Requirements</h2>
<p>Specialized inference methods + models, without requiring users to reimplement nor understand them every time. Leverage expert knowledge. Efficient inference, flexible framework. Existing frameworks either did one or the other: flexible, or efficient.</p>
<h2 id="what-does-it-look-like">What does it look like?</h2>
<p><strong>Modelling</strong></p>
<p><strong>Inference</strong></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb49-1" data-line-number="1">m <span class="op">=</span> Model()</a>
<a class="sourceLine" id="cb49-2" data-line-number="2">m.mu <span class="op">=</span> Variable()</a>
<a class="sourceLine" id="cb49-3" data-line-number="3">m.s <span class="op">=</span> Variable(transformation<span class="op">=</span>PositiveTransformation())</a>
<a class="sourceLine" id="cb49-4" data-line-number="4">m.Y <span class="op">=</span> Normal.define_variable(mean<span class="op">=</span>m.mu, variance<span class="op">=</span>m.s)</a></code></pre></div>
<ul>
<li>Variable</li>
<li>Distribution</li>
<li><p>Function</p></li>
<li><code>log_pdf</code></li>
<li><p><code>draw_samples</code></p></li>
<li>Variational Inference</li>
<li><p>MCMC Sampling (<em>soon</em>) Built on MXNet Gluon (imperative code, not static graph)</p></li>
</ul>
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb50-1" data-line-number="1">infr <span class="op">=</span> GradBasedInference(inference_algorithm<span class="op">=</span>MAP(model<span class="op">=</span>m, observed<span class="op">=</span>[m.Y]))</a>
<a class="sourceLine" id="cb50-2" data-line-number="2">infr.run(Y<span class="op">=</span>data)</a></code></pre></div>
<ul>
<li>Model + Inference together form building blocks.
<ul>
<li>Just doing modular modeling with universal inference doesn’t really scale, need specialized inference methods for specialized modelling objects like non-parametrics.</li>
</ul></li>
</ul>
<h2 id="pilco-a-model-based-policy-search-edit">PILCO: A Model-based Policy Search <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/mxfusion-pilco.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/mxfusion-pilco.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Common reinforcement learning methods suffer from data inefficiency, which can be a issue in real world applications where gathering sufficiently large amounts of data pose economic issues and may be impossible. propose a model-based policy search method known as PILCO in part to address this issue. PILCO uses a Gaussian process (GP) for learning the dynamics of the environment and optimizes a parametric policy function using the learned dynamics model.</p>
<p>We construct an implementation of PILCO using MXFusion. This implementation follows the main idea of PILCO and has a few enhancements in addition to the published implementation. The enhancements are as follows: * <strong>Use Monte Carlo integration instead of moment estimation.</strong> We approximate the expected reward using Monte Carlo integration instead of the proposed moment estimation approach. This removes the bias in the expected reward computation and enables a wide range of choices of kernels and policy functions. In the original work, only RBF and linear kernel and only linear and RBF network policy can be used. * <strong>Use automatic differentiation.</strong> Thanks to automatic differentiation, no gradient derivation is needed. * <strong>A unified interface of Gaussian process.</strong> MXFusion provides an unified inferface of GP modules. We allows us to easily switch among plan GP, variational sparse GP and stocastic variational GP implementations.</p>
<p>This notebook depends on MXNet, MXFusion and Open AI Gym. These packages can be installed into your Python environment by running the following commands.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="ex">pip</span> install mxnet mxfusion gym</a></code></pre></div>
<p>Set the global configuration.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb52-1" data-line-number="1"><span class="im">import</span> os</a>
<a class="sourceLine" id="cb52-2" data-line-number="2">os.environ[<span class="st">&#39;MXNET_ENGINE_TYPE&#39;</span>] <span class="op">=</span> <span class="st">&#39;NaiveEngine&#39;</span></a>
<a class="sourceLine" id="cb52-3" data-line-number="3"><span class="im">from</span> mxfusion.common <span class="im">import</span> config</a>
<a class="sourceLine" id="cb52-4" data-line-number="4">config.DEFAULT_DTYPE <span class="op">=</span> <span class="st">&#39;float64&#39;</span></a>
<a class="sourceLine" id="cb52-5" data-line-number="5"><span class="op">%</span>matplotlib inline</a></code></pre></div>
<p>We use the inverted pendulum swingup problem as an example. We use the <a href="https://gym.openai.com/envs/Pendulum-v0/">Pendulum-v0</a> environment in Open AI Gym. The task is to swing the pendulum up and balance it at the inverted position. This is a classical control problem and is known to be unsolvable with a linear controller.</p>
<p>To solve this problem with PILCO, we need three components:</p>
<ul>
<li>Execute a policy in an real environment (an Open AI Gym simulator in this example) and collect data.</li>
<li>Fit a GP model as the model for the dynamics of the environment.</li>
<li>Optimize the policy given the dynamics model learned from all the data that have been collected so far.</li>
</ul>
<p>The overall PILCO algorithm is to iterate the above three steps until a policy that can solve the problem is found.</p>
<h2 id="execute-the-environment">Execute the Environment</h2>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb53-1" data-line-number="1"><span class="im">import</span> gym</a>
<a class="sourceLine" id="cb53-2" data-line-number="2">env <span class="op">=</span> gym.make(<span class="st">&#39;Pendulum-v0&#39;</span>)</a></code></pre></div>
<p>The state of the pendulum environment is a 3D vector. The first two dimensions are the 2D location of the end point of the pendulum. The third dimension encodes the angular speed of the pendulum. The action space is a 1D vector in [-2, 2].</p>
<p>We write a helper function for executing the environment with a given policy.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb54-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb54-2" data-line-number="2"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb54-3" data-line-number="3"><span class="im">from</span> matplotlib <span class="im">import</span> animation</a></code></pre></div>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb55-1" data-line-number="1"><span class="kw">def</span> run_one_episode(env, policy, initial_state<span class="op">=</span><span class="va">None</span>, max_steps<span class="op">=</span><span class="dv">200</span>, verbose<span class="op">=</span><span class="va">False</span>, render<span class="op">=</span><span class="va">False</span>):</a>
<a class="sourceLine" id="cb55-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb55-3" data-line-number="3"><span class="co">    Drives an episode of the OpenAI gym environment using the policy to decide next actions.</span></a>
<a class="sourceLine" id="cb55-4" data-line-number="4"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb55-5" data-line-number="5">    observation <span class="op">=</span> env.reset()</a>
<a class="sourceLine" id="cb55-6" data-line-number="6">    <span class="cf">if</span> initial_state <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</a>
<a class="sourceLine" id="cb55-7" data-line-number="7">        env.env.state <span class="op">=</span> initial_state</a>
<a class="sourceLine" id="cb55-8" data-line-number="8">        observation <span class="op">=</span> env.env._get_obs()</a>
<a class="sourceLine" id="cb55-9" data-line-number="9">    env._max_episode_steps <span class="op">=</span> max_steps</a>
<a class="sourceLine" id="cb55-10" data-line-number="10">    step_idx <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb55-11" data-line-number="11">    done <span class="op">=</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb55-12" data-line-number="12">    total_reward <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb55-13" data-line-number="13">    frames <span class="op">=</span> []</a>
<a class="sourceLine" id="cb55-14" data-line-number="14">    all_actions <span class="op">=</span> []</a>
<a class="sourceLine" id="cb55-15" data-line-number="15">    all_observations <span class="op">=</span> [observation]</a>
<a class="sourceLine" id="cb55-16" data-line-number="16">    <span class="cf">while</span> <span class="kw">not</span> done:</a>
<a class="sourceLine" id="cb55-17" data-line-number="17">        <span class="cf">if</span> render:</a>
<a class="sourceLine" id="cb55-18" data-line-number="18">            frames.append(env.render(mode <span class="op">=</span> <span class="st">&#39;rgb_array&#39;</span>))</a>
<a class="sourceLine" id="cb55-19" data-line-number="19">        <span class="cf">if</span> verbose:</a>
<a class="sourceLine" id="cb55-20" data-line-number="20">            <span class="bu">print</span>(observation)</a>
<a class="sourceLine" id="cb55-21" data-line-number="21">        action <span class="op">=</span> policy(observation)</a>
<a class="sourceLine" id="cb55-22" data-line-number="22">        observation, reward, done, info <span class="op">=</span> env.step(action)</a>
<a class="sourceLine" id="cb55-23" data-line-number="23">        all_observations.append(observation)</a>
<a class="sourceLine" id="cb55-24" data-line-number="24">        all_actions.append(action)</a>
<a class="sourceLine" id="cb55-25" data-line-number="25">        total_reward <span class="op">+=</span> reward</a>
<a class="sourceLine" id="cb55-26" data-line-number="26">        step_idx <span class="op">+=</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb55-27" data-line-number="27">        <span class="cf">if</span> done <span class="kw">or</span> step_idx<span class="op">&gt;=</span>max_steps<span class="dv">-1</span>:</a>
<a class="sourceLine" id="cb55-28" data-line-number="28">            <span class="bu">print</span>(<span class="st">&quot;Episode finished after </span><span class="sc">{}</span><span class="st"> timesteps because </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(step_idx<span class="op">+</span><span class="dv">1</span>, <span class="st">&quot;&#39;done&#39; reached&quot;</span> <span class="cf">if</span> done <span class="cf">else</span> <span class="st">&quot;Max timesteps reached&quot;</span>))</a>
<a class="sourceLine" id="cb55-29" data-line-number="29">            <span class="cf">break</span></a>
<a class="sourceLine" id="cb55-30" data-line-number="30">    <span class="cf">if</span> render:</a>
<a class="sourceLine" id="cb55-31" data-line-number="31">        fig <span class="op">=</span> plt.figure()</a>
<a class="sourceLine" id="cb55-32" data-line-number="32">        ax <span class="op">=</span> fig.gca()</a>
<a class="sourceLine" id="cb55-33" data-line-number="33">        fig.tight_layout()</a>
<a class="sourceLine" id="cb55-34" data-line-number="34">        patch <span class="op">=</span> ax.imshow(frames[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb55-35" data-line-number="35">        ax.axis(<span class="st">&#39;off&#39;</span>)</a>
<a class="sourceLine" id="cb55-36" data-line-number="36">        <span class="kw">def</span> animate(i):</a>
<a class="sourceLine" id="cb55-37" data-line-number="37">            patch.set_data(frames[i])</a>
<a class="sourceLine" id="cb55-38" data-line-number="38">        anim <span class="op">=</span> animation.FuncAnimation(plt.gcf(), animate, frames <span class="op">=</span> <span class="bu">len</span>(frames), interval<span class="op">=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb55-39" data-line-number="39">        <span class="cf">return</span> total_reward, np.array(all_observations, dtype<span class="op">=</span>np.float64,), np.array(all_actions, dtype<span class="op">=</span>np.float64), anim</a>
<a class="sourceLine" id="cb55-40" data-line-number="40">    <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb55-41" data-line-number="41">        <span class="cf">return</span> total_reward, np.array(all_observations, dtype<span class="op">=</span>np.float64,), np.array(all_actions, dtype<span class="op">=</span>np.float64)</a></code></pre></div>
<p>We first apply a random policy and see how the environment reacts. The random policy uniformly samples in the space of action.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb56-1" data-line-number="1"><span class="kw">def</span> random_policy(state):</a>
<a class="sourceLine" id="cb56-2" data-line-number="2">    <span class="cf">return</span> env.action_space.sample()</a></code></pre></div>
<p>The animation is generated with the following commands:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb57-1" data-line-number="1">anim <span class="op">=</span> run_one_episode(env, random_policy, max_steps<span class="op">=</span><span class="dv">500</span>, render<span class="op">=</span><span class="va">True</span>, verbose<span class="op">=</span><span class="va">False</span>)[<span class="op">-</span><span class="dv">1</span>]</a>
<a class="sourceLine" id="cb57-2" data-line-number="2"></a>
<a class="sourceLine" id="cb57-3" data-line-number="3"><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&#39;animation_random_policy.html&#39;</span>, <span class="st">&#39;w&#39;</span>) <span class="im">as</span> f:</a>
<a class="sourceLine" id="cb57-4" data-line-number="4">    f.write(anim.to_jshtml())</a></code></pre></div>
<h2 id="pendulum">Pendulum</h2>
<div class="figure">
<div id="pendulum-random-policy-figure" class="figure-frame">
<iframe src="../slides/diagrams/ml/animation_random_policy.html" width="100%" height="auto" allowtransparency="true" frameborder="0">
</iframe>
</div>
<div id="pendulum-random-policy-magnify" class="magnify" onclick="magnifyFigure(&#39;pendulum-random-policy&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="pendulum-random-policy-caption" class="caption-frame">
<p>Figure: Random policy for the control of the pendulum.</p>
</div>
</div>
<p>The dynamics model of pendulum can be written as <br /><span class="math display">$$
p(\dataScalar_{t+1}|\dataScalar_t, a_t)
$$</span><br /> where <span class="math inline">$\dataScalar_t$</span> is the state vector at the time <span class="math inline"><em>t</em></span> and <span class="math inline"><em>a</em><sub><em>t</em></sub></span> is the action taken at the time <span class="math inline"><em>t</em></span>.</p>
<p>PILCO uses a Gaussian process to model the above dynamics.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb58-1" data-line-number="1"><span class="kw">def</span> prepare_data(state_list, action_list, win_in):</a>
<a class="sourceLine" id="cb58-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb58-3" data-line-number="3"><span class="co">    Prepares a list of states and a list of actions as inputs to the Gaussian Process for training.</span></a>
<a class="sourceLine" id="cb58-4" data-line-number="4"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb58-5" data-line-number="5">    </a>
<a class="sourceLine" id="cb58-6" data-line-number="6">    X_list <span class="op">=</span> []</a>
<a class="sourceLine" id="cb58-7" data-line-number="7">    Y_list <span class="op">=</span> []</a>
<a class="sourceLine" id="cb58-8" data-line-number="8">    </a>
<a class="sourceLine" id="cb58-9" data-line-number="9">    <span class="cf">for</span> state_array, action_array <span class="kw">in</span> <span class="bu">zip</span>(state_list, action_list):</a>
<a class="sourceLine" id="cb58-10" data-line-number="10">        <span class="co"># the state and action array shape should be aligned.</span></a>
<a class="sourceLine" id="cb58-11" data-line-number="11">        <span class="cf">assert</span> state_array.shape[<span class="dv">0</span>]<span class="op">-</span><span class="dv">1</span> <span class="op">==</span> action_array.shape[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb58-12" data-line-number="12">        </a>
<a class="sourceLine" id="cb58-13" data-line-number="13">        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(state_array.shape[<span class="dv">0</span>]<span class="op">-</span>win_in):</a>
<a class="sourceLine" id="cb58-14" data-line-number="14">            Y_list.append(state_array[i<span class="op">+</span>win_in:i<span class="op">+</span>win_in<span class="op">+</span><span class="dv">1</span>])</a>
<a class="sourceLine" id="cb58-15" data-line-number="15">            X_list.append(np.hstack([state_array[i:i<span class="op">+</span>win_in].flatten(), action_array[i:i<span class="op">+</span>win_in].flatten()]))</a>
<a class="sourceLine" id="cb58-16" data-line-number="16">    X <span class="op">=</span> np.vstack(X_list)</a>
<a class="sourceLine" id="cb58-17" data-line-number="17">    Y <span class="op">=</span> np.vstack(Y_list)</a>
<a class="sourceLine" id="cb58-18" data-line-number="18">    <span class="cf">return</span> X, Y</a></code></pre></div>
<p>In this example, we do a maximum likelihood estimate for the model hyper- parameters. In <code>MXFusion</code>, Gaussian process regression model is available as a module, which includes a dediated inference algorithm.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb59-1" data-line-number="1"><span class="im">import</span> mxnet <span class="im">as</span> mx</a>
<a class="sourceLine" id="cb59-2" data-line-number="2"><span class="im">from</span> mxfusion <span class="im">import</span> Model, Variable</a>
<a class="sourceLine" id="cb59-3" data-line-number="3"><span class="im">from</span> mxfusion.components.variables <span class="im">import</span> PositiveTransformation</a>
<a class="sourceLine" id="cb59-4" data-line-number="4"><span class="im">from</span> mxfusion.components.distributions.gp.kernels <span class="im">import</span> RBF</a>
<a class="sourceLine" id="cb59-5" data-line-number="5"><span class="im">from</span> mxfusion.modules.gp_modules <span class="im">import</span> GPRegression</a>
<a class="sourceLine" id="cb59-6" data-line-number="6"><span class="im">from</span> mxfusion.inference <span class="im">import</span> GradBasedInference, MAP</a></code></pre></div>
<h2 id="define-and-fit-the-model">Define and fit the model</h2>
<div class="sourceCode" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb60-1" data-line-number="1"><span class="kw">def</span> fit_model(state_list, action_list, win_in, verbose<span class="op">=</span><span class="va">True</span>):</a>
<a class="sourceLine" id="cb60-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb60-3" data-line-number="3"><span class="co">    Fits a Gaussian Process model to the state / action pairs passed in. </span></a>
<a class="sourceLine" id="cb60-4" data-line-number="4"><span class="co">    This creates a model of the environment which is used during</span></a>
<a class="sourceLine" id="cb60-5" data-line-number="5"><span class="co">    policy optimization instead of querying the environment directly.</span></a>
<a class="sourceLine" id="cb60-6" data-line-number="6"><span class="co">    </span></a>
<a class="sourceLine" id="cb60-7" data-line-number="7"><span class="co">    See mxfusion.gp_modules for additional types of GP models to fit,</span></a>
<a class="sourceLine" id="cb60-8" data-line-number="8"><span class="co">    including Sparse GP and Stochastic Varitional Inference Sparse GP.</span></a>
<a class="sourceLine" id="cb60-9" data-line-number="9"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb60-10" data-line-number="10">    X, Y <span class="op">=</span> prepare_data(state_list, action_list, win_in)</a>
<a class="sourceLine" id="cb60-11" data-line-number="11"></a>
<a class="sourceLine" id="cb60-12" data-line-number="12">    m <span class="op">=</span> Model()</a>
<a class="sourceLine" id="cb60-13" data-line-number="13">    m.N <span class="op">=</span> Variable()</a>
<a class="sourceLine" id="cb60-14" data-line-number="14">    m.X <span class="op">=</span> Variable(shape<span class="op">=</span>(m.N, X.shape[<span class="op">-</span><span class="dv">1</span>]))</a>
<a class="sourceLine" id="cb60-15" data-line-number="15">    m.noise_var <span class="op">=</span> Variable(shape<span class="op">=</span>(<span class="dv">1</span>,), transformation<span class="op">=</span>PositiveTransformation(),</a>
<a class="sourceLine" id="cb60-16" data-line-number="16">                           initial_value<span class="op">=</span><span class="fl">0.01</span>)</a>
<a class="sourceLine" id="cb60-17" data-line-number="17">    m.kernel <span class="op">=</span> RBF(input_dim<span class="op">=</span>X.shape[<span class="op">-</span><span class="dv">1</span>], variance<span class="op">=</span><span class="dv">1</span>, lengthscale<span class="op">=</span><span class="dv">1</span>, ARD<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb60-18" data-line-number="18">    m.Y <span class="op">=</span> GPRegression.define_variable(</a>
<a class="sourceLine" id="cb60-19" data-line-number="19">        X<span class="op">=</span>m.X, kernel<span class="op">=</span>m.kernel, noise_var<span class="op">=</span>m.noise_var,</a>
<a class="sourceLine" id="cb60-20" data-line-number="20">        shape<span class="op">=</span>(m.N, Y.shape[<span class="op">-</span><span class="dv">1</span>]))</a>
<a class="sourceLine" id="cb60-21" data-line-number="21">    m.Y.factor.gp_log_pdf.jitter <span class="op">=</span> <span class="fl">1e-6</span></a>
<a class="sourceLine" id="cb60-22" data-line-number="22"></a>
<a class="sourceLine" id="cb60-23" data-line-number="23">    infr <span class="op">=</span> GradBasedInference(</a>
<a class="sourceLine" id="cb60-24" data-line-number="24">        inference_algorithm<span class="op">=</span>MAP(model<span class="op">=</span>m, observed<span class="op">=</span>[m.X, m.Y]))</a>
<a class="sourceLine" id="cb60-25" data-line-number="25">    infr.run(X<span class="op">=</span>mx.nd.array(X, dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>),</a>
<a class="sourceLine" id="cb60-26" data-line-number="26">             Y<span class="op">=</span>mx.nd.array(Y, dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>),</a>
<a class="sourceLine" id="cb60-27" data-line-number="27">             max_iter<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.1</span>, verbose<span class="op">=</span>verbose)</a>
<a class="sourceLine" id="cb60-28" data-line-number="28">    <span class="cf">return</span> m, infr, X, Y</a></code></pre></div>
<h2 id="policy">Policy</h2>
<p>PILCO computes the expected reward of a policy given the dynamics model. First, we need to define the parametric form of the policy. In this example, we use a neural network with one hidden layer. As the action space is [-2, 2], we apply a <code>tanh</code> transformation and multiply the come with two. This enforces the returned actions stay within the range.</p>
<p>We define a neural network with one hidden layer and and output constrained between [-2,2] for the policy.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb61-1" data-line-number="1"><span class="im">from</span> mxnet.gluon <span class="im">import</span> HybridBlock</a>
<a class="sourceLine" id="cb61-2" data-line-number="2"><span class="im">from</span> mxnet.gluon.nn <span class="im">import</span> Dense</a>
<a class="sourceLine" id="cb61-3" data-line-number="3"></a>
<a class="sourceLine" id="cb61-4" data-line-number="4"><span class="kw">class</span> NNController(HybridBlock):</a>
<a class="sourceLine" id="cb61-5" data-line-number="5">    <span class="co">&quot;&quot;&quot;Define a neural network policy network.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb61-6" data-line-number="6">    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, prefix<span class="op">=</span><span class="va">None</span>, params<span class="op">=</span><span class="va">None</span>):</a>
<a class="sourceLine" id="cb61-7" data-line-number="7">        <span class="bu">super</span>(NNController, <span class="va">self</span>).<span class="fu">__init__</span>(prefix<span class="op">=</span>prefix, params<span class="op">=</span>params)</a>
<a class="sourceLine" id="cb61-8" data-line-number="8">        <span class="va">self</span>.dense1 <span class="op">=</span> Dense(<span class="dv">100</span>, in_units<span class="op">=</span><span class="bu">len</span>(env.observation_space.high), dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>)</a>
<a class="sourceLine" id="cb61-9" data-line-number="9">        <span class="va">self</span>.dense2 <span class="op">=</span> Dense(<span class="dv">1</span>, in_units<span class="op">=</span><span class="dv">100</span>, dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>, activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>)</a>
<a class="sourceLine" id="cb61-10" data-line-number="10"></a>
<a class="sourceLine" id="cb61-11" data-line-number="11">    <span class="kw">def</span> hybrid_forward(<span class="va">self</span>, F, x):</a>
<a class="sourceLine" id="cb61-12" data-line-number="12">        out <span class="op">=</span> <span class="va">self</span>.dense2(<span class="va">self</span>.dense1(x))<span class="op">*</span><span class="dv">2</span> <span class="co"># Scale up the output</span></a>
<a class="sourceLine" id="cb61-13" data-line-number="13">        <span class="cf">return</span> out </a>
<a class="sourceLine" id="cb61-14" data-line-number="14">    </a>
<a class="sourceLine" id="cb61-15" data-line-number="15">policy <span class="op">=</span> NNController()</a>
<a class="sourceLine" id="cb61-16" data-line-number="16">policy.collect_params().initialize(mx.initializer.Xavier(magnitude<span class="op">=</span><span class="dv">1</span>))</a></code></pre></div>
<p>To compute the expected reward, we also need to define a reward function. This reward function is defined by us according to the task. The main component is the height of the pendulum. We also penalize the force and the angular momentum.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="kw">class</span> CostFunction(mx.gluon.HybridBlock):</a>
<a class="sourceLine" id="cb62-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb62-3" data-line-number="3"><span class="co">    The goal is to get the pendulum upright and stable as quickly as possible.</span></a>
<a class="sourceLine" id="cb62-4" data-line-number="4"></a>
<a class="sourceLine" id="cb62-5" data-line-number="5"><span class="co">    Taken from the code for Pendulum.</span></a>
<a class="sourceLine" id="cb62-6" data-line-number="6"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb62-7" data-line-number="7">    <span class="kw">def</span> hybrid_forward(<span class="va">self</span>, F, state, action):</a>
<a class="sourceLine" id="cb62-8" data-line-number="8">        <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb62-9" data-line-number="9"><span class="co">        :param state: [np.cos(theta), np.sin(theta), ~ momentum(theta)]</span></a>
<a class="sourceLine" id="cb62-10" data-line-number="10"><span class="co">        a -&gt; 0 when pendulum is upright, largest when pendulum is hanging down completely.</span></a>
<a class="sourceLine" id="cb62-11" data-line-number="11"><span class="co">        b -&gt; penalty for taking action</span></a>
<a class="sourceLine" id="cb62-12" data-line-number="12"><span class="co">        c -&gt; penalty for pendulum momentum</span></a>
<a class="sourceLine" id="cb62-13" data-line-number="13"><span class="co">        &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb62-14" data-line-number="14">        a_scale <span class="op">=</span> <span class="fl">2.</span></a>
<a class="sourceLine" id="cb62-15" data-line-number="15">        b_scale <span class="op">=</span> <span class="fl">.001</span></a>
<a class="sourceLine" id="cb62-16" data-line-number="16">        c_scale <span class="op">=</span> <span class="fl">.1</span></a>
<a class="sourceLine" id="cb62-17" data-line-number="17">        a <span class="op">=</span> F.<span class="bu">sum</span>(a_scale <span class="op">*</span> (state[:,:,<span class="dv">0</span>:<span class="dv">1</span>] <span class="dv">-1</span>) <span class="op">**</span> <span class="dv">2</span>, axis<span class="op">=-</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb62-18" data-line-number="18">        b <span class="op">=</span> F.<span class="bu">sum</span>(b_scale <span class="op">*</span> action <span class="op">**</span> <span class="dv">2</span>, axis<span class="op">=-</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb62-19" data-line-number="19">        c <span class="op">=</span> F.<span class="bu">sum</span>(c_scale <span class="op">*</span> state[:,:,<span class="dv">2</span>:<span class="dv">3</span>] <span class="op">**</span> <span class="dv">2</span>, axis<span class="op">=-</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb62-20" data-line-number="20">        <span class="cf">return</span> (a <span class="op">+</span> c <span class="op">+</span> b)</a>
<a class="sourceLine" id="cb62-21" data-line-number="21">    </a>
<a class="sourceLine" id="cb62-22" data-line-number="22">cost <span class="op">=</span> CostFunction()</a></code></pre></div>
<p>The expected reward function can be written as <br /><span class="math display">$$
R = \mathbb{E}_{p(\dataScalar_T, \ldots,
\dataScalar_0)}\left(\sum_{t=0}^\top r(\dataScalar_t)\right)
$$</span><br /> where <span class="math inline"><em>r</em>( ⋅ )</span> is the reward function, <span class="math inline">$p(\dataScalar_T, \ldots, \dataScalar_0)$</span> is the joint distribution when applying the policy to the dynamics model: <br /><span class="math display">$$
p(\dataScalar_T, \ldots, \dataScalar_0) = p(\dataScalar_0) \prod_{t=1}^\top p(\dataScalar_t|\dataScalar_{t-1}, a_{t-1}),
$$</span><br /> where <span class="math inline">$a_{t-1} = \pi(\dataScalar_{t-1})$</span> is the action taken at the time <span class="math inline"><em>t</em> − 1</span>, which is the outcome of the policy <span class="math inline"><em>π</em>( ⋅ )</span>.</p>
<p>The expected reward function is implemented as follows.</p>
<h2 id="obtaining-the-policy-gradients">Obtaining the policy gradients</h2>
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb63-1" data-line-number="1"><span class="im">from</span> mxfusion.inference.inference_alg <span class="im">import</span> SamplingAlgorithm</a></code></pre></div>
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb64-1" data-line-number="1"><span class="kw">class</span> PolicyUpdateGPParametricApprox(SamplingAlgorithm):</a>
<a class="sourceLine" id="cb64-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;Class for the policy update for PILCO.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb64-3" data-line-number="3">    <span class="kw">def</span> compute(<span class="va">self</span>, F, variables):</a>
<a class="sourceLine" id="cb64-4" data-line-number="4">        </a>
<a class="sourceLine" id="cb64-5" data-line-number="5">        s_0 <span class="op">=</span> <span class="va">self</span>.initial_state_generator(<span class="va">self</span>.num_samples)</a>
<a class="sourceLine" id="cb64-6" data-line-number="6">        a_0 <span class="op">=</span> <span class="va">self</span>.policy(s_0)</a>
<a class="sourceLine" id="cb64-7" data-line-number="7">        a_t_plus_1 <span class="op">=</span> a_0</a>
<a class="sourceLine" id="cb64-8" data-line-number="8">        x_t <span class="op">=</span> F.expand_dims(F.concat(s_0, a_0, dim<span class="op">=</span><span class="dv">1</span>), axis<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb64-9" data-line-number="9"></a>
<a class="sourceLine" id="cb64-10" data-line-number="10">        gp <span class="op">=</span> <span class="va">self</span>.model.Y.factor</a>
<a class="sourceLine" id="cb64-11" data-line-number="11">        sample_func <span class="op">=</span> gp.draw_parametric_samples(F, variables, <span class="va">self</span>.num_samples, <span class="va">self</span>.approx_samples)</a>
<a class="sourceLine" id="cb64-12" data-line-number="12">        cost <span class="op">=</span> <span class="dv">0</span></a>
<a class="sourceLine" id="cb64-13" data-line-number="13">        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_time_steps):</a>
<a class="sourceLine" id="cb64-14" data-line-number="14">            s_t_plus_1 <span class="op">=</span> sample_func(F, x_t)</a>
<a class="sourceLine" id="cb64-15" data-line-number="15">            cost <span class="op">=</span> cost <span class="op">+</span> <span class="va">self</span>.cost_function(s_t_plus_1, a_t_plus_1)</a>
<a class="sourceLine" id="cb64-16" data-line-number="16">            a_t_plus_1 <span class="op">=</span> mx.nd.expand_dims(<span class="va">self</span>.policy(s_t_plus_1), axis<span class="op">=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb64-17" data-line-number="17">            x_t <span class="op">=</span> mx.nd.concat(s_t_plus_1, a_t_plus_1, dim<span class="op">=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb64-18" data-line-number="18">        total_cost <span class="op">=</span> F.mean(cost)</a>
<a class="sourceLine" id="cb64-19" data-line-number="19">        <span class="cf">return</span> total_cost, total_cost</a></code></pre></div>
<p>We optimize the policy with respect to the expected reward by using a gradient optimizer.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb65-1" data-line-number="1"><span class="im">from</span> mxfusion.inference <span class="im">import</span> GradTransferInference</a></code></pre></div>
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb66-1" data-line-number="1"><span class="kw">def</span> optimize_policy(policy, cost_func, model, infr, model_data_X, model_data_Y,</a>
<a class="sourceLine" id="cb66-2" data-line-number="2">                    initial_state_generator, num_grad_steps,</a>
<a class="sourceLine" id="cb66-3" data-line-number="3">                    learning_rate<span class="op">=</span><span class="fl">1e-2</span>, num_time_steps<span class="op">=</span><span class="dv">100</span>, </a>
<a class="sourceLine" id="cb66-4" data-line-number="4">                    num_samples<span class="op">=</span><span class="dv">10</span>, verbose<span class="op">=</span><span class="va">True</span>):</a>
<a class="sourceLine" id="cb66-5" data-line-number="5">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb66-6" data-line-number="6"><span class="co">    Takes as primary inputs a policy, cost function, and trained model.</span></a>
<a class="sourceLine" id="cb66-7" data-line-number="7"><span class="co">    Optimizes the policy for num_grad_steps number of iterations.</span></a>
<a class="sourceLine" id="cb66-8" data-line-number="8"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb66-9" data-line-number="9">    mb_alg <span class="op">=</span> PolicyUpdateGPParametricApprox(</a>
<a class="sourceLine" id="cb66-10" data-line-number="10">        model<span class="op">=</span>model, observed<span class="op">=</span>[model.X, model.Y], cost_function<span class="op">=</span>cost_func,</a>
<a class="sourceLine" id="cb66-11" data-line-number="11">        policy<span class="op">=</span>policy, n_time_steps<span class="op">=</span>num_time_steps,</a>
<a class="sourceLine" id="cb66-12" data-line-number="12">        initial_state_generator<span class="op">=</span>initial_state_generator,</a>
<a class="sourceLine" id="cb66-13" data-line-number="13">        num_samples<span class="op">=</span>num_samples)</a>
<a class="sourceLine" id="cb66-14" data-line-number="14"></a>
<a class="sourceLine" id="cb66-15" data-line-number="15">    infr_pred <span class="op">=</span> GradTransferInference(</a>
<a class="sourceLine" id="cb66-16" data-line-number="16">        mb_alg, infr_params<span class="op">=</span>infr.params, train_params<span class="op">=</span>policy.collect_params())</a>
<a class="sourceLine" id="cb66-17" data-line-number="17">    infr_pred.run(</a>
<a class="sourceLine" id="cb66-18" data-line-number="18">        max_iter<span class="op">=</span>num_grad_steps,</a>
<a class="sourceLine" id="cb66-19" data-line-number="19">        X<span class="op">=</span>mx.nd.array(model_data_X, dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>),</a>
<a class="sourceLine" id="cb66-20" data-line-number="20">        Y<span class="op">=</span>mx.nd.array(model_data_Y, dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>),</a>
<a class="sourceLine" id="cb66-21" data-line-number="21">        verbose<span class="op">=</span>verbose, learning_rate<span class="op">=</span>learning_rate)</a>
<a class="sourceLine" id="cb66-22" data-line-number="22">    <span class="cf">return</span> policy</a></code></pre></div>
<h2 id="the-loop">The Loop</h2>
<p>We need to define a function that provides random initial states.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb67-1" data-line-number="1"><span class="kw">def</span> initial_state_generator(num_initial_states):</a>
<a class="sourceLine" id="cb67-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb67-3" data-line-number="3"><span class="co">    Starts from valid states by drawing theta and momentum</span></a>
<a class="sourceLine" id="cb67-4" data-line-number="4"><span class="co">    then computing np.cos(theta) and np.sin(theta) for state[0:2].s</span></a>
<a class="sourceLine" id="cb67-5" data-line-number="5"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb67-6" data-line-number="6">    <span class="cf">return</span> mx.nd.array(</a>
<a class="sourceLine" id="cb67-7" data-line-number="7">        [env.observation_space.sample() <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_initial_states)],</a>
<a class="sourceLine" id="cb67-8" data-line-number="8">        dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb68-1" data-line-number="1">num_episode <span class="op">=</span> <span class="dv">20</span> <span class="co"># how many model fit + policy optimization episodes to run</span></a>
<a class="sourceLine" id="cb68-2" data-line-number="2">num_samples <span class="op">=</span> <span class="dv">100</span> <span class="co"># how many sample trajectories the policy optimization loop uses</span></a>
<a class="sourceLine" id="cb68-3" data-line-number="3">num_grad_steps <span class="op">=</span> <span class="dv">1000</span> <span class="co"># how many gradient steps the optimizer takes per episode</span></a>
<a class="sourceLine" id="cb68-4" data-line-number="4">num_time_steps <span class="op">=</span> <span class="dv">100</span> <span class="co"># how far to roll out each sample trajectory</span></a>
<a class="sourceLine" id="cb68-5" data-line-number="5">learning_rate <span class="op">=</span> <span class="fl">1e-3</span> <span class="co"># learning rate for the policy optimization</span></a>
<a class="sourceLine" id="cb68-6" data-line-number="6"></a>
<a class="sourceLine" id="cb68-7" data-line-number="7">all_states <span class="op">=</span> []</a>
<a class="sourceLine" id="cb68-8" data-line-number="8">all_actions <span class="op">=</span> []</a></code></pre></div>
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb69-1" data-line-number="1"><span class="cf">for</span> i_ep <span class="kw">in</span> <span class="bu">range</span>(num_episode):</a>
<a class="sourceLine" id="cb69-2" data-line-number="2">    <span class="co"># Run an episode and collect data.</span></a>
<a class="sourceLine" id="cb69-3" data-line-number="3">    <span class="cf">if</span> i_ep <span class="op">==</span> <span class="dv">0</span>:</a>
<a class="sourceLine" id="cb69-4" data-line-number="4">        policy_func <span class="op">=</span> <span class="kw">lambda</span> x: env.action_space.sample()</a>
<a class="sourceLine" id="cb69-5" data-line-number="5">    <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb69-6" data-line-number="6">        policy_func <span class="op">=</span> <span class="kw">lambda</span> x: policy(mx.nd.expand_dims(mx.nd.array(x, dtype<span class="op">=</span><span class="st">&#39;float64&#39;</span>), axis<span class="op">=</span><span class="dv">0</span>)).asnumpy()[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb69-7" data-line-number="7">    total_reward, states, actions <span class="op">=</span> run_one_episode(</a>
<a class="sourceLine" id="cb69-8" data-line-number="8">        env, policy_func, max_steps<span class="op">=</span>num_time_steps)</a>
<a class="sourceLine" id="cb69-9" data-line-number="9">    all_states.append(states)</a>
<a class="sourceLine" id="cb69-10" data-line-number="10">    all_actions.append(actions)</a>
<a class="sourceLine" id="cb69-11" data-line-number="11"></a>
<a class="sourceLine" id="cb69-12" data-line-number="12">    <span class="co"># Fit a model.</span></a>
<a class="sourceLine" id="cb69-13" data-line-number="13">    model, infr, model_data_X, model_data_Y <span class="op">=</span> fit_model(</a>
<a class="sourceLine" id="cb69-14" data-line-number="14">        all_states, all_actions, win_in<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb69-15" data-line-number="15"></a>
<a class="sourceLine" id="cb69-16" data-line-number="16">    <span class="co"># Optimize the policy.</span></a>
<a class="sourceLine" id="cb69-17" data-line-number="17">    policy <span class="op">=</span> optimize_policy(</a>
<a class="sourceLine" id="cb69-18" data-line-number="18">        policy, cost, model, infr, model_data_X, model_data_Y,</a>
<a class="sourceLine" id="cb69-19" data-line-number="19">        initial_state_generator, num_grad_steps<span class="op">=</span>num_grad_steps,</a>
<a class="sourceLine" id="cb69-20" data-line-number="20">        num_samples<span class="op">=</span>num_samples, learning_rate<span class="op">=</span>learning_rate,</a>
<a class="sourceLine" id="cb69-21" data-line-number="21">        num_time_steps<span class="op">=</span>num_time_steps)</a></code></pre></div>
<p>Policy after the first episode (random exploration):</p>
<div class="figure">
<div id="pilco-pendulum-policy-iter-0-figure" class="figure-frame">
<iframe src="../slides/diagrams/ml/animation_policy_iter_0.html" width="100%" height="auto" allowtransparency="true" frameborder="0">
</iframe>
</div>
<div id="pilco-pendulum-policy-iter-0-magnify" class="magnify" onclick="magnifyFigure(&#39;pilco-pendulum-policy-iter-0&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="pilco-pendulum-policy-iter-0-caption" class="caption-frame">
<p>Figure: PILCO policy for control of the animation after first episode (using random exploration).</p>
</div>
</div>
<p>Policy after the 5th episode:</p>
<div class="figure">
<div id="pilco-pendulum-policy-iter-0-figure" class="figure-frame">
<iframe src="../slides/diagrams/ml/animation_policy_iter_4.html" width="100%" height="auto" allowtransparency="true" frameborder="0">
</iframe>
</div>
<div id="pilco-pendulum-policy-iter-0-magnify" class="magnify" onclick="magnifyFigure(&#39;pilco-pendulum-policy-iter-0&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="pilco-pendulum-policy-iter-0-caption" class="caption-frame">
<p>Figure: PILCO policy for control of the animation after the fifth episode.</p>
</div>
</div>
<p><a href="https://github.com/amzn/mxfusion" class="uri">https://github.com/amzn/mxfusion</a></p>
<h2 id="long-term-aim">Long term Aim</h2>
<ul>
<li>Simulate/Emulate the components of the system.
<ul>
<li>Validate with real world using multifidelity.</li>
<li>Interpret system using e.g. sensitivity analysis.</li>
</ul></li>
<li>Perform end to end learning to optimize.
<ul>
<li>Maintain interpretability.</li>
</ul></li>
</ul>
<h1 id="references" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Cooper:transformation91">
<p>Cooper, Brian. 1991. <em>Transformation of a Valley: Derbyshire Derwent</em>. Scarthin Books.</p>
</div>
<div id="ref-Maxwell:governors1867">
<p>Maxwell, James Clerk. 1867. “On Governors.” <em>Proceedings of the Royal Society of London</em> 16. The Royal Society: 270–83. <a href="http://www.jstor.org/stable/112510" class="uri">http://www.jstor.org/stable/112510</a>.</p>
</div>
<div id="ref-Perdikaris:multifidelity17">
<p>Perdikaris, P., M. Raissi, A. Damianou, N. D. Lawrence, and G. E. Karniadakis. 2017. “Nonlinear Information Fusion Algorithms for Data-Efficient Multi-Fidelity Modelling.” <em>Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</em> 473 (2198). The Royal Society. <a href="https://doi.org/10.1098/rspa.2016.0751" class="uri">https://doi.org/10.1098/rspa.2016.0751</a>.</p>
</div>
<div id="ref-Wiener:cybernetics48">
<p>Wiener, Norbert. 1948. <em>Cybernetics: Control and Communication in the Animal and the Machine</em>. Cambridge, MA: MIT Press.</p>
</div>
</div>


