---
title: "Fairness and Diversity of Decision Making"
venue: "Center for the Advanced Studies of the Behavioral Sciences, Joint American Academy and Royal Society Workshop"
abstract: "<p>Mathematical definitions of fairness insist on clearly categorized groups and clear mathematical interpretations of fairness. In law this arises through the concept of <em>unlawful</em> descrimination. There is no such thing as a correct model. We must accept that our predictions will sometimes be wrong. In the face of this certainty we have a choice: how we should be wrong. We can choose to be wrong by over-simplifying or we can choose to be wrong by over-complicating (given the available data). In machine learning this is known as the bias-variance dilemma. In this talk we consider the implications of the bias-variance dilemma for fairness of decision making.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: Amazon Cambridge and University of Sheffield
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
blog: 2017-11-15-decision-making.md
blog: 2018-02-06-natural-and-artificial-intelligence.md
blog: 2015-12-04-what-kind-of-ai.md
date: 2018-11-08
published: 2018-11-08
reveal: 2018-11-08-fairness-and-diversity-of-decision-making.slides.html
ipynb: 2018-11-08-fairness-and-diversity-of-decision-making.ipynb
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Front matter -->
<p>.</p>
<!---->
<!--Back matter-->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--include{_philosophy/includes/utilitarianism.md}
include{_philosophy/includes/utility-utilitarianism.md}
include{_philosophy/includes/trolley-push.md}-->
<h2 id="what-is-machine-learning-edit">What is Machine Learning? <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-2.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-2.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Machine learning allows us to extract knowledge from data to form a prediction.</p>
<p><br /><span class="math display">$$\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}$$</span><br /></p>
<p>A machine learning prediction is made by combining a model with data to form the prediction. The manner in which this is done gives us the machine learning <em>algorithm</em>.</p>
<p>Machine learning models are <em>mathematical models</em> which make weak assumptions about data, e.g. smoothness assumptions. By combining these assumptions with the data we observe we can interpolate between data points or, occasionally, extrapolate into the future.</p>
<p>Machine learning is a technology which strongly overlaps with the methodology of statistics. From a historical/philosophical view point, machine learning differs from statistics in that the focus in the machine learning community has been primarily on accuracy of prediction, whereas the focus in statistics is typically on the interpretability of a model and/or validating a hypothesis through data collection.</p>
<p>The rapid increase in the availability of compute and data has led to the increased prominence of machine learning. This prominence is surfacing in two different, but overlapping domains: data science and artificial intelligence.</p>
<p>The real challenge, however, is end-to-end decision making. Taking information from the enviroment and using it to drive decision making to achieve goals.</p>
<!--




## Prospect Theory <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-towards-variance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-towards-variance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>

* Daniel Kahneman's Nobel Memorial Prize in Economics was awarded for the idea of *prospect theory*. 
* Kahneman describes the theory and its background in his book, "Thinking Fast and Slow" [@Kahneman-fastslow11]. 
* Empirical theory about how people are responsive to change in circumstance, not absolute circumstance. 

## Subjective Utility 

* Bentham's ideas focussed around the idea of a global utility.
* Natural selection insists there must be *variation* in the population
* Without variation, there is no separation between effective and ineffective strategies.

## A Cognitive Bias towards Variance 

* Kahneman explores our tendency to produce overcomplicated explanations
* Prediction is
    $$ \text{model} + \text{data} \rightarrow \text{prediction}$$
* Models fail as overly simple or overly complex


-->
<!--




## Bias vs Variance <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>

* 'bias variance dilemma' @Geman-biasvariance92
* Decompose errors as 
    1. due to oversimplification (the bias error) and 
    2. those due to insufficient data to underpin a complex model (variance error).

## In Machine Learning 

* Two approaches
   * Use simpler models (better consistency and generalization)
   * Use more complex models and average.





## Bias vs Variance Error Plots <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/bias-variance-plots.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/bias-variance-plots.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>

Helper function for sampling data from two different classes.

```{.python}
import numpy as np
```

```{.python}
def create_data(per_cluster=30):
    """Create a randomly sampled data set
    
    :param per_cluster: number of points in each cluster
    """
    X = []
    y = []
    scale = 3
    prec = 1/(scale*scale)
    pos_mean = [[-1, 0],[0,0.5],[1,0]]
    pos_cov = [[prec, 0.], [0., prec]]
    neg_mean = [[0, -0.5],[0,-0.5],[0,-0.5]]
    neg_cov = [[prec, 0.], [0., prec]]
    for mean in pos_mean:
        X.append(np.random.multivariate_normal(mean=mean, cov=pos_cov, size=per_class))
        y.append(np.ones((per_class, 1)))
    for mean in neg_mean:
        X.append(np.random.multivariate_normal(mean=mean, cov=neg_cov, size=per_class))
        y.append(np.zeros((per_class, 1)))
    return np.vstack(X), np.vstack(y).flatten()
```
        
Helper function for plotting the decision boundary of the SVM.

```{.python}
def plot_contours(ax, cl, xx, yy, **params):
    """Plot the decision boundaries for a classifier.

    :param ax: matplotlib axes object
    :param cl: a classifier
    :param xx: meshgrid ndarray
    :param yy: meshgrid ndarray
    :param params: dictionary of params to pass to contourf, optional
    """
    Z = cl.decision_function(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    # Plot decision boundary and regions
    out = ax.contour(xx, yy, Z, 
                     levels=[-1., 0., 1], 
                     colors='black', 
                     linestyles=['dashed', 'solid', 'dashed'])
    out = ax.contourf(xx, yy, Z, 
                     levels=[Z.min(), 0, Z.max()], 
                     colors=[[0.5, 1.0, 0.5], [1.0, 0.5, 0.5]])
    return out
```


```{.python}
import mlai
import os
```
```{.python}
def decision_boundary_plot(models, X, y, axs, filename, titles, xlim, ylim):
    """Plot a decision boundary on the given axes
    
    :param axs: the axes to plot on.
    :param models: the SVM models to plot
    :param titles: the titles for each axis
    :param X: input training data
    :param y: target training data"""
    for ax in axs.flatten():
        ax.clear()
    X0, X1 = X[:, 0], X[:, 1]
    if xlim is None:
        xlim = [X0.min()-1, X0.max()+1]
    if ylim is None:
        ylim = [X1.min()-1, X1.max()+1]
    xx, yy = np.meshgrid(np.arange(xlim[0], xlim[1], 0.02),
                         np.arange(ylim[0], ylim[1], 0.02))
    for cl, title, ax in zip(models, titles, axs.flatten()):
        plot_contours(ax, cl, xx, yy,
                      cmap=plt.cm.coolwarm, alpha=0.8)
        ax.plot(X0[y==1], X1[y==1], 'r.', markersize=10)
        ax.plot(X0[y==0], X1[y==0], 'g.', markersize=10)
        ax.set_xlim(xlim)
        ax.set_ylim(ylim)
        ax.set_xticks(())
        ax.set_yticks(())
        ax.set_title(title)
        mlai.write_figure(os.path.join(filename),
                          figure=fig,
                          transparent=True)
    return xlim, ylim
```


```{.python}
import matplotlib
font = {'family' : 'sans',
        'weight' : 'bold',
        'size'   : 22}

matplotlib.rc('font', **font)
import matplotlib.pyplot as plt
```



```{.python}
# Create an instance of SVM and fit the data. 
C = 100.0  # SVM regularization parameter
gammas = [0.001, 0.01, 0.1, 1]


per_class=30
num_samps = 20
# Set-up 2x2 grid for plotting.
fig, ax = plt.subplots(1, 4, figsize=(10,3))
xlim=None
ylim=None
for samp in range(num_samps):
    X, y=create_data(per_class)
    models = []
    titles = []
    for gamma in gammas:
        models.append(svm.SVC(kernel='rbf', gamma=gamma, C=C))
        titles.append('$\gamma={}$'.format(gamma))
    models = (cl.fit(X, y) for cl in models)
    xlim, ylim = decision_boundary_plot(models, X, y, 
                           axs=ax, 
                           filename='../slides/diagrams/ml/bias-variance{samp:0>3}.svg'.format(samp=samp), 
                           titles=titles,
                          xlim=xlim,
                          ylim=ylim)
```


```{.python}
import pods
from ipywidgets import IntSlider
```
```{.python}
pods.notebook.display_plots('bias-variance{samp:0>3}.svg', 
                            directory='../slides/diagrams/ml', 
                            samp=IntSlider(0,0,19,1))
```
                            





<div class="figure">
<div class="figure-frame" id="bias-variance-errors-figure">
<table><tr><td width="45%"><object class="svgplot "  data="../slides/diagrams/ml/bias-variance000.svg"  style="vertical-align:middle;"></object></td><td width="45%"><object class="svgplot "  data="../slides/diagram/ml/bias-variance019.svg"  style="vertical-align:middle;"></object></td></tr></table>
</div>
<div class="magnify" id="bias-variance-errors-magnify" onclick="magnifyFigure('bias-variance-errors')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="bias-variance-errors-caption">
Figure: In each figure the more simple model is on the left, and the more complex model is on the right. Each fit is done to a different version of the data set. The simpler model is more consistent in its errors (bias error), whereas the more complex model is varying in its errors (variance error).
</div>
</div>




## Decision Making and Bias-Variance 

* In a population we should prefer variance-errors. 
    * Bias errors lead to consistent, decsion making.
    * Consistently wrong!
    
* Variance errors can also be averaged e.g. [bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating) and [boosting](https://en.wikipedia.org/wiki/Boosting_(machine_learning)) [@Breiman-bagging96] 


-->
<!--



## Rational Behaviour <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-rational.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-rational.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>

* Sustain a variety of approaches to life.
* Complex explanations such as half-time football punditry.
* Also clinical experts [@Meehl-clinicalstatistical54]. Meehl suggested they 'try to be clever and think outside the box'. 


## One Correct Solution 

* Artificial Selection and Eugenics.
* OK for race horses, greyhounds, crops, sheep and cows 
* Not OK for the human race.


## One Correct Solution 

* Flawed understanding of science
* Animals in a species become too specialised then they may not be able to respond to changing circumstances. 
    * Think of cheetahs and eagles vs rats and pigeons.


## Similar Ideas Socially 

> I may not agree with many people's subjective approach to life, I may even believe it to be severely sub-optimal. But I should not presume to know better, even if prior experience shows that my own 'way of being' is effective. 
>
> Variation is vitally important for robustness. There may be future circumstances where my approaches fail utterly, and other ways of being are better.


## A Universal Utility 

* Quality of our individual subjective utilities measured by effectiveness.
* But it is survival of entire species that dominates long term.
* A universal utility by which we are judged is difficult to define.


## The Real Ethical Dilemma 

* Trolley Problem is an oversimplification.
* Driverless cars: 
    * introduce driverless cars and bring about a 90% reduction in deaths 
    * What if remaining deaths are all cyclists?


-->
<!--



## Uncertainty: The Tyger that Burns Bright <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/uncertainty-and-absolutism.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/uncertainty-and-absolutism.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>

* Non-survival of the non-fit 
* The marvel of evolution is its responsiveness.
* Utility function evolves socially and in our environment.

(["survival of the fittest"](https://en.wikipedia.org/wiki/Survival_of_the_fittest) is due to [Herbert Spencer](https://en.wikipedia.org/wiki/Herbert_Spencer))

## Absolute Policies 

* There is only one absolute policy we should follow. 

> There will be single absolute policy that should be followed slavishly in all circumstances


## George Box 

> Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.
>
> George E. P. Box [@Box-science76]


## Tigers and Trolleys 

* A simple switch in the points, is deterministic/mechanistic

<div class="figure">
<div class="figure-frame" id="trolley-problem-1-figure">
<div class="centered centered" style=""><img class="negate" src="../slides/diagrams/ai/Trolley_1.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="trolley-problem-1-magnify" onclick="magnifyFigure('trolley-problem-1')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="trolley-problem-1-caption">
Figure: The original trolley problem. The decision is deterministic.
</div>
</div>




* The second example is largely contrived, and riddled with uncertainty.

<div class="figure">
<div class="figure-frame" id="trolley-problem-2-figure">
<div class="centered centered" style=""><img class="negate" src="../slides/diagrams/ai/trolley2.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="trolley-problem-2-magnify" onclick="magnifyFigure('trolley-problem-2')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="trolley-problem-2-caption">
Figure: In the situation where you push an overweight gentleman, the decision is riddled with uncertainty. Doubt inevitably creeps in.
</div>
</div>

-->
<!--  -->
<!--  -->


