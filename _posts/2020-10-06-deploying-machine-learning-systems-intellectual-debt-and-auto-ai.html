---
title: "Deploying Machine Learning: Intellectual Debt and AutoAI"
venue: "Virtual Advances in Data Science Seminar, Manchester"
abstract: "<p>From the dawn of cybernetics, and across the last eight decades, we’ve worked to make machine learning methods successful. But now that these methods are being widely adopted we need to deal with the consequences of success. Many of those consequences can only be understood when a holistic approach to the machine learning problem is considered: the deployment of a method within a context for a particular objective. In this circumstance, it’s easy to see that questions of interpretability, fairness and transparency are all contextual. In this talk we summarize this challenge using Jonathan Zittrain’s term of 'intellectual debt', we discuss how it pans out in reality and how this challenge could be addressed using machine learning techniques to give us 'Auto AI'. This work is sponsored by an ATI Senior AI Fellowship.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orcid: 
youtube: 5PdHgR6zz1o
date: 2020-10-06
published: 2020-10-06
week: 0
reveal: 2020-10-06-deploying-machine-learning-systems-intellectual-debt-and-auto-ai.slides.html
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<h1 id="the-great-ai-fallacy">The Great AI Fallacy</h1>
<p>There is a lot of variation in the use of the term artificial intelligence. I’m sometimes asked to define it, but depending on whether you’re speaking to a member of the public, a fellow machine learning researcher, or someone from the business community, the sense of the term differs.</p>
<p>However, underlying its use I’ve detected one disturbing trend. A trend I’m beginining to think of as "The Great AI Fallacy".</p>
<p>The fallacy is associated with an implicit promise that is embedded in many statements about Artificial Intelligence. Artificial Intelligence, as it currently exists, is merely a form of automated decision making. The implicit promise of Artificial Intelligence is that it will be the first wave of automation where the machine adapts to the human, rather than the human adapting to the machine.</p>
<p>How else can we explain the suspension of sensible business judgment that is accompanying the hype surrounding AI?</p>
<p>This fallacy is particularly pernicious because there are serious benefits to society in deploying this new wave of data-driven automated decision making. But the AI Fallacy is causing us to suspend our calibrated skepticism that is needed to deploy these systems safely and efficiently.</p>
<p>The problem is compounded because many of the techniques that we’re speaking of were originally developed in academic laboratories in isolation from real-world deployment.</p>
<div class="figure">
<div id="jeeves-springtime-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ai/Jeeves_in_the_Springtime_01.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="jeeves-springtime-magnify" class="magnify" onclick="magnifyFigure(&#39;jeeves-springtime&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="jeeves-springtime-caption" class="caption-frame">
<p>Figure: We seem to have fallen for a perspective on AI that suggests it will adapt to our schedule, rather in the manner of a 1930s manservant.</p>
</div>
</div>
<h2 id="artificial-vs-natural-systems">Artificial vs Natural Systems</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/artificial-vs-natural-systems-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/artificial-vs-natural-systems-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>Let’s take a step back from artificial intelligence, and consider natural intelligence. Or even more generally, let’s consider the contrast between an artificial <em>system</em> and an natural system. The key difference between the two is that artificial systems are <em>designed</em> whereas natural systems are <em>evolved</em>.</p>
<p>Systems design is a major component of all Engineering disciplines. The details differ, but there is a single common theme: achieve your objective with the minimal use of resources to do the job. That provides efficiency. The engineering designer imagines a solution that requires the minimal set of components to achieve the result. A water pump has one route through the pump. That minimises the number of components needed. Redundancy is introduced only in safety critical systems, such as aircraft control systems. Students of biology, however, will be aware that in nature system-redundancy is everywhere. Redundancy leads to robustness. For an organism to survive in an evolving environment it must first be robust, then it can consider how to be efficient. Indeed, organisms that evolve to be too efficient at a particular task, like those that occupy a niche environment, are particularly vulnerable to extinction.</p>
<p>This notion is akin to the idea that only the best will survive, popularly encoded into an notion of evolution by Herbert Spencer’s quote.</p>
<blockquote>
<p>Survival of the fittest</p>
<p><a href="https://en.wikipedia.org/wiki/Herbert_Spencer">Herbet Spencer</a>, 1864</p>
</blockquote>
<p>Darwin himself never said "Survival of the Fittest" he talked about evolution by natural selection.</p>
<blockquote>
<p>Non-survival of the non-fit</p>
</blockquote>
<p>Evolution is better described as "non-survival of the non-fit". You don’t have to be the fittest to survive, you just need to avoid the pitfalls of life. This is the first priority.</p>
<p>So it is with natural vs artificial intelligences. Any natural intelligence that was not robust to changes in its external environment would not survive, and therefore not reproduce. In contrast the artificial intelligences we produce are designed to be efficient at one specific task: control, computation, playing chess. They are <em>fragile</em>.</p>
<p>The first rule of a natural system is not be intelligent, it is "don’t be stupid".</p>
<p>A mistake we make in the design of our systems is to equate fitness with the objective function, and to assume it is known and static. In practice, a real environment would have an evolving fitness function which would be unknown at any given time.</p>
<p>You can also read this blog post on <a href="http://inverseprobability.com/2018/02/06/natural-and-artificial-intelligence">Natural and Artificial Intelligence</a>..</p>
<p>The first criterion of a natural intelligence is <em>don’t fail</em>, not because it has a will or intent of its own, but because if it had failed it wouldn’t have stood the test of time. It would no longer exist. In contrast, the mantra for artificial systems is to be more efficient. Our artificial systems are often given a single objective (in machine learning it is encoded in a mathematical function) and they aim to achieve that objective efficiently. These are different characteristics. Even if we wanted to incorporate <em>don’t fail</em> in some form, it is difficult to design for. To design for "don’t fail", you have to consider every which way in which things can go wrong, if you miss one you fail. These cases are sometimes called corner cases. But in a real, uncontrolled environment, almost everything is a corner. It is difficult to imagine everything that can happen. This is why most of our automated systems operate in controlled environments, for example in a factory, or on a set of rails. Deploying automated systems in an uncontrolled environment requires a different approach to systems design. One that accounts for uncertainty in the environment and is robust to unforeseen circumstances.</p>
<h1 id="intellectual-debt">Intellectual Debt</h1>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/intellectual-debt-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/intellectual-debt-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="intellectual-debt-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ai/2020-02-12-intellectual-debt.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="intellectual-debt-magnify" class="magnify" onclick="magnifyFigure(&#39;intellectual-debt&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="intellectual-debt-caption" class="caption-frame">
<p>Figure: Jonathan Zittrain’s term to describe the challenges of explanation that come with AI is Intellectual Debt.</p>
</div>
</div>
<p>In computer systems the concept of <em>technical debt</em> has been surfaced by authors including <span class="citation" data-cites="Sculley:debt15">Sculley et al. (2015)</span>. It is an important concept, that I think is somewhat hidden from the academic community, because it is a phenomenon that occurs when a computer software system is deployed.</p>
<h2 id="separation-of-concerns">Separation of Concerns</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_software/includes/separation-of-concerns.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_software/includes/separation-of-concerns.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>To construct such complex systems an approach known as "separation of concerns" has been developed. The idea is that you architect your system, which consists of a large-scale complex task, into a set of simpler tasks. Each of these tasks is separately implemented. This is known as the decomposition of the task.</p>
<p>This is where Jonathan Zittrain’s beautifully named term "intellectual debt" rises to the fore. Separation of concerns enables the construction of a complex system. But who is concerned with the overall system?</p>
<ul>
<li><p>Technical debt is the inability to <em>maintain</em> your complex software system.</p></li>
<li><p>Intellectual debt is the inability to <em>explain</em> your software system.</p></li>
</ul>
<p>It is right there in our approach to software engineering. "Separation of concerns" means no one is concerned about the overall system itself.</p>
<h2 id="buying-system">Buying System</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/buying-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/buying-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>An example of a complex decision making system might be an automated buying system. In such a system, the idea is to match demand for products to supply of products.</p>
<p>The matching of demand and supply is a repetetive theme for decision making systems. Not only does it occur in automated buying, but also in the allocation of drivers to riders in a ride sharing system. Or in the allocation of compute resource to users in a cloud system.</p>
<p>The components of any of these system include: predictions of the demand for the product, or the drivers or the compute. Then predictions of the supply. Decisions are then made for how much material to keep in stock, or how many drivers to have on the road, or how much computer capacity to have in your data centres. These decisions have cost implications. The optimal amount of product will depend on the cost of making it available. For a buying system this is the storage costs.</p>
<p>Decisions are made on the basis of the supply and demand to make new orders, to encourage more drivers to come into the system or to build new data centers or rent more computational power.</p>
<div class="figure">
<div id="buying-system-components-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/software/buying-schematic.svg" width="40%" style=" ">
</object>
</div>
<div id="buying-system-components-magnify" class="magnify" onclick="magnifyFigure(&#39;buying-system-components&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="buying-system-components-caption" class="caption-frame">
<p>Figure: The components of a putative automated buying system</p>
</div>
</div>
<h2 id="monolithic-system">Monolithic System</h2>
<p>The classical approach to building these systems was a ‘monolithic system’. Built in a similar way to the successful applicaitons software such as Excel or Word, or large operating systems, a single code base was constructed. The complexity of such code bases run to many lines.</p>
<p>In practice, shared dynamically linked libraries may be used for aspects such as user interface, or networking, but the software often has many millions of lines of code. For example, the Microsoft Office suite is said to contain over 30 millions of lines of code.</p>
<div class="figure">
<div id="ml-system-monolith-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-monolith-purchasing.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-monolith-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-monolith&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ml-system-monolith-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="service-oriented-architecture">Service Oriented Architecture</h2>
<p>Such software is not only difficult to develop, it is difficult to scale when computation demands increase. Amazon’s original website software (called Obidos) was a <a href="https://en.wikipedia.org/wiki/Obidos_(software)">monolithic design</a> but by the early noughties it was becoming difficult to sustain and maintain. The software was phased out in 2006 to be replaced by a modularized software known as a ‘service oriented architecture’.</p>
<p>In Service Oriented Architecture, or "Software as a Service" the idea is that code bases are modularized and communicate with one another using network requests. A standard approach is to use a <a href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST API</a>. So, rather than a single monolithic code base, the code is developed with individual services that handle the different requests.</p>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing000.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ml-system-downstream-purchasing-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<p>This is the landscape we now find ourselves in with regard to software development. In practice, each of these services is often ‘owned’ and maintained by an individual team. The team is judged by the quality of their service provision. They work to detailed specifications on what their service should output, what its availability should be and other objectives like speed of response. This allows for conditional independence between teams and for faster development.</p>
<h2 id="buying-to-banking">Buying to Banking</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/buying-to-banking.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/buying-to-banking.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>The same model we consider for buying, can also be considered in the case of, for example, a banking application. In a typical banking application, we receive loan requests from customers. For an individual customer, before making a loan, the bank may wish to make a forecast around their costs (expenditures on food, housing, entertainment etc) and their income (salary, rental income etc). These forecasts would inform the conditions of the loan. For example how much the bank is willing to lend, and under what interest rates and repayment conditions. These terms will be based on previous experience of loaning, but also constrained by regulatory conditions often imposed by a financial regulator.</p>
<div class="figure">
<div id="ml-system-downstream-banking-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-banking000.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-downstream-banking-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-banking&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ml-system-downstream-banking-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system where a decision about a loan is being made on the basis of (potentially personal) data from a customer.</p>
</div>
</div>
<p>In many regulatory environments, the bank will be restricted in terms of what information they are allowed to use in dictating loan terms. For example, with in the EU there are prohibited characteristics such as race, gender, sexuality, religion and health status which cannot be used (even indirectly) for making the loan. Along with stipulating these characteristics, the badly-named GDPR<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> also gives particular stipulations for rights individuals have for explanation around consequential decisions, such as obtaining a loan.</p>
<p>The challenge of Intellectual Debt means that it’s possible for a bank to produce an automated loan decision system, which even the bank itself doesn’t understand, which makes it rather hard to conform to the intent of the GDPR which requires the bank to explain to customers the reasoning behind decisions based on personal data.</p>
<h2 id="safeboda">SafeBoda</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/safe-boda.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/safe-boda.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>The complexity of building safe, maintainable systems that are based on interacting components which include machine learning models means that smaller companies can be excluded from access to these technologies due the technical and intellectual debt incurred when maintaining such systems in a real-world environment.</p>
<div class="figure">
<div id="safe-boda-system-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ai/safe-boda.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="safe-boda-system-magnify" class="magnify" onclick="magnifyFigure(&#39;safe-boda-system&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="safe-boda-system-caption" class="caption-frame">
<p>Figure: SafeBoda is a ride allocation system for Boda Boda drivers. Let’s imagine the capabilities we need for such an AI system.</p>
</div>
</div>
<p><a href="https://safeboda.com/ug/index.php#whysafeboda">SafeBoda</a> is a Kampala based rider allocation system for Boda Boda drivers. Boda boda are motorcycle taxis which give employment to, often young men, across Kampala. Safe Boda is driven by the knowledge that road accidents are set to match HIV/AIDS as the highest cause of death in low/middle income families by 2030.</p>
<blockquote>
<p>With road accidents set to match HIV/AIDS as the highest cause of death in low/middle income countries by 2030, SafeBoda’s aim is to modernise informal transportation and ensure safe access to mobility.</p>
</blockquote>
<p>A key aim of the AutoAI agenda is to reduce these technical challenges, so that such software can be maintained safely and reliably by a small team of software engineers. Without this capability it is hard to imagine how low resource environments can fully benefit from the ‘data revolution’ without heavy reliance on technical provision from high-resource environments. Such dependence would inevitably mean a skew towards the challenges that high-resource economies face, rather than the more urgent and important problems that are faced in low-resource environments.</p>
<h2 id="fit-models-to-fit-systems">FIT Models to FIT Systems</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/fit-systems.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/fit-systems.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>Zittrain points out the challenge around the lack of interpretability of individual ML models as the origin of intellectual debt. In machine learning I refer to work in this area as fairness, interpretability and transparency or FIT models. To an extent I agree with Zittrain, but if we understand the context and purpose of the decision making, I believe this is readily put right by the correct monitoring and retraining regime around the model. A concept I refer to as "progression testing". Indeed, the best teams do this at the moment, and their failure to do it feels more of a matter of technical debt rather than intellectual, because arguably it is a maintenance task rather than an explanation task. After all, we have good statistical tools for interpreting individual models and decisions when we have the context. We can linearise around the operating point, we can perform counterfactual tests on the model. We can build empirical validation sets that explore fairness or accuracy of the model.</p>
<p>So, this is where, my understanding of intellectual debt in ML systems departs, I believe from John Zittrain’s. The long-term challenge is <em>not</em> in the individual model. We have excellent statistical tools for validating what any individual model, the long-term challenge is the complex interaction between different components in the decomposed system, where the original intent of each component has been forgotten (except perhaps by Lancelot) and each service has been repurposed. We need to move from FIT models to FIT systems.</p>
<p>How to address these challenges? With collaborators I’ve been working towards a solution that contains broadly two parts. The first part is what we refer to as "Data-Oriented Architectures". The second part is "meta modelling", machine learning techniques that help us model the models.</p>
<div class="figure">
<div id="ride-allocation-system-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ride-allocation-prediction.svg" width="60%" style=" ">
</object>
</div>
<div id="ride-allocation-system-magnify" class="magnify" onclick="magnifyFigure(&#39;ride-allocation-system&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ride-allocation-system-caption" class="caption-frame">
<p>Figure: Some software components in a ride allocation system. Circled components are hypothetical, rectangles represent actual data.</p>
</div>
</div>
<h1 id="a-solution">A Solution</h1>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/deploying-machine-learning-systems-intellectual-debt-and-auto-ai.mdtmp.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/deploying-machine-learning-systems-intellectual-debt-and-auto-ai.mdtmp.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<h2 id="data-oriented-architectures">Data-oriented Architectures</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-oriented-architectures-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-oriented-architectures-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>Data-oriented architectures aim to address the rat’s nest that is the current interaction between the services in a service-oriented architecture. It does this by introducing data-oriented programming. The data-oriented programming language tracks the movement of data between each service.</p>
<p>Service-oriented programming style is a necessary, but not sufficient approach to data-oriented programming. Data-oriented programming is not only about the individual services, but how they are connected. Which service is calling which and where the flow of the data through the system occurs?</p>
<p>If each service has its inputs and outputs declared on a wider ecosystem, then we can programmatically determine which inputs effect which decisions. This programmatic discovery is vital because as systems are built compositionally, the actual inputs that affect a final decision may not be known to any of the software engineers who are maintaining the system.</p>
<h2 id="milan">Milan</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/milan.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/milan.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>To answer these challenges at Amazon we began the process of constructing software for data oriented architectures. The team built a <em>data-oriented programming</em> language which is <a href="https://github.com/amzn/milan">now available through BSD license</a>. The language is called Milan. Quoting from <a href="https://tborchertblog.wordpress.com/2020/02/13/28/">Tom Borchert’s blog on Milan</a>:</p>
<blockquote>
<p>Milan has three components:</p>
<ol type="1">
<li><p>A general-purpose stream algebra that encodes relationships between data streams (the Milan Intermediate Language or Milan IL)</p></li>
<li><p>A Scala library for building programs in that algebra.</p></li>
<li><p>A compiler that takes programs expressed in Milan IL and produces a Flink application that executes the program.</p></li>
</ol>
<p>Component (2) can be extended to support interfaces in additional languages, and component (3) can be extended to support additional runtime targets. Considering just the multiple interfaces and the multiple runtimes, Milan looks a lot like the much more mature Apache Beam. The difference lies in (1), Milan’s general-purpose stream algebra.</p>
</blockquote>
<div class="figure">
<div id="milan-schematic-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/software/milan-schematic.svg" width="80%" style=" ">
</object>
</div>
<div id="milan-schematic-magnify" class="magnify" onclick="magnifyFigure(&#39;milan-schematic&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="milan-schematic-caption" class="caption-frame">
<p>Figure: The Milan Software has a general purpose stream algebra at its core, the Milan IL.</p>
</div>
</div>
<div class="figure">
<div id="milan-software-page-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/software/milan.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="milan-software-page-magnify" class="magnify" onclick="magnifyFigure(&#39;milan-software-page&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="milan-software-page-caption" class="caption-frame">
<p>Figure: The Milan Software is designed for building modern AI systems. <a href="https://github.com/amzn/milan/" class="uri">https://github.com/amzn/milan/</a></p>
</div>
</div>
<p>It is through the general-purpose stream algebra that we hope to make significant inroads on the intellectual debt challenge.</p>
<p>The stream algebra defines the relationship between different machine learning components in the wider software architecture. Composition of multiple services cannot occur without a signature existing within the stream algebra. The Milan IL becomes the key information structure that is required to reason about the wider software system.</p>
<h2 id="context">Context</h2>
<p>This deals with the challenges that arise through the intellectual debt because we can now see the context around each service. This allows us to design the relevant validation checks to ensure that accuracy and fairness are maintained. By recompiling the algebra to focus on a particular decision within the system we can also derive new statistical tests to validate performance. These are the checks that we refer to as progression testing. The loss of programmer control means that we can no longer rely on software tests written at design time, we must have the capability to deploy new (statistical) tests after deployment as the uses to which each service is placed extend to previously un-envisaged domains.</p>
<h2 id="stateless-services">Stateless Services</h2>
<p>Importantly, Milan does not place onerous constraints on the builders of individual machine learning models (or other components). Standard modelling frameworks can be used. The main constraint is that any code that is not visible to the ecosystem does not maintain or store global state. This condition implies that the parameters of any machine learning model need to also be declared as an input to the model within the Milan IL.</p>
<h2 id="meta-modelling">Meta Modelling</h2>
<div class="figure">
<div id="emukit-software-page-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/uq/emukit-software-page.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-software-page-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-software-page&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="emukit-software-page-caption" class="caption-frame">
<p>Figure: The Emukit software is a set of software tools for emulation and surrogate modeling. <a href="https://amzn.github.io/emukit/" class="uri">https://amzn.github.io/emukit/</a></p>
</div>
</div>
<p>Where does machine learning come in? The strategy I propose is that the Milan IL is integrated with meta-modelling approaches to assist in the explanation of the decision-making framework. At their simplest these approaches may be novelty detection algorithms on the data streams that are emerging from a given service. This is a form of <em>progression testing</em>. But we can go much further. By knowing the training data, the inputs and outputs of the individual services in the software ecosystem, we can build meta-models that test for fairness, accuracy not just of individual system components, but short or long cascades of decision making. Through the use of the Milan IL algebra all these tests could be automatically deployed. The focus of machine learning is on the models-that-model-the-models. The meta-models.</p>
<p>In Amazon, our own focus was on the use of statistical emulators, sometimes known as surrogate models, for fulfilling this task. The work we were putting into this route is available through another software package, <a href="https://amzn.github.io/emukit/">Emukit, a framework for decision making under uncertainty</a>. With collaborators my current focus for addressing these issues is a form of fusion of Emukit and Milan (Milemukit??). But the nature of this fusion requires testing on real world problem sets. A task we hope to carry out in close collaboration with colleagues at <a href="http://www.datascienceafrica.org/">Data Science Africa</a>.</p>
<h2 id="autoai-fit-models-to-fit-systems">AutoAI: FIT Models to FIT Systems</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/fit-models-to-fit-systems.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/fit-models-to-fit-systems.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>The idea of AutoAI is to combine the streaming algebra we obtain from the data oriented architecture (we can think of it as a ‘tube map for data flows’) with monitoring techniques both from machine learning, classical statistics and softare verification for ensuring that the system is performing as designed and/or alerting us to when our assumptions about the system are invalidated.</p>
<p>We can already deploy classical statistical approaches for e.g. outlier detection, or use proofs from category theory to demonstrate that a particular decision is not based on a protected characteristic.</p>
<p>The additional aim would be to use techniques from uncertainty quantification and statistical emulation to provide more interpretability to those decisions.</p>
<p>This domain has been called FAT modelling in machine learning, but I prefer the acronym FIT for fairness, interpretability and transparency.</p>
<p>AutoAI makes us realise that AutoML isn’t sufficient for improving the performance of the system, because it works on a componentwise basis. Similarly, FIT machine learning models are not sufficient. We need to move from FIT models to FIT systems.</p>
<h2 id="statistical-emulation">Statistical Emulation</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_uq/includes/emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_uq/includes/emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="statistical-emulation-1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation000.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-1-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-1&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="statistical-emulation-1-caption" class="caption-frame">
<p>Figure: Real world systems consiste of simulators, that capture our domain knowledge about how our systems operate. Different simulators run at different speeds and granularities.</p>
</div>
</div>
<p>In many real world systems, decisions are made through simulating the environment. Simulations may operate at different granularities. For example, simulations are used in weather forecasts and climate forecasts. The UK Met office uses the same code for both, but operates climate simulations one at greater spatial and temporal resolutions.</p>
<div class="figure">
<div id="statistical-emulation-2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation001.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-2-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-2&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="statistical-emulation-2-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model.</p>
</div>
</div>
<p>A statistical emulator is a data-driven model that learns about the underlying simulation. Importantly, learns with uncertainty, so it ‘knows what it doesn’t know’. In practice, we can call the emulator in place of the simulator. If the emulator ‘doesn’t know’, it can call the simulator for the answer.</p>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-5-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-5&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="statistical-emulation-5-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.</p>
</div>
</div>
<div class="figure">
<div id="statistical-emulation-6-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation005.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-6-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-6&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="statistical-emulation-6-caption" class="caption-frame">
<p>Figure: In modern machine learning system design, the emulator may also consider the output of ML models (for monitoring bias or accuracy) and Operations Research models..</p>
</div>
</div>
<p>As well as reconstructing an individual simulator, the emulator can calibrate the simulation to the real world, by monitoring differences between the simulator and real data. This allows the emulator to characterise where the simulation can be relied on, i.e. we can validate the simulator.</p>
<p>Similarly, the emulator can adjudicate between simulations. This is known as <em>multi-fidelity emulation</em>. The emulator characterizes which emulations perform well where.</p>
<p>If all this modelling is done with judiscious handling of the uncertainty, the <em>computational doubt</em>, then the emulator can assist in desciding what experiment should be run next to aid a decision: should we run a simulator, in which case which one, or should we attempt to acquire data from a real world intervention.</p>
<h2 id="bayesian-inference-by-rejection-sampling">Bayesian Inference by Rejection Sampling</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-very-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-very-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>One view of Bayesian inference is to assume we are given a mechanism for generating samples, where we assume that mechanism is representing on accurate view on the way we believe the world works.</p>
<p>This mechanism is known as our <em>prior</em> belief.</p>
<p>We combine our prior belief with our observations of the real world by discarding all those samples that are inconsistent with our prior. The <em>likelihood</em> defines mathematically what we mean by inconsistent with the prior. The higher the noise level in the likelihood, the looser the notion of consistent.</p>
<p>The samples that remain are considered to be samples from the <em>posterior</em>.</p>
<p>This approach to Bayesian inference is closely related to two sampling techniques known as <em>rejection sampling</em> and <em>importance sampling</em>. It is realized in practice in an approach known as <em>approximate Bayesian computation</em> (ABC) or likelihood-free inference.</p>
<p>In practice, the algorithm is often too slow to be practical, because most samples will be inconsistent with the data and as a result the mechanism has to be operated many times to obtain a few posterior samples.</p>
<p>However, in the Gaussian process case, when the likelihood also assumes Gaussian noise, we can operate this mechanism mathematically, and obtain the posterior density <em>analytically</em>. This is the benefit of Gaussian processes.</p>
<div class="figure">
<div id="gp-rejection-samples-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gp_rejection_sample003.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gp_rejection_sample004.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gp_rejection_sample005.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="gp-rejection-samples-magnify" class="magnify" onclick="magnifyFigure(&#39;gp-rejection-samples&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="gp-rejection-samples-caption" class="caption-frame">
<p>Figure: One view of Bayesian inference is we have a machine for generating samples (the <em>prior</em>), and we discard all samples inconsistent with our data, leaving the samples of interest (the <em>posterior</em>). The Gaussian process allows us to do this analytically.</p>
</div>
</div>
<h2 id="deep-emulation">Deep Emulation</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_uq/includes/deep-emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_uq/includes/deep-emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing000.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ml-system-downstream-purchasing-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<p>As a solution we can use of <em>emulators</em>. When constructing an ML system, software engineers, ML engineers, economists and operations researchers are explicitly defining relationships between variables of interest in the system. That implicitly defines a joint distribution, <span class="math inline">$p(\dataVector^*, \dataVector)$</span>. In a decomposable system any sub-component may be defined as <span class="math inline">$p(\dataVector_\mathbf{i}|\dataVector_\mathbf{j})$</span> where <span class="math inline">$\dataVector_\mathbf{i}$</span> and <span class="math inline">$\dataVector_\mathbf{j}$</span> represent sub-sets of the full set of variables <span class="math inline">$\left\{\dataVector^*, \dataVector \right\}$</span>. In those cases where the relationship is deterministic, the probability density would collapse to a vector-valued deterministic function, <span class="math inline">$\mappingFunctionVector_\mathbf{i}\left(\dataVector_\mathbf{j}\right)$</span>.</p>
<p>Inter-variable relationships could be defined by, for example a neural network (machine learning), an integer program (operational research), or a simulation (supply chain). This makes probabilistic inference in this joint density for real world systems is either very hard or impossible.</p>
<p>Emulation is a form of meta-modelling: we construct a model of the model. We can define the joint density of an emulator as <span class="math inline">$s(\dataVector*, \dataVector)$</span>, but if this probability density is to be an accurate representation of our system, it is likely to be prohibitively complex. Current practice is to design an emulator to deal with a specific question. This is done by fitting an ML model to a simulation from the the appropriate conditional distribution, <span class="math inline">$p(\dataVector_\mathbf{i}|\dataVector_\mathbf{j})$</span>, which is intractable. The emulator provides an approximated answer of the form <span class="math inline">$s(\dataVector_\mathbf{i}|\dataVector_\mathbf{j})$</span>. Critically, an emulator should incorporate its uncertainty about its approximation. So the emulator answer will be less certain than direct access to the conditional <span class="math inline">$p(\dataVector_i|\dataVector_j)$</span>, but it may be sufficiently confident to act upon. Careful design of emulators to answer a given question leads to efficient diagnostics and understanding of the system. But in a complex interacting system an exponentially increasing number of questions can be asked. This calls for a system of automated construction of emulators which selects the right structure and redeploys the emulator as necessary. Rapid redeployment of emulators could exploit pre-existing emulators through <em>transfer learning</em>.</p>
<p>Automatically deploying these families of emulators for full system understanding is highly ambitious. It requires advances in engineering infrastructure, emulation and Bayesian optimization. However, the intermediate steps of developing this architecture also allow for automated monitoring of system accuracy and fairness. This facilitates AutoML on a component-wise basis which we can see as a simple implementation of AutoAI. The proposal is structured so that despite its technical ambition there is a smooth ramp of benefits to be derived across the programme of work.</p>
<p>In Applied Mathematics, the field studying these techniques is known as <em>uncertainty quantification</em>. The new challenge is the automation of emulator creation on demand to answer questions of interest and facilitate the system design, i.e. AutoAI through BSO.</p>
<p>At design stage, any particular AI task could be decomposed in multiple ways. Bayesian system optimization will assist both in determining the large-scale system design through exploring different decompositions and in refinement of the deployed system.</p>
<p>So far, most work on emulators has focussed on emulating a single component. Automated deployment and maintenance of ML systems requires networks of emulators that can be deployed and redeployed on demand depending on the particular question of interest. Therefore, the technical innovations we require are in the mathematical composition of emulator models <span class="citation" data-cites="Damianou:deepgp13 Pedikaris:nonlinear17">(Damianou and Lawrence 2013; Perdikaris et al. 2017)</span>. Different chains of emulators will need to be rapidly composed to make predictions of downstream performance. This requires rapid retraining of emulators and <em>propagation of uncertainty</em> through the emulation pipeline a process we call <em>deep emulation</em>.</p>
<!--Our main approach for this will be automated learning of the structure
of deep probabilistic models, such as deep Gaussian processes
[@Damianou:deepgp13]. The proposer is an international expert in this
domain.-->
<p>Recomposing the ML system requires structural learning of the network. By parameterizing covariance functions appropriately this can be done through Gaussian processes (e.g. <span class="citation" data-cites="Damianou:manifold12">(Damianou et al., n.d.)</span>), but one could also consider Bayesian neural networks and other generative models, e.g. Generative Adversarial Networks <span class="citation" data-cites="Goodfellow:gans14">(Goodfellow et al. 2014)</span>.</p>
<!-- This structural learning allows us to associate data with the relevant -->
<!-- layer of the model, rather than merely on the leaf nodes of the output -->
<!-- model. When deploying the deep Gaussian process as an emulator, this -->
<!-- allows for the possibility of learning the structure of the different -->
<!-- component parts of the underlying system. This should aid the user in -->
<!-- determining the ideal system decomposition. -->
<div class="figure">
<div id="ml-system-downstream-purchasing1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing001.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing1-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing1&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ml-system-downstream-purchasing1-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<div class="figure">
<div id="ml-system-downstream-purchasing2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing002.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing2-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing2&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ml-system-downstream-purchasing2-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<div class="figure">
<div id="ml-system-downstream-purchasing3-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing003.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing3-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing3&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="ml-system-downstream-purchasing3-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-5-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-5&#39;)">
<p>&lt;img class="img-button" src="{{"/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"&gt;</p>
</div>
<div id="statistical-emulation-5-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.</p>
</div>
</div>
<h2 id="conclusion">Conclusion</h2>
<p>Today’s artificial intelligence is fundamentally Machine Learning Systems design, but the systems we are building will not fulfill the promises we are making for them (The Great AI Fallacy). We are not yet ready to deploy automation in fully uncontrolled environments due to major issues around <em>intellectual debt</em>. Until we modify our approaches we will not be able to deliver on the promise. Until then, monitoring and upadate of deployed systems will be key to practical and safe AI.</p>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-Damianou:manifold12">
<p>Damianou, Andreas, Carl Henrik Ek, Michalis K. Titsias, and Neil D. Lawrence. n.d. "Manifold Relevance Determination." In.</p>
</div>
<div id="ref-Damianou:deepgp13">
<p>Damianou, Andreas, and Neil D. Lawrence. 2013. "Deep Gaussian Processes." In, 31:207–15.</p>
</div>
<div id="ref-Goodfellow:gans14">
<p>Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. "Generative Adversarial Nets." In <em>Advances in Neural Information Processing Systems 27</em>, edited by Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, 2672–80. Curran Associates, Inc.</p>
</div>
<div id="ref-Pedikaris:nonlinear17">
<p>Perdikaris, Paris, Maziar Raissi, Andreas Damianou, Neil D. Lawrence, and George Em Karnidakis. 2017. "Nonlinear Information Fusion Algorithms for Data-Efficient Multi-Fidelity Modelling." <em>Proc. R. Soc. A</em> 473 (20160751). <a href="https://doi.org/10.1098/rspa.2016.0751">https://doi.org/10.1098/rspa.2016.0751</a>.</p>
</div>
<div id="ref-Sculley:debt15">
<p>Sculley, D., Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-François Crespo, and Dan Dennison. 2015. "Hidden Technical Debt in Machine Learning Systems." In <em>Advances in Neural Information Processing Systems 28</em>, edited by Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, 2503–11. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf">http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf</a>.</p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>The GDPR is "General Data Protection Regulation" but it does not ‘protect data’ it ‘protects individuals’ with regard to decision making based on their personal data. The misnomer data-protection is unfortunate, a better way of viewing this legislation is "personal data rights" legislation.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

