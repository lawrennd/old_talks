---
title: "Deploying Machine Learning: Intellectual Debt and AutoAI"
venue: "Virtual Advances in Data Science Seminar, Manchester"
abstract: "<p>From the dawn of cybernetics, and across the last eight decades, we’ve worked to make machine learning methods successful. But now that these methods are being widely adopted we need to deal with the consequences of success. Many of those consequences can only be understood when a holistic approach to the machine learning problem is considered: the deployment of a method within a context for a particular objective. In this circumstance, it’s easy to see that questions of interpretability, fairness and transparency are all contextual. In this talk we summarize this challenge using Jonathan Zittrain’s term of “intellectual debt”, we discuss how it pans out in reality and how this challenge could be addressed using machine learning techniques to give us “Auto AI”. This work is sponsored by an ATI Senior AI Fellowship.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
blog: null
date: 2020-10-06
published: 2020-10-06
week: 0
reveal: 2020-10-06-deploying-machine-learning-systems-intellectual-debt-and-auto-ai.slides.html
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<h1 id="the-great-ai-fallacy">The Great AI Fallacy</h1>
<p>There is a lot of variation in the use of the term artificial intelligence. I’m sometimes asked to define it, but depending on whether you’re speaking to a member of the public, a fellow machine learning researcher, or someone from the business community, the sense of the term differs.</p>
<p>However, underlying its use I’ve detected one disturbing trend. A trend I’m beginining to think of as “The Great AI Fallacy”.</p>
<p>The fallacy is associated with an implicit promise that is embedded in many statements about Artificial Intelligence. Artificial Intelligence, as it currently exists, is merely a form of automated decision making. The implicit promise of Artificial Intelligence is that it will be the first wave of automation where the machine adapts to the human, rather than the human adapting to the machine.</p>
<p>How else can we explain the suspension of sensible business judgment that is accompanying the hype surrounding AI?</p>
<p>This fallacy is particularly pernicious because there are serious benefits to society in deploying this new wave of data-driven automated decision making. But the AI Fallacy is causing us to suspend our calibrated skepticism that is needed to deploy these systems safely and efficiently.</p>
<p>The problem is compounded because many of the techniques that we’re speaking of were originally developed in academic laboratories in isolation from real-world deployment.</p>
<div class="figure">
<div id="jeeves-springtime-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ai/Jeeves_in_the_Springtime_01.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="jeeves-springtime-magnify" class="magnify" onclick="magnifyFigure(&#39;jeeves-springtime&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="jeeves-springtime-caption" class="caption-frame">
<p>Figure: We seem to have fallen for a perspective on AI that suggests it will adapt to our schedule, rather in the manner of a 1930s manservant.</p>
</div>
</div>
<h2 id="artificial-vs-natural-systems">Artificial vs Natural Systems</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/artificial-vs-natural-systems-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/artificial-vs-natural-systems-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>Let’s take a step back from artificial intelligence, and consider natural intelligence. Or even more generally, let’s consider the contrast between an artificial <em>system</em> and an natural system. The key difference between the two is that artificial systems are <em>designed</em> whereas natural systems are <em>evolved</em>.</p>
<p>Systems design is a major component of all Engineering disciplines. The details differ, but there is a single common theme: achieve your objective with the minimal use of resources to do the job. That provides efficiency. The engineering designer imagines a solution that requires the minimal set of components to achieve the result. A water pump has one route through the pump. That minimises the number of components needed. Redundancy is introduced only in safety critical systems, such as aircraft control systems. Students of biology, however, will be aware that in nature system-redundancy is everywhere. Redundancy leads to robustness. For an organism to survive in an evolving environment it must first be robust, then it can consider how to be efficient. Indeed, organisms that evolve to be too efficient at a particular task, like those that occupy a niche environment, are particularly vulnerable to extinction.</p>
<p>This notion is akin to the idea that only the best will survive, popularly encoded into an notion of evolution by Herbert Spencer’s quote.</p>
<blockquote>
<p>Survival of the fittest</p>
<p><a href="https://en.wikipedia.org/wiki/Herbert_Spencer">Herbet Spencer</a>, 1864</p>
</blockquote>
<p>Darwin himself never said “Survival of the Fittest” he talked about evolution by natural selection.</p>
<blockquote>
<p>Non-survival of the non-fit</p>
</blockquote>
<p>Evolution is better described as “non-survival of the non-fit”. You don’t have to be the fittest to survive, you just need to avoid the pitfalls of life. This is the first priority.</p>
<p>So it is with natural vs artificial intelligences. Any natural intelligence that was not robust to changes in its external environment would not survive, and therefore not reproduce. In contrast the artificial intelligences we produce are designed to be efficient at one specific task: control, computation, playing chess. They are <em>fragile</em>.</p>
<p>The first rule of a natural system is not be intelligent, it is “don’t be stupid”.</p>
<p>A mistake we make in the design of our systems is to equate fitness with the objective function, and to assume it is known and static. In practice, a real environment would have an evolving fitness function which would be unknown at any given time.</p>
<p>You can also read this blog post on <a href="http://inverseprobability.com/2018/02/06/natural-and-artificial-intelligence">Natural and Artificial Intelligence</a>..</p>
<p>The first criterion of a natural intelligence is <em>don’t fail</em>, not because it has a will or intent of its own, but because if it had failed it wouldn’t have stood the test of time. It would no longer exist. In contrast, the mantra for artificial systems is to be more efficient. Our artificial systems are often given a single objective (in machine learning it is encoded in a mathematical function) and they aim to achieve that objective efficiently. These are different characteristics. Even if we wanted to incorporate <em>don’t fail</em> in some form, it is difficult to design for. To design for “don’t fail”, you have to consider every which way in which things can go wrong, if you miss one you fail. These cases are sometimes called corner cases. But in a real, uncontrolled environment, almost everything is a corner. It is difficult to imagine everything that can happen. This is why most of our automated systems operate in controlled environments, for example in a factory, or on a set of rails. Deploying automated systems in an uncontrolled environment requires a different approach to systems design. One that accounts for uncertainty in the environment and is robust to unforeseen circumstances.</p>
<h2 id="todays-artificial-systems">Today’s Artificial Systems</h2>
<p>The systems we produce today only work well when their tasks are pigeonholed, bounded in their scope. To achieve robust artificial intelligences we need new approaches to both the design of the individual components, and the combination of components within our AI systems. We need to deal with uncertainty and increase robustness. Today, it is easy to make a fool of an artificial intelligent agent, technology needs to address the challenge of the uncertain environment to achieve robust intelligences.</p>
<p>However, even if we find technological solutions for these challenges, it may be that the essence of human intelligence remains out of reach. It may be that the most quintessential element of our intelligence is defined by limitations. Limitations that computers have never experienced.</p>
<p>Claude Shannon developed the idea of information theory: the mathematics of information. He defined the amount of information we gain when we learn the result of a coin toss as a “bit” of information. A typical computer can communicate with another computer with a billion bits of information per second. Equivalent to a billion coin tosses per second. So how does this compare to us? Well, we can also estimate the amount of information in the English language. Shannon estimated that the average English word contains around 12 bits of information, twelve coin tosses, this means our verbal communication rates are only around the order of tens to hundreds of bits per second. Computers communicate tens of millions of times faster than us, in relative terms we are constrained to a bit of pocket money, while computers are corporate billionaires.</p>
<p>Our intelligence is not an island, it interacts, it infers the goals or intent of others, it predicts our own actions and how we will respond to others. We are social animals, and together we form a communal intelligence that characterises our species. For intelligence to be communal, our ideas to be shared somehow. We need to overcome this bandwidth limitation. The ability to share and collaborate, despite such constrained ability to communicate, characterises us. We must intellectually commune with one another. We cannot communicate all of what we saw, or the details of how we are about to react. Instead, we need a shared understanding. One that allows us to infer each other’s intent through context and a common sense of humanity. This characteristic is so strong that we anthropomorphise any object with which we interact. We apply moods to our cars, our cats, our environment. We seed the weather, volcanoes, trees with intent. Our desire to communicate renders us intellectually animist.</p>
<p>But our limited bandwidth doesn’t constrain us in our imaginations. Our consciousness, our sense of self, allows us to play out different scenarios. To internally observe how our self interacts with others. To learn from an internal simulation of the wider world. Empathy allows us to understand others’ likely responses without having the full detail of their mental state. We can infer their perspective. Self-awareness also allows us to understand our own likely future responses, to look forward in time, play out a scenario. Our brains contain a sense of self and a sense of others. Because our communication cannot be complete it is both contextual and cultural. When driving a car in the UK a flash of the lights at a junction concedes the right of way and invites another road user to proceed, whereas in Italy, the same flash asserts the right of way and warns another road user to remain.</p>
<p>Our main intelligence is our social intelligence, intelligence that is dedicated to overcoming our bandwidth limitation. We are individually complex, but as a society we rely on shared behaviours and oversimplification of our selves to remain coherent.</p>
<p>This nugget of our intelligence seems impossible for a computer to recreate directly, because it is a consequence of our evolutionary history. The computer, on the other hand, was born into a world of data, of high bandwidth communication. It was not there through the genesis of our minds and the cognitive compromises we made are lost to time. To be a truly human intelligence you need to have shared that journey with us.</p>
<p>Of course, none of this prevents us emulating those aspects of human intelligence that we observe in humans. We can form those emulations based on data. But even if an artificial intelligence can emulate humans to a high degree of accuracy it is a different type of intelligence. It is not constrained in the way human intelligence is. You may ask does it matter? Well, it is certainly important to us in many domains that there’s a human pulling the strings. Even in pure commerce it matters: the narrative story behind a product is often as important as the product itself. Handmade goods attract a price premium over factory made. Or alternatively in entertainment: people pay more to go to a live concert than for streaming music over the internet. People will also pay more to go to see a play in the theatre rather than a movie in the cinema.</p>
<p>In many respects I object to the use of the term Artificial Intelligence. It is poorly defined and means different things to different people. But there is one way in which the term is very accurate. The term artificial is appropriate in the same way we can describe a plastic plant as an artificial plant. It is often difficult to pick out from afar whether a plant is artificial or not. A plastic plant can fulfil many of the functions of a natural plant, and plastic plants are more convenient. But they can never replace natural plants.</p>
<p>In the same way, our natural intelligence is an evolved thing of beauty, a consequence of our limitations. Limitations which don’t apply to artificial intelligences and can only be emulated through artificial means. Our natural intelligence, just like our natural landscapes, should be treasured and can never be fully replaced.</p>
<h1 id="intellectual-debt">Intellectual Debt</h1>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/intellectual-debt-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/intellectual-debt-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="intellectual-debt-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ai/2020-02-12-intellectual-debt.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="intellectual-debt-magnify" class="magnify" onclick="magnifyFigure(&#39;intellectual-debt&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="intellectual-debt-caption" class="caption-frame">
<p>Figure: Jonathan Zittrain’s term to describe the challenges of explanation that come with AI is Intellectual Debt.</p>
</div>
</div>
<p>In computer systems the concept of <em>technical debt</em> has been surfaced by authors including <span class="citation" data-cites="Sculley:debt15">Sculley et al. (2015)</span>. It is an important concept, that I think is somewhat hidden from the academic community, because it is a phenomenon that occurs when a computer software system is deployed.</p>
<h2 id="buying-system">Buying System</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/buying-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/buying-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="buying-system-components-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/software/buying-schematic.svg" width="40%" style=" ">
</object>
</div>
<div id="buying-system-components-magnify" class="magnify" onclick="magnifyFigure(&#39;buying-system-components&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="buying-system-components-caption" class="caption-frame">
<p>Figure: The components of a putative automated buying system</p>
</div>
</div>
<h2 id="monolithic-system">Monolithic System</h2>
<div class="figure">
<div id="ml-system-monolith-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-monolith-purchasing.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-monolith-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-monolith&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ml-system-monolith-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="service-oriented-architecture">Service Oriented Architecture</h2>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing000.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ml-system-downstream-purchasing-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="to-banking">… to Banking</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/buying-to-banking.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/buying-to-banking.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="ml-system-downstream-banking-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-banking000.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-downstream-banking-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-banking&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ml-system-downstream-banking-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="safeboda">SafeBoda</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/safe-boda.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/safe-boda.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="safe-boda-system-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ai/safe-boda.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="safe-boda-system-magnify" class="magnify" onclick="magnifyFigure(&#39;safe-boda-system&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="safe-boda-system-caption" class="caption-frame">
<p>Figure: SafeBoda is a ride allocation system for Boda Boda drivers. Let’s imagine the capabilities we need for such an AI system.</p>
</div>
</div>
<p><a href="https://safeboda.com/ug/index.php#whysafeboda">SafeBoda</a> is a Kampala based rider allocation system for Boda Boda drivers. Boda boda are motorcycle taxis which give employment to, often young men, across Kampala. Safe Boda is driven by the knowledge that road accidents are set to match HIV/AIDS as the highest cause of death in low/middle income families by 2030.</p>
<blockquote>
<p>With road accidents set to match HIV/AIDS as the highest cause of death in low/middle income countries by 2030, SafeBoda’s aim is to modernise informal transportation and ensure safe access to mobility.</p>
</blockquote>
<h2 id="technical-consequence">Technical Consequence</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/ml-system-decomposability.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/ml-system-decomposability.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>Classical systems design assumes that the system is decomposable. That we can decompose the complex decision making process into distinct and independently designable parts. The composition of these parts gives us our final system.</p>
<p>Nicolas Negroponte, the original founder of MIT’s media lab used to write a column called ‘bits and atoms’. This referred to the ability of information to effect movement of goods in the physical world. It is this interaction where machine learning technologies have the possibility to bring most benefit.</p>
<h2 id="fit-models-to-fit-systems">FIT Models to FIT Systems</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/fit-systems.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/fit-systems.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>Zittrain points out the challenge around the lack of interpretability of individual ML models as the origin of intellectual debt. In machine learning I refer to work in this area as fairness, interpretability and transparency or FIT models. To an extent I agree with Zittrain, but if we understand the context and purpose of the decision making, I believe this is readily put right by the correct monitoring and retraining regime around the model. A concept I refer to as “progression testing”. Indeed, the best teams do this at the moment, and their failure to do it feels more of a matter of technical debt rather than intellectual, because arguably it is a maintenance task rather than an explanation task. After all, we have good statistical tools for interpreting individual models and decisions when we have the context. We can linearise around the operating point, we can perform counterfactual tests on the model. We can build empirical validation sets that explore fairness or accuracy of the model.</p>
<p>So, this is where, my understanding of intellectual debt in ML systems departs, I believe from John Zittrain’s. The long-term challenge is <em>not</em> in the individual model. We have excellent statistical tools for validating what any individual model, the long-term challenge is the complex interaction between different components in the decomposed system, where the original intent of each component has been forgotten (except perhaps by Lancelot) and each service has been repurposed. We need to move from FIT models to FIT systems.</p>
<p>How to address these challenges? With collaborators I’ve been working towards a solution that contains broadly two parts. The first part is what we refer to as “Data-Oriented Architectures”. The second part is “meta modelling”, machine learning techniques that help us model the models.</p>
<div class="figure">
<div id="ride-allocation-system-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ride-allocation-prediction.svg" width="60%" style=" ">
</object>
</div>
<div id="ride-allocation-system-magnify" class="magnify" onclick="magnifyFigure(&#39;ride-allocation-system&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ride-allocation-system-caption" class="caption-frame">
<p>Figure: Some software components in a ride allocation system. Circled components are hypothetical, rectangles represent actual data.</p>
</div>
</div>
<h1 id="a-solution">A Solution</h1>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/deploying-machine-learning-systems-intellectual-debt-and-auto-ai.mdtmp.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/deploying-machine-learning-systems-intellectual-debt-and-auto-ai.mdtmp.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<h2 id="data-oriented-architectures">Data-oriented Architectures</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-oriented-architectures-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-oriented-architectures-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>Data-oriented architectures aim to address the rat’s nest that is the current interaction between the services in a service-oriented architecture. It does this by introducing data-oriented programming. The data-oriented programming language tracks the movement of data between each service.</p>
<p>Service-oriented programming style is a necessary, but not sufficient approach to data-oriented programming. Data-oriented programming is not only about the individual services, but how they are connected. Which service is calling which and where the flow of the data through the system occurs?</p>
<p>If each service has its inputs and outputs declared on a wider ecosystem, then we can programmatically determine which inputs effect which decisions. This programmatic discovery is vital because as systems are built compositionally, the actual inputs that affect a final decision may not be known to any of the software engineers who are maintaining the system.</p>
<h2 id="milan">Milan</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/milan.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/milan.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="milan-schematic-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/software/milan-schematic.svg" width="80%" style=" ">
</object>
</div>
<div id="milan-schematic-magnify" class="magnify" onclick="magnifyFigure(&#39;milan-schematic&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="milan-schematic-caption" class="caption-frame">
<p>Figure: The Milan Software has a general purpose stream algebra at its core, the Milan IL.</p>
</div>
</div>
<div class="figure">
<div id="milan-software-page-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/software/milan.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="milan-software-page-magnify" class="magnify" onclick="magnifyFigure(&#39;milan-software-page&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="milan-software-page-caption" class="caption-frame">
<p>Figure: The Milan Software is designed for building modern AI systems. <a href="https://github.com/amzn/milan/" class="uri">https://github.com/amzn/milan/</a></p>
</div>
</div>
<p>At Amazon my team built a <em>data-oriented programming</em> language which is <a href="https://github.com/amzn/milan">now available through BSD license</a>. The language is called Milan. The team was led by Tom Borchert, quoting from <a href="https://tborchertblog.wordpress.com/2020/02/13/28/">Tom’s blog on Milan</a>:</p>
<blockquote>
<p>Milan has three components:</p>
<ol type="1">
<li><p>A general-purpose stream algebra that encodes relationships between data streams (the Milan Intermediate Language or Milan IL)</p></li>
<li><p>A Scala library for building programs in that algebra.</p></li>
<li><p>A compiler that takes programs expressed in Milan IL and produces a Flink application that executes the program.</p></li>
</ol>
<p>Component (2) can be extended to support interfaces in additional languages, and component (3) can be extended to support additional runtime targets. Considering just the multiple interfaces and the multiple runtimes, Milan looks a lot like the much more mature Apache Beam. The difference lies in (1), Milan’s general-purpose stream algebra.</p>
</blockquote>
<p>It is through the general-purpose stream algebra that we hope to make significant inroads on the intellectual debt challenge.</p>
<p>The stream algebra defines the relationship between different machine learning components in the wider software architecture. Composition of multiple services cannot occur without a signature existing within the stream algebra. The Milan IL becomes the key information structure that is required to reason about the wider software system.</p>
<h2 id="context">Context</h2>
<p>This deals with the challenges that arise through the <em>death of the programmer</em> because we can now see the context around each service. This allows us to design the relevant validation checks to ensure that accuracy and fairness are maintained. By recompiling the algebra to focus on a particular decision within the system we can also derive new statistical tests to validate performance. These are the checks that we refer to as progression testing. The loss of programmer control means that we can no longer rely on software tests written at design time, we must have the capability to deploy new (statistical) tests after deployment as the uses to which each service is placed extend to previously un-envisaged domains.</p>
<h2 id="stateless-services">Stateless Services</h2>
<p>Importantly, Milan does not place onerous constraints on the builders of individual machine learning models (or other components). Standard modelling frameworks can be used. The main constraint is that any code that is not visible to the ecosystem does not maintain or store global state. This condition implies that the parameters of any machine learning model need to also be declared as an input to the model within the Milan IL.</p>
<h2 id="meta-modelling">Meta Modelling</h2>
<div class="figure">
<div id="emukit-software-page-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/uq/emukit-software-page.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-software-page-magnify" class="magnify" onclick="magnifyFigure(&#39;emukit-software-page&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="emukit-software-page-caption" class="caption-frame">
<p>Figure: The Emukit software is a set of software tools for emulation and surrogate modeling. <a href="https://amzn.github.io/emukit/" class="uri">https://amzn.github.io/emukit/</a></p>
</div>
</div>
<p>Where does machine learning come in? The strategy I propose is that the Milan IL is integrated with meta-modelling approaches to assist in the explanation of the decision-making framework. At their simplest these approaches may be novelty detection algorithms on the data streams that are emerging from a given service. This is a form of <em>progression testing</em>. But we can go much further. By knowing the training data, the inputs and outputs of the individual services in the software ecosystem, we can build meta-models that test for fairness, accuracy not just of individual system components, but short or long cascades of decision making. Through the use of the Milan IL algebra all these tests could be automatically deployed. The focus of machine learning is on the models-that-model-the-models. The meta-models.</p>
<p>In Amazon, our own focus was on the use of statistical emulators, sometimes known as surrogate models, for fulfilling this task. The work we were putting into this route is available through another software package, <a href="https://amzn.github.io/emukit/">Emukit, a framework for decision making under uncertainty</a>. With collaborators my current focus for addressing these issues is a form of fusion of Emukit and Milan (Milemukit??). But the nature of this fusion requires testing on real world problem sets. A task we hope to carry out in close collaboration with colleagues at <a href="http://www.datascienceafrica.org/">Data Science Africa</a>.</p>
<h2 id="deep-emulation">Deep Emulation</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/deep-emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/deep-emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing000.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ml-system-downstream-purchasing-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<p>As a solution we can use of <em>emulators</em>. When constructing an ML system, software engineers, ML engineers, economists and operations researchers are explicitly defining relationships between variables of interest in the system. That implicitly defines a joint distribution, <span class="math inline">$p(\dataVector^*, \dataVector)$</span>. In a decomposable system any sub-component may be defined as <span class="math inline">$p(\dataVector_\mathbf{i}|\dataVector_\mathbf{j})$</span> where <span class="math inline">$\dataVector_\mathbf{i}$</span> and <span class="math inline">$\dataVector_\mathbf{j}$</span> represent sub-sets of the full set of variables <span class="math inline">$\left\{\dataVector^*, \dataVector \right\}$</span>. In those cases where the relationship is deterministic, the probability density would collapse to a vector-valued deterministic function, <span class="math inline">$\mappingFunctionVector_\mathbf{i}\left(\dataVector_\mathbf{j}\right)$</span>.</p>
<p>Inter-variable relationships could be defined by, for example a neural network (machine learning), an integer program (operational research), or a simulation (supply chain). This makes probabilistic inference in this joint density for real world systems is either very hard or impossible.</p>
<p>Emulation is a form of meta-modelling: we construct a model of the model. We can define the joint density of an emulator as <span class="math inline">$s(\dataVector*, \dataVector)$</span>, but if this probability density is to be an accurate representation of our system, it is likely to be prohibitively complex. Current practice is to design an emulator to deal with a specific question. This is done by fitting an ML model to a simulation from the the appropriate conditional distribution, <span class="math inline">$p(\dataVector_\mathbf{i}|\dataVector_\mathbf{j})$</span>, which is intractable. The emulator provides an approximated answer of the form <span class="math inline">$s(\dataVector_\mathbf{i}|\dataVector_\mathbf{j})$</span>. Critically, an emulator should incorporate its uncertainty about its approximation. So the emulator answer will be less certain than direct access to the conditional <span class="math inline">$p(\dataVector_i|\dataVector_j)$</span>, but it may be sufficiently confident to act upon. Careful design of emulators to answer a given question leads to efficient diagnostics and understanding of the system. But in a complex interacting system an exponentially increasing number of questions can be asked. This calls for a system of automated construction of emulators which selects the right structure and redeploys the emulator as necessary. Rapid redeployment of emulators could exploit pre-existing emulators through <em>transfer learning</em>.</p>
<p>Automatically deploying these families of emulators for full system understanding is highly ambitious. It requires advances in engineering infrastructure, emulation and Bayesian optimization. However, the intermediate steps of developing this architecture also allow for automated monitoring of system accuracy and fairness. This facilitates AutoML on a component-wise basis which we can see as a simple implementation of AutoAI. The proposal is structured so that despite its technical ambition there is a smooth ramp of benefits to be derived across the programme of work.</p>
<p>In Applied Mathematics, the field studying these techniques is known as <em>uncertainty quantification</em>. The new challenge is the automation of emulator creation on demand to answer questions of interest and facilitate the system design, i.e. AutoAI through BSO.</p>
<p>At design stage, any particular AI task could be decomposed in multiple ways. Bayesian system optimization will assist both in determining the large-scale system design through exploring different decompositions and in refinement of the deployed system.</p>
<p>So far, most work on emulators has focussed on emulating a single component. Automated deployment and maintenance of ML systems requires networks of emulators that can be deployed and redeployed on demand depending on the particular question of interest. Therefore, the technical innovations we require are in the mathematical composition of emulator models <span class="citation" data-cites="Damianou:deepgp13 Pedikaris:nonlinear17">(Damianou and Lawrence 2013; Perdikaris et al. 2017)</span>. Different chains of emulators will need to be rapidly composed to make predictions of downstream performance. This requires rapid retraining of emulators and <em>propagation of uncertainty</em> through the emulation pipeline a process we call <em>deep emulation</em>.</p>
<!--Our main approach for this will be automated learning of the structure
of deep probabilistic models, such as deep Gaussian processes
[@Damianou:deepgp13]. The proposer is an international expert in this
domain.-->
<p>Recomposing the ML system requires structural learning of the network. By parameterizing covariance functions appropriately this can be done through Gaussian processes (e.g. <span class="citation" data-cites="Damianou:manifold12">(Damianou et al., n.d.)</span>), but one could also consider Bayesian neural networks and other generative models, e.g. Generative Adversarial Networks <span class="citation" data-cites="Goodfellow:gans14">(Goodfellow et al. 2014)</span>.</p>
<!-- This structural learning allows us to associate data with the relevant -->
<!-- layer of the model, rather than merely on the leaf nodes of the output -->
<!-- model. When deploying the deep Gaussian process as an emulator, this -->
<!-- allows for the possibility of learning the structure of the different -->
<!-- component parts of the underlying system. This should aid the user in -->
<!-- determining the ideal system decomposition. -->
<div class="figure">
<div id="ml-system-downstream-purchasing1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing001.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing1-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing1&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ml-system-downstream-purchasing1-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<div class="figure">
<div id="ml-system-downstream-purchasing2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing002.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing2-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing2&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ml-system-downstream-purchasing2-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<div class="figure">
<div id="ml-system-downstream-purchasing3-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-purchasing003.svg" width="75%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing3-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-purchasing3&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="ml-system-downstream-purchasing3-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="statistical-emulation">Statistical Emulation</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<div class="figure">
<div id="statistical-emulation-1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation000.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-1-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-1&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="statistical-emulation-1-caption" class="caption-frame">
<p>Figure: Real world systems consiste of simulators, that capture our domain knowledge about how our systems operate. Different simulators run at different speeds and granularities.</p>
</div>
</div>
<p>In many real world systems, decisions are made through simulating the environment. Simulations may operate at different granularities. For example, simulations are used in weather forecasts and climate forecasts. The UK Met office uses the same code for both, but operates climate simulations one at greater spatial and temporal resolutions.</p>
<div class="figure">
<div id="statistical-emulation-2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation001.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-2-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-2&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="statistical-emulation-2-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model.</p>
</div>
</div>
<p>A statistical emulator is a data-driven model that learns about the underlying simulation. Importantly, learns with uncertainty, so it ‘knows what it doesn’t know’. In practice, we can call the emulator in place of the simulator. If the emulator ‘doesn’t know’, it can call the simulator for the answer.</p>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-5-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-5&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="statistical-emulation-5-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.</p>
</div>
</div>
<div class="figure">
<div id="statistical-emulation-6-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation005.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-6-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-6&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="statistical-emulation-6-caption" class="caption-frame">
<p>Figure: In modern machine learning system design, the emulator may also consider the output of ML models (for monitoring bias or accuracy) and Operations Research models..</p>
</div>
</div>
<p>As well as reconstructing an individual simulator, the emulator can calibrate the simulation to the real world, by monitoring differences between the simulator and real data. This allows the emulator to characterise where the simulation can be relied on, i.e. we can validate the simulator.</p>
<p>Similarly, the emulator can adjudicate between simulations. This is known as <em>multi-fidelity emulation</em>. The emulator characterizes which emulations perform well where.</p>
<p>If all this modelling is done with judiscious handling of the uncertainty, the <em>computational doubt</em>, then the emulator can assist in desciding what experiment should be run next to aid a decision: should we run a simulator, in which case which one, or should we attempt to acquire data from a real world intervention.</p>
<h2 id="bayesian-inference-by-rejection-sampling">Bayesian Inference by Rejection Sampling</h2>
<p><span style="text-align:right"><span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-intro-very-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-intro-very-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></span></p>
<p>One view of Bayesian inference is to assume we are given a mechanism for generating samples, where we assume that mechanism is representing on accurate view on the way we believe the world works.</p>
<p>This mechanism is known as our <em>prior</em> belief.</p>
<p>We combine our prior belief with our observations of the real world by discarding all those samples that are inconsistent with our prior. The <em>likelihood</em> defines mathematically what we mean by inconsistent with the prior. The higher the noise level in the likelihood, the looser the notion of consistent.</p>
<p>The samples that remain are considered to be samples from the <em>posterior</em>.</p>
<p>This approach to Bayesian inference is closely related to two sampling techniques known as <em>rejection sampling</em> and <em>importance sampling</em>. It is realized in practice in an approach known as <em>approximate Bayesian computation</em> (ABC) or likelihood-free inference.</p>
<p>In practice, the algorithm is often too slow to be practical, because most samples will be inconsistent with the data and as a result the mechanism has to be operated many times to obtain a few posterior samples.</p>
<p>However, in the Gaussian process case, when the likelihood also assumes Gaussian noise, we can operate this mechanism mathematically, and obtain the posterior density <em>analytically</em>. This is the benefit of Gaussian processes.</p>
<div class="figure">
<div id="gp-rejection-samples-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gp_rejection_sample003.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gp_rejection_sample004.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gp_rejection_sample005.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="gp-rejection-samples-magnify" class="magnify" onclick="magnifyFigure(&#39;gp-rejection-samples&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="gp-rejection-samples-caption" class="caption-frame">
<p>Figure: One view of Bayesian inference is we have a machine for generating samples (the <em>prior</em>), and we discard all samples inconsistent with our data, leaving the samples of interest (the <em>posterior</em>). The Gaussian process allows us to do this analytically.</p>
</div>
</div>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-5-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-5&#39;)">
<p>&lt;img class=“img-button” src=“{{”/assets/images/Magnify_Large.svg" | relative_url }}" style=“width:1.5ex”&gt;</p>
</div>
<div id="statistical-emulation-5-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.</p>
</div>
</div>
<h2 id="conclusion">Conclusion</h2>
<p>Today’s artificial intelligence is fundamentally Machine Learning Systems design, but the systems we are building will not fulfill the promises we are making for them. We are not yet ready to deploy automation in fully uncontrolled environments. Until we modify our approaches we will not be able to deliver on the promise. Until then, monitoring and upadate of deployed systems will be key to practical and safe AI.</p>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-Damianou:manifold12">
<p>Damianou, Andreas, Carl Henrik Ek, Michalis K. Titsias, and Neil D. Lawrence. n.d. “Manifold Relevance Determination.” In.</p>
</div>
<div id="ref-Damianou:deepgp13">
<p>Damianou, Andreas, and Neil D. Lawrence. 2013. “Deep Gaussian Processes.” In, 31:207–15.</p>
</div>
<div id="ref-Goodfellow:gans14">
<p>Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Nets.” In <em>Advances in Neural Information Processing Systems 27</em>, edited by Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, 2672–80. Curran Associates, Inc.</p>
</div>
<div id="ref-Pedikaris:nonlinear17">
<p>Perdikaris, Paris, Maziar Raissi, Andreas Damianou, Neil D. Lawrence, and George Em Karnidakis. 2017. “Nonlinear Information Fusion Algorithms for Data-Efficient Multi-Fidelity Modelling.” <em>Proc. R. Soc. A</em> 473 (20160751). <a href="https://doi.org/10.1098/rspa.2016.0751">https://doi.org/10.1098/rspa.2016.0751</a>.</p>
</div>
<div id="ref-Sculley:debt15">
<p>Sculley, D., Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-François Crespo, and Dan Dennison. 2015. “Hidden Technical Debt in Machine Learning Systems.” In <em>Advances in Neural Information Processing Systems 28</em>, edited by Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, 2503–11. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf">http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf</a>.</p>
</div>
</div>

