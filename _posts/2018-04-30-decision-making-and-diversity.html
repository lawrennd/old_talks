---
title: "Decision Making and Diversity"
venue: "CFI Lunchtime Seminar"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: Amazon Cambridge and University of Sheffield
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
blog: 2018-02-06-natural-and-artificial-intelligence.md
blog: 2017-11-15-decision-making.md
blog: 2015-12-04-what-kind-of-ai.md
date: 2018-04-30
published: 2018-04-30
reveal: 2018-04-30-decision-making-and-diversity.slides.html
ipynb: 2018-04-30-decision-making-and-diversity.ipynb
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Front matter -->
<p>.</p>
<!---->
<!--Back matter-->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<h2 id="justice-whats-the-right-thing-to-do-edit">Justice: What's The Right Thing to Do? <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/justice-sandel.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/justice-sandel.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="justice-whats-the-right-thing-to-do-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/philosophy/justice-whats-the-right-thing-to-do.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="justice-whats-the-right-thing-to-do-magnify" class="magnify" onclick="magnifyFigure(&#39;justice-whats-the-right-thing-to-do&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="justice-whats-the-right-thing-to-do-caption" class="caption-frame">
<p>Figure: Sandel's book looks at how to do the right thing with a context of moreal philosophy. <span class="citation">Sandel (2010)</span></p>
</div>
</div>
<p>In the book &quot;Justice: What's The Right Thing to Do?&quot; <span class="citation">(Sandel 2010)</span> Michael Sandel aims to help us answer questions about how to do the right thing by giving some context and background in moral philosophy. Sandel is a philosopher based at Harvard University who is reknowned for his popular treatments of the subject. He starts by illustrating decision making through the <a href="https://en.wikipedia.org/wiki/Trolley_problem">'trolley' problem</a>.</p>
<h2 id="the-trolley-problem-edit">The Trolley Problem <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-switch.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-switch.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="trolley-problem-original-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="../slides/diagrams/ai/Trolley_1.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="trolley-problem-original-magnify" class="magnify" onclick="magnifyFigure(&#39;trolley-problem-original&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="trolley-problem-original-caption" class="caption-frame">
<p>Figure: The trolley problem in its original form.</p>
</div>
</div>
<h2 id="the-push-and-the-trolley-edit">The Push and the Trolley <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-push.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-push.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="the-trolley-problem-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="../slides/diagrams/ai/trolley2.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-trolley-problem-magnify" class="magnify" onclick="magnifyFigure(&#39;the-trolley-problem&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="the-trolley-problem-caption" class="caption-frame">
<p>Figure: The trolley problem.</p>
</div>
</div>
<h2 id="prospect-theory-edit">Prospect Theory <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-towards-variance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-towards-variance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<ul>
<li>Daniel Kahneman's Nobel Memorial Prize in Economics was awarded for the idea of <em>prospect theory</em>.</li>
<li>Kahneman describes the theory and its background in his book, &quot;Thinking Fast and Slow&quot; <span class="citation">(Kahneman 2011)</span>.</li>
<li>Empirical theory about how people are responsive to change in circumstance, not absolute circumstance.</li>
</ul>
<h2 id="subjective-utility">Subjective Utility</h2>
<ul>
<li>Bentham's ideas focussed around the idea of a global utility.</li>
<li>Natural selection insists there must be <em>variation</em> in the population</li>
<li>Without variation, there is no separation between effective and ineffective strategies.</li>
</ul>
<h2 id="a-cognitive-bias-towards-variance">A Cognitive Bias towards Variance</h2>
<ul>
<li>Kahneman explores our tendency to produce overcomplicated explanations</li>
<li>Prediction is <br /><span class="math display">model + data → prediction</span><br /></li>
<li>Models fail as overly simple or overly complex</li>
</ul>
<h2 id="bias-vs-variance-edit">Bias vs Variance <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<ul>
<li>'bias variance dilemma' <span class="citation">Geman, Bienenstock, and Doursat (1992)</span></li>
<li>Decompose errors as
<ol style="list-style-type: decimal">
<li>due to oversimplification (the bias error) and</li>
<li>those due to insufficient data to underpin a complex model (variance error).</li>
</ol></li>
</ul>
<h2 id="in-machine-learning">In Machine Learning</h2>
<ul>
<li>Two approaches</li>
<li>Use simpler models (better consistency and generalization)</li>
<li>Use more complex models and average.</li>
</ul>
<h2 id="bias-vs-variance-error-plots-edit">Bias vs Variance Error Plots <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/bias-variance-plots.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/bias-variance-plots.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Helper function for sampling data from two different classes.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> numpy <span class="im">as</span> np</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> create_data(per_cluster<span class="op">=</span><span class="dv">30</span>):
    <span class="co">&quot;&quot;&quot;Create a randomly sampled data set</span>
<span class="co">    </span>
<span class="co">    :param per_cluster: number of points in each cluster</span>
<span class="co">    &quot;&quot;&quot;</span>
    X <span class="op">=</span> []
    y <span class="op">=</span> []
    scale <span class="op">=</span> <span class="dv">3</span>
    prec <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(scale<span class="op">*</span>scale)
    pos_mean <span class="op">=</span> [[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>],[<span class="dv">0</span>,<span class="fl">0.5</span>],[<span class="dv">1</span>,<span class="dv">0</span>]]
    pos_cov <span class="op">=</span> [[prec, <span class="dv">0</span>.], [<span class="dv">0</span>., prec]]
    neg_mean <span class="op">=</span> [[<span class="dv">0</span>, <span class="op">-</span><span class="fl">0.5</span>],[<span class="dv">0</span>,<span class="op">-</span><span class="fl">0.5</span>],[<span class="dv">0</span>,<span class="op">-</span><span class="fl">0.5</span>]]
    neg_cov <span class="op">=</span> [[prec, <span class="dv">0</span>.], [<span class="dv">0</span>., prec]]
    <span class="cf">for</span> mean <span class="kw">in</span> pos_mean:
        X.append(np.random.multivariate_normal(mean<span class="op">=</span>mean, cov<span class="op">=</span>pos_cov, size<span class="op">=</span>per_class))
        y.append(np.ones((per_class, <span class="dv">1</span>)))
    <span class="cf">for</span> mean <span class="kw">in</span> neg_mean:
        X.append(np.random.multivariate_normal(mean<span class="op">=</span>mean, cov<span class="op">=</span>neg_cov, size<span class="op">=</span>per_class))
        y.append(np.zeros((per_class, <span class="dv">1</span>)))
    <span class="cf">return</span> np.vstack(X), np.vstack(y).flatten()</code></pre></div>
<p>Helper function for plotting the decision boundary of the SVM.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> plot_contours(ax, cl, xx, yy, <span class="op">**</span>params):
    <span class="co">&quot;&quot;&quot;Plot the decision boundaries for a classifier.</span>

<span class="co">    :param ax: matplotlib axes object</span>
<span class="co">    :param cl: a classifier</span>
<span class="co">    :param xx: meshgrid ndarray</span>
<span class="co">    :param yy: meshgrid ndarray</span>
<span class="co">    :param params: dictionary of params to pass to contourf, optional</span>
<span class="co">    &quot;&quot;&quot;</span>
    Z <span class="op">=</span> cl.decision_function(np.c_[xx.ravel(), yy.ravel()])
    Z <span class="op">=</span> Z.reshape(xx.shape)
    <span class="co"># Plot decision boundary and regions</span>
    out <span class="op">=</span> ax.contour(xx, yy, Z, 
                     levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>., <span class="dv">0</span>., <span class="dv">1</span>], 
                     colors<span class="op">=</span><span class="st">&#39;black&#39;</span>, 
                     linestyles<span class="op">=</span>[<span class="st">&#39;dashed&#39;</span>, <span class="st">&#39;solid&#39;</span>, <span class="st">&#39;dashed&#39;</span>])
    out <span class="op">=</span> ax.contourf(xx, yy, Z, 
                     levels<span class="op">=</span>[Z.<span class="bu">min</span>(), <span class="dv">0</span>, Z.<span class="bu">max</span>()], 
                     colors<span class="op">=</span>[[<span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="fl">0.5</span>], [<span class="fl">1.0</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>]])
    <span class="cf">return</span> out</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> mlai
<span class="im">import</span> os</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> decision_boundary_plot(models, X, y, axs, filename, titles, xlim, ylim):
    <span class="co">&quot;&quot;&quot;Plot a decision boundary on the given axes</span>
<span class="co">    </span>
<span class="co">    :param axs: the axes to plot on.</span>
<span class="co">    :param models: the SVM models to plot</span>
<span class="co">    :param titles: the titles for each axis</span>
<span class="co">    :param X: input training data</span>
<span class="co">    :param y: target training data&quot;&quot;&quot;</span>
    <span class="cf">for</span> ax <span class="kw">in</span> axs.flatten():
        ax.clear()
    X0, X1 <span class="op">=</span> X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>]
    <span class="cf">if</span> xlim <span class="kw">is</span> <span class="va">None</span>:
        xlim <span class="op">=</span> [X0.<span class="bu">min</span>()<span class="op">-</span><span class="dv">1</span>, X0.<span class="bu">max</span>()<span class="op">+</span><span class="dv">1</span>]
    <span class="cf">if</span> ylim <span class="kw">is</span> <span class="va">None</span>:
        ylim <span class="op">=</span> [X1.<span class="bu">min</span>()<span class="op">-</span><span class="dv">1</span>, X1.<span class="bu">max</span>()<span class="op">+</span><span class="dv">1</span>]
    xx, yy <span class="op">=</span> np.meshgrid(np.arange(xlim[<span class="dv">0</span>], xlim[<span class="dv">1</span>], <span class="fl">0.02</span>),
                         np.arange(ylim[<span class="dv">0</span>], ylim[<span class="dv">1</span>], <span class="fl">0.02</span>))
    <span class="cf">for</span> cl, title, ax <span class="kw">in</span> <span class="bu">zip</span>(models, titles, axs.flatten()):
        plot_contours(ax, cl, xx, yy,
                      cmap<span class="op">=</span>plt.cm.coolwarm, alpha<span class="op">=</span><span class="fl">0.8</span>)
        ax.plot(X0[y<span class="op">==</span><span class="dv">1</span>], X1[y<span class="op">==</span><span class="dv">1</span>], <span class="st">&#39;r.&#39;</span>, markersize<span class="op">=</span><span class="dv">10</span>)
        ax.plot(X0[y<span class="op">==</span><span class="dv">0</span>], X1[y<span class="op">==</span><span class="dv">0</span>], <span class="st">&#39;g.&#39;</span>, markersize<span class="op">=</span><span class="dv">10</span>)
        ax.set_xlim(xlim)
        ax.set_ylim(ylim)
        ax.set_xticks(())
        ax.set_yticks(())
        ax.set_title(title)
        mlai.write_figure(os.path.join(filename),
                          figure<span class="op">=</span>fig,
                          transparent<span class="op">=</span><span class="va">True</span>)
    <span class="cf">return</span> xlim, ylim</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> matplotlib
font <span class="op">=</span> {<span class="st">&#39;family&#39;</span> : <span class="st">&#39;sans&#39;</span>,
        <span class="st">&#39;weight&#39;</span> : <span class="st">&#39;bold&#39;</span>,
        <span class="st">&#39;size&#39;</span>   : <span class="dv">22</span>}

matplotlib.rc(<span class="st">&#39;font&#39;</span>, <span class="op">**</span>font)
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Create an instance of SVM and fit the data. </span>
C <span class="op">=</span> <span class="fl">100.0</span>  <span class="co"># SVM regularization parameter</span>
gammas <span class="op">=</span> [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>]


per_class<span class="op">=</span><span class="dv">30</span>
num_samps <span class="op">=</span> <span class="dv">20</span>
<span class="co"># Set-up 2x2 grid for plotting.</span>
fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">3</span>))
xlim<span class="op">=</span><span class="va">None</span>
ylim<span class="op">=</span><span class="va">None</span>
<span class="cf">for</span> samp <span class="kw">in</span> <span class="bu">range</span>(num_samps):
    X, y<span class="op">=</span>create_data(per_class)
    models <span class="op">=</span> []
    titles <span class="op">=</span> []
    <span class="cf">for</span> gamma <span class="kw">in</span> gammas:
        models.append(svm.SVC(kernel<span class="op">=</span><span class="st">&#39;rbf&#39;</span>, gamma<span class="op">=</span>gamma, C<span class="op">=</span>C))
        titles.append(<span class="st">&#39;$\gamma=</span><span class="sc">{}</span><span class="st">$&#39;</span>.<span class="bu">format</span>(gamma))
    models <span class="op">=</span> (cl.fit(X, y) <span class="cf">for</span> cl <span class="kw">in</span> models)
    xlim, ylim <span class="op">=</span> decision_boundary_plot(models, X, y, 
                           axs<span class="op">=</span>ax, 
                           filename<span class="op">=</span><span class="st">&#39;../slides/diagrams/ml/bias-variance</span><span class="sc">{samp:0&gt;3}</span><span class="st">.svg&#39;</span>.<span class="bu">format</span>(samp<span class="op">=</span>samp), 
                           titles<span class="op">=</span>titles,
                          xlim<span class="op">=</span>xlim,
                          ylim<span class="op">=</span>ylim)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pods
<span class="im">from</span> ipywidgets <span class="im">import</span> IntSlider</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">pods.notebook.display_plots(<span class="st">&#39;bias-variance</span><span class="sc">{samp:0&gt;3}</span><span class="st">.svg&#39;</span>, 
                            directory<span class="op">=</span><span class="st">&#39;../slides/diagrams/ml&#39;</span>, 
                            samp<span class="op">=</span>IntSlider(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">19</span>,<span class="dv">1</span>))</code></pre></div>
<div class="figure">
<div id="bias-variance-errors-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class="svgplot " data="../slides/diagrams/ml/bias-variance000.svg" style="vertical-align:middle;">
</object>
</td>
<td width="45%">
<object class="svgplot " data="../slides/diagram/ml/bias-variance019.svg" style="vertical-align:middle;">
</object>
</td>
</tr>
</table>
</div>
<div id="bias-variance-errors-magnify" class="magnify" onclick="magnifyFigure(&#39;bias-variance-errors&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="bias-variance-errors-caption" class="caption-frame">
<p>Figure: In each figure the more simple model is on the left, and the more complex model is on the right. Each fit is done to a different version of the data set. The simpler model is more consistent in its errors (bias error), whereas the more complex model is varying in its errors (variance error).</p>
</div>
</div>
<h2 id="decision-making-and-bias-variance">Decision Making and Bias-Variance</h2>
<ul>
<li>In a population we should prefer variance-errors.
<ul>
<li>Bias errors lead to consistent, decsion making.</li>
<li>Consistently wrong!</li>
</ul></li>
<li>Variance errors can also be averaged e.g. <a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">bagging</a> and <a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)">boosting</a> <span class="citation">(Breiman 1996)</span></li>
</ul>
<h2 id="rational-behaviour-edit">Rational Behaviour <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-rational.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-rational.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<ul>
<li>Sustain a variety of approaches to life.</li>
<li>Complex explanations such as half-time football punditry.</li>
<li>Also clinical experts <span class="citation">(Meehl 1954)</span>. Meehl suggested they 'try to be clever and think outside the box'.</li>
</ul>
<h2 id="one-correct-solution">One Correct Solution</h2>
<ul>
<li>Artificial Selection and Eugenics.</li>
<li>OK for race horses, greyhounds, crops, sheep and cows</li>
<li>Not OK for the human race.</li>
</ul>
<h2 id="one-correct-solution-1">One Correct Solution</h2>
<ul>
<li>Flawed understanding of science</li>
<li>Animals in a species become too specialised then they may not be able to respond to changing circumstances.
<ul>
<li>Think of cheetahs and eagles vs rats and pigeons.</li>
</ul></li>
</ul>
<h2 id="similar-ideas-socially">Similar Ideas Socially</h2>
<blockquote>
<p>I may not agree with many people's subjective approach to life, I may even believe it to be severely sub-optimal. But I should not presume to know better, even if prior experience shows that my own 'way of being' is effective.</p>
<p>Variation is vitally important for robustness. There may be future circumstances where my approaches fail utterly, and other ways of being are better.</p>
</blockquote>
<h2 id="a-universal-utility">A Universal Utility</h2>
<ul>
<li>Quality of our individual subjective utilities measured by effectiveness.</li>
<li>But it is survival of entire species that dominates long term.</li>
<li>A universal utility by which we are judged is difficult to define.</li>
</ul>
<h2 id="the-real-ethical-dilemma">The Real Ethical Dilemma</h2>
<ul>
<li>Trolley Problem is an oversimplification.</li>
<li>Driverless cars:
<ul>
<li>introduce driverless cars and bring about a 90% reduction in deaths</li>
<li>What if remaining deaths are all cyclists?</li>
</ul></li>
</ul>
<h2 id="uncertainty-the-tyger-that-burns-bright-edit">Uncertainty: The Tyger that Burns Bright <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/uncertainty-and-absolutism.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/uncertainty-and-absolutism.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<ul>
<li>Non-survival of the non-fit</li>
<li>The marvel of evolution is its responsiveness.</li>
<li>Utility function evolves socially and in our environment.</li>
</ul>
<p>(<a href="https://en.wikipedia.org/wiki/Survival_of_the_fittest">&quot;survival of the fittest&quot;</a> is due to <a href="https://en.wikipedia.org/wiki/Herbert_Spencer">Herbert Spencer</a>)</p>
<h2 id="absolute-policies">Absolute Policies</h2>
<ul>
<li>There is only one absolute policy we should follow.</li>
</ul>
<blockquote>
<p>There will be single absolute policy that should be followed slavishly in all circumstances</p>
</blockquote>
<h2 id="george-box">George Box</h2>
<blockquote>
<p>Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.</p>
<p>George E. P. Box <span class="citation">(Box 1976)</span></p>
</blockquote>
<h2 id="tigers-and-trolleys">Tigers and Trolleys</h2>
<ul>
<li>A simple switch in the points, is deterministic/mechanistic</li>
</ul>
<div class="figure">
<div id="trolley-problem-1-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="../slides/diagrams/ai/Trolley_1.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="trolley-problem-1-magnify" class="magnify" onclick="magnifyFigure(&#39;trolley-problem-1&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="trolley-problem-1-caption" class="caption-frame">
<p>Figure: The original trolley problem. The decision is deterministic.</p>
</div>
</div>
<ul>
<li>The second example is largely contrived, and riddled with uncertainty.</li>
</ul>
<div class="figure">
<div id="trolley-problem-2-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="../slides/diagrams/ai/trolley2.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="trolley-problem-2-magnify" class="magnify" onclick="magnifyFigure(&#39;trolley-problem-2&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="trolley-problem-2-caption" class="caption-frame">
<p>Figure: In the situation where you push an overweight gentleman, the decision is riddled with uncertainty. Doubt inevitably creeps in.</p>
</div>
</div>
<h1 id="references" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Box-science76">
<p>Box, George E. P. 1976. “Science and Statistics.” <em>Journal of the American Statistical Association</em> 71 (356): 791–99. <a href="http://www.jstor.org/stable/2286841" class="uri">http://www.jstor.org/stable/2286841</a>.</p>
</div>
<div id="ref-Breiman-bagging96">
<p>Breiman, Leo. 1996. “Bagging Predictors.” <em>Machine Learning</em> 24 (2): 123–40. doi:<a href="https://doi.org/10.1007/BF00058655">10.1007/BF00058655</a>.</p>
</div>
<div id="ref-Geman-biasvariance92">
<p>Geman, Stuart, Elie Bienenstock, and René Doursat. 1992. “Neural Networks and the Bias/Variance Dilemma.” <em>Neural Computation</em> 4 (1): 1–58. doi:<a href="https://doi.org/10.1162/neco.1992.4.1.1">10.1162/neco.1992.4.1.1</a>.</p>
</div>
<div id="ref-Kahneman-fastslow11">
<p>Kahneman, Daniel. 2011. <em>Thinking Fast and Slow</em>.</p>
</div>
<div id="ref-Meehl-clinicalstatistical54">
<p>Meehl, Paul E. 1954. <em>Clinical Versus Statistical Prediction: A Theoretical Analysis and a Review of the Evidence</em>.</p>
</div>
<div id="ref-Sandel-justice10">
<p>Sandel, Michael. 2010. <em>Justice: What’s the Right Thing to Do?</em></p>
</div>
</div>


