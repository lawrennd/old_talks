---
title: "Natural and Artificial Intelligence"
venue: "Amazon Thursday Thoughts"
abstract: "What is the nature of machine intelligence and how does it differ from humans? In this talk we explore some of the differences between natural and machine intelligence."
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: Amazon and University of Sheffield
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
date: 2018-03-29
published: 2018-03-29
reveal: 2018-03-29-on-natural-and-artificial-intelligence.slides.html
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>



    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!--notes:
- a plastic plant. is poor. It is poorly define
- it may with us for the did not join us It’s intelligence is based The worth of an idea  A negotiated compromise betwagreed upon , because it is predicated on a shared condition. The constraints on . A shared limitations.  is this condition. This locked in intelligence, because however we create an artificial intelligence it will 
- The challenge for an artificial intelligence is to emulat
-, an ingrained world view.or is predisposed to certain
- to seek out teleological explanations. 
- Each of To have a shared understanding on intent, we need a shared understanding of each other, of how we’ll likely react to different circumstances. We do this through empathy, through our artificial systems are able to communicate any of their thoughts far While communication does not have to be part of an individuals intelligence, if we consider the populations intelligence, we see that the architecture for sharing information wilI if we assume that sharing of information between individual computers or humans is a key 
- The average word in English contains 12 
- The challenges of this new form of systems design have already been explored in systems biology, a field dedicated to the reverse engineering of biological systems. As many researchers have found, classical approaches to reverse engineering, which typically involve subjecting the system to a perturbation. In other words actively changing the system, to obtain a deeper understanding of behaviour normally fail because a natural system will often compensate. Survival dictates that there should be back up systems that kick in. 
- Robust approaches to systems design for the “don’t fail” predicate are beyond the scope of current engineering practice. They require uncertainty, best default behaviours, worst case analyses. They require you to consider how your artificial intelligence should respond to a mischievous 10 year old. 
-  (in the simplest case, hitting it with a hammer
- Firstly, imagine all the different pin configurations there could be in our hyperspace pinball machine. There are many pin configurations that may work well, but in such a complex machine, even if we have a lot of data to test it with, there may be areas of the machine we don’t explore until we test it in the real world, unforeseen circumstances. How do we guarantee that the machine doesn’t mess up?
- Or what if we get the objective function wrong? How do we distil our desired behaviour into a simple mathematical function. 
- *Pigeonholed activity*
- *Natural vs artificial systems*
- *natural vs human intelligence*
- The prediction function is the object that is used to make new pr
- that we are a long way off. Or at least, there are technological breakthroughs that need to happen 
So what will be the last bastion 
- In the timeliSuper human performance on specific tasks are hailed as breaDebates around artificial intelligence are confused because the fail to properly define tBroadly My own position is Human intelligence is quite diffrArtificial intelligence is a loaded term, one that is challenging because it means different things to different people. Historically, artificial intelligence practitioners focussed on planning and logic. Recreating the reasoning abilities of humans in our artificial devices, but the new wave of breakthroughs come from something else. From artificial neural network models. 
- However, just as the origins of Although the origins of - One challenge is that most practitioners of artificial intelligence do not give 
- Or at least in emulating a set of actions that we regard as intelligent. Whether it’s 
-->
<!-- Front matter -->
<!-- Front matter -->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!--Back matter-->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<p><em>How are we making computers do the things we used to associated only with humans? Have we made a breakthrough in understanding human intelligence?</em></p>
<p>While recent achievements might give the sense that the answer is yes, the short answer is that we are nowhere near. All we’ve achieved for the moment is a breakthrough in <em>emulating intelligence</em>.</p>
<h2 id="what-is-intelligence-edit">What is Intelligence? <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/what-is-intelligence.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/what-is-intelligence.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>One challenge with the word intelligence is it means many different things to different people. My own definition of intelligence is the use of information to achieve goals more efficiently. Where information is measured in Shannon terms, and efficiency is measured in terms of use of resource, typically available energy or maybe time. The definition appeals to me because it brings about a connection between the major historic revolutions, which have been about energy, and the current changes which focus more on information. However, the definition does not specify the goal. Some prefer to try and incorporate the goal in their definition of intelligence, and that goals should be somehow emergent from intelligence. For complex tasks sub-goals are certainly emergent, but I don’t seek to incorporate a global goal in my own definition.</p>
<p>So where are we in terms of intelligence? There is certainly an information revolution going on, and it is causing disruption across many industries. But what we are saying about machine learning and artificial inteligence has been said before in relation to the invention of sillicon chips. I gave a version of this talk once at the BBC, and Bill Thompson was kind enough to share with me the archive of “Silicon Factor”, a series of three programs broadcast in 1980 exploring the “microelectronics revolution”. There is a remarkable similarity to everything the experts say in these programs and what experts say about AI today. And of course, these experts were right, jobs have changed, industry is different and we are still deep in the micro-electronics revolution. However, these changes do not happen overnight, those broadcasts were made nearly forty years ago. The “Fourth Industrial Revolution” is merely a continuation of an ongoing revolution in information, one which was triggered by the Silicon Factor, continued by the internet and has been given further momentum by mobile communications.</p>
<p>With a word like intelligence, we can’t just think about our own definition of intelligence, but we should also take into account public understanding of the world. For many people intelligence is something specific to humans, and as a result what the term refers to evolves. Artificial intelligence is a very emotive term, because it feels close to us, it makes us think that computers are doing things like us. As a result it is also a shifting definition, it comes to me “intelligence is the stuff I can do that computers can’t”. This lends a narcissistic element to our fascination with artificial intelligence, because it is also a fascination with ourselves.</p>
<p>A hundred years ago <em>computers</em> were human beings, often female, who conducted repetitive mathematical tasks for the creation of mathematical tables such as logarithms. Our modern digital computers were originally called <em>automatic computers</em> to reflect the fact that the intelligence of these human operators had been automated. But despite the efficiency with which they perform these tasks, very few think of their mobile phones or computers as intelligent.</p>
<p>Norbert Wiener launched last century’s first wave of interest in emulation of intelligence with his book “Cybernetics”. The great modern success that stemmed from that work is the modern engineering discipline of Automatic Control. The technology that allows fighter jets to fly. These ideas came out of the Second World War, when researchers explored the use of radar (automated sensing) and automatic computation for decryption of military codes (automated decision making). Post war a body of researchers, including Alan Turing, were seeing the potential for electronic emulation of what had up until then been the preserve of an animallian nervous system.</p>
<div class="figure">
<div id="science-holborn-viaduct-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/science-holborn-viaduct.jpg" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="science-holborn-viaduct-magnify" class="magnify" onclick="magnifyFigure(&#39;science-holborn-viaduct&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="science-holborn-viaduct-caption" class="caption-frame">
<p>Figure: Science on Holborn Viaduct, cradling the Centrifugal Governor.</p>
</div>
</div>
<p>Artificial intelligence is a badly defined term. Successful deployments of intelligent systems are common, but normally they are redefined to be non-intelligent. My favourite example is <a href="https://en.wikipedia.org/wiki/Centrifugal_governor">the Centrifugal governor</a>. Applied to the Steam Engine by Boulton and Watt and immortalised in the arms of the statue of “Science” on the Holborn viaduct in London, the centrifugal governor automatically regulated the speed of a steam engine, closing the inlet valve progressively as the engine ran faster. It did the job that an intelligent operator used to have to do, but few today would describe it as “artificial intelligence”.</p>
<p>The current revolution in AI is being driven by machine learning. Machine learning is an approach to prediction which is data driven. It is not the first approach to focus on data, the statistical sciences have combined models with data for a number of years. But machine learning has taken a particular focus on improving the quality of prediction, whereas statistical sciences have traditionally focussed more on explaination. Machine learning is giving us information processing engines that are equivalent to the steam engines of the industrial revolution.</p>
<h2 id="what-is-machine-learning-edit">What is Machine Learning? <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-2.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-2.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Machine learning allows us to extract knowledge from data to form a prediction.</p>
<p><br /><span class="math display">$$\text{data} + \text{model} \xrightarrow{\text{compute}} \text{prediction}$$</span><br /></p>
<p>A machine learning prediction is made by combining a model with data to form the prediction. The manner in which this is done gives us the machine learning <em>algorithm</em>.</p>
<p>Machine learning models are <em>mathematical models</em> which make weak assumptions about data, e.g. smoothness assumptions. By combining these assumptions with the data, we observe we can interpolate between data points or, occasionally, extrapolate into the future.</p>
<p>Machine learning is a technology which strongly overlaps with the methodology of statistics. From a historical/philosophical view point, machine learning differs from statistics in that the focus in the machine learning community has been primarily on accuracy of prediction, whereas the focus in statistics is typically on the interpretability of a model and/or validating a hypothesis through data collection.</p>
<p>The rapid increase in the availability of compute and data has led to the increased prominence of machine learning. This prominence is surfacing in two different but overlapping domains: data science and artificial intelligence.</p>
<h2 id="from-model-to-decision-edit">From Model to Decision <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-end-to-end.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-end-to-end.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>The real challenge, however, is end-to-end decision making. Taking information from the environment and using it to drive decision making to achieve goals.</p>
<h2 id="artificial-vs-natural-systems-edit">Artificial vs Natural Systems <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/artificial-vs-natural-systems-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/artificial-vs-natural-systems-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Let’s take a step back from artificial intelligence, and consider natural intelligence. Or even more generally, let’s consider the contrast between an artificial <em>system</em> and an natural system. The key difference between the two is that artificial systems are <em>designed</em> whereas natural systems are <em>evolved</em>.</p>
<p>Systems design is a major component of all Engineering disciplines. The details differ, but there is a single common theme: achieve your objective with the minimal use of resources to do the job. That provides efficiency. The engineering designer imagines a solution that requires the minimal set of components to achieve the result. A water pump has one route through the pump. That minimises the number of components needed. Redundancy is introduced only in safety critical systems, such as aircraft control systems. Students of biology, however, will be aware that in nature system-redundancy is everywhere. Redundancy leads to robustness. For an organism to survive in an evolving environment it must first be robust, then it can consider how to be efficient. Indeed, organisms that evolve to be too efficient at a particular task, like those that occupy a niche environment, are particularly vulnerable to extinction.</p>
<p>This notion is akin to the idea that only the best will survive, popularly encoded into an notion of evolution by Herbert Spencer’s quote.</p>
<blockquote>
<p>Survival of the fittest</p>
<p><a href="https://en.wikipedia.org/wiki/Herbert_Spencer">Herbet Spencer</a>, 1864</p>
</blockquote>
<p>Darwin himself never said “Survival of the Fittest” he talked about evolution by natural selection.</p>
<blockquote>
<p>Non-survival of the non-fit</p>
</blockquote>
<p>Evolution is better described as “non-survival of the non-fit”. You don’t have to be the fittest to survive, you just need to avoid the pitfalls of life. This is the first priority.</p>
<p>So it is with natural vs artificial intelligences. Any natural intelligence that was not robust to changes in its external environment would not survive, and therefore not reproduce. In contrast the artificial intelligences we produce are designed to be efficient at one specific task: control, computation, playing chess. They are <em>fragile</em>.</p>
<p>The first rule of a natural system is not be intelligent, it is “don’t be stupid”.</p>
<p>A mistake we make in the design of our systems is to equate fitness with the objective function, and to assume it is known and static. In practice, a real environment would have an evolving fitness function which would be unknown at any given time.</p>
<p>You can also read this blog post on <a href="http://inverseprobability.com/2018/02/06/natural-and-artificial-intelligence">Natural and Artificial Intelligence</a>..</p>
<p>The first criterion of a natural intelligence is <em>don’t fail</em>, not because it has a will or intent of its own, but because if it had failed it wouldn’t have stood the test of time. It would no longer exist. In contrast, the mantra for artificial systems is to be more efficient. Our artificial systems are often given a single objective (in machine learning it is encoded in a mathematical function) and they aim to achieve that objective efficiently. These are different characteristics. Even if we wanted to incorporate <em>don’t fail</em> in some form, it is difficult to design for. To design for “don’t fail”, you have to consider every which way in which things can go wrong, if you miss one you fail. These cases are sometimes called corner cases. But in a real, uncontrolled environment, almost everything is a corner. It is difficult to imagine everything that can happen. This is why most of our automated systems operate in controlled environments, for example in a factory, or on a set of rails. Deploying automated systems in an uncontrolled environment requires a different approach to systems design. One that accounts for uncertainty in the environment and is robust to unforeseen circumstances.</p>
<h2 id="todays-artificial-systems">Today’s Artificial Systems</h2>
<p>The systems we produce today only work well when their tasks are pigeonholed, bounded in their scope. To achieve robust artificial intelligences we need new approaches to both the design of the individual components, and the combination of components within our AI systems. We need to deal with uncertainty and increase robustness. Today, it is easy to make a fool of an artificial intelligent agent, technology needs to address the challenge of the uncertain environment to achieve robust intelligences.</p>
<p>However, even if we find technological solutions for these challenges, it may be that the essence of human intelligence remains out of reach. It may be that the most quintessential element of our intelligence is defined by limitations. Limitations that computers have never experienced.</p>
<p>Claude Shannon developed the idea of information theory: the mathematics of information. He defined the amount of information we gain when we learn the result of a coin toss as a “bit” of information. A typical computer can communicate with another computer with a billion bits of information per second. Equivalent to a billion coin tosses per second. So how does this compare to us? Well, we can also estimate the amount of information in the English language. Shannon estimated that the average English word contains around 12 bits of information, twelve coin tosses, this means our verbal communication rates are only around the order of tens to hundreds of bits per second. Computers communicate tens of millions of times faster than us, in relative terms we are constrained to a bit of pocket money, while computers are corporate billionaires.</p>
<p>Our intelligence is not an island, it interacts, it infers the goals or intent of others, it predicts our own actions and how we will respond to others. We are social animals, and together we form a communal intelligence that characterises our species. For intelligence to be communal, our ideas to be shared somehow. We need to overcome this bandwidth limitation. The ability to share and collaborate, despite such constrained ability to communicate, characterises us. We must intellectually commune with one another. We cannot communicate all of what we saw, or the details of how we are about to react. Instead, we need a shared understanding. One that allows us to infer each other’s intent through context and a common sense of humanity. This characteristic is so strong that we anthropomorphise any object with which we interact. We apply moods to our cars, our cats, our environment. We seed the weather, volcanoes, trees with intent. Our desire to communicate renders us intellectually animist.</p>
<p>But our limited bandwidth doesn’t constrain us in our imaginations. Our consciousness, our sense of self, allows us to play out different scenarios. To internally observe how our self interacts with others. To learn from an internal simulation of the wider world. Empathy allows us to understand others’ likely responses without having the full detail of their mental state. We can infer their perspective. Self-awareness also allows us to understand our own likely future responses, to look forward in time, play out a scenario. Our brains contain a sense of self and a sense of others. Because our communication cannot be complete it is both contextual and cultural. When driving a car in the UK a flash of the lights at a junction concedes the right of way and invites another road user to proceed, whereas in Italy, the same flash asserts the right of way and warns another road user to remain.</p>
<p>Our main intelligence is our social intelligence, intelligence that is dedicated to overcoming our bandwidth limitation. We are individually complex, but as a society we rely on shared behaviours and oversimplification of our selves to remain coherent.</p>
<p>This nugget of our intelligence seems impossible for a computer to recreate directly, because it is a consequence of our evolutionary history. The computer, on the other hand, was born into a world of data, of high bandwidth communication. It was not there through the genesis of our minds and the cognitive compromises we made are lost to time. To be a truly human intelligence you need to have shared that journey with us.</p>
<p>Of course, none of this prevents us emulating those aspects of human intelligence that we observe in humans. We can form those emulations based on data. But even if an artificial intelligence can emulate humans to a high degree of accuracy it is a different type of intelligence. It is not constrained in the way human intelligence is. You may ask does it matter? Well, it is certainly important to us in many domains that there’s a human pulling the strings. Even in pure commerce it matters: the narrative story behind a product is often as important as the product itself. Handmade goods attract a price premium over factory made. Or alternatively in entertainment: people pay more to go to a live concert than for streaming music over the internet. People will also pay more to go to see a play in the theatre rather than a movie in the cinema.</p>
<p>In many respects I object to the use of the term Artificial Intelligence. It is poorly defined and means different things to different people. But there is one way in which the term is very accurate. The term artificial is appropriate in the same way we can describe a plastic plant as an artificial plant. It is often difficult to pick out from afar whether a plant is artificial or not. A plastic plant can fulfil many of the functions of a natural plant, and plastic plants are more convenient. But they can never replace natural plants.</p>
<p>In the same way, our natural intelligence is an evolved thing of beauty, a consequence of our limitations. Limitations which don’t apply to artificial intelligences and can only be emulated through artificial means. Our natural intelligence, just like our natural landscapes, should be treasured and can never be fully replaced.</p>
<h2 id="engineering-systems-design">Engineering Systems Design</h2>
<p>Engineering systems design is a major component of all engineering disciplines, in each domain the details differ, but there is a common theme. The aim is to achieve your objective with the minimal use of resources to do the job. This provides <em>efficiency</em>. An engineering designer imagines a solution that requires the minimal set of components to achieve a given result.</p>
<p>For example, a water pump has a single route through the pump, the mechanism of the pump involves a single non-redundant set of linkages. This minimizes the resources needed for manufacturing the pump.</p>
<h2 id="dont-fail">Don’t Fail</h2>
<p>The first criterion of natural intelligence is <em>don’t fail</em>. This is in contrast to the mantra for artificial systems which is to be more efficient. Artificial systems are typically given a single objective (in machine learning it is encoded in a mathematical function). The aim is to achieve that objective efficiently.</p>
<p>Even if we wanted to incorporate <em>don’t fail</em> in some form, it is surprisingly difficult to design for. You would have to consider every which way in which things can go wrong. If you miss one you will fail. These cases are sometimes called corner cases.</p>
<p>In an uncontrolled environment there are corners everywhere. It is difficult to imagine everything that can happen. As a result most of our automated systems operate in controlled environments, e.g. in a factory, on a set of rails.</p>
<p>We can imagine a driverless car operating on a highway (a more controlled environment), but it is harder to imagine how one would operate in the city centres of Naples, Kampala or Delhi (less controlled environments).</p>
<p>Deployment in uncontrolled environments may require a different approach to systems design, one that accounts for uncertainty in the environment and one that is robust to unforeseen circumstances.</p>
<h2 id="peppercorns-edit">Peppercorns <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/peppercorn.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/peppercorn.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="peppercorn-siri-figure" class="figure-frame">
<iframe width="800px" height="600px" src="https://www.youtube.com/embed/1y2UKz47gew?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="peppercorn-siri-magnify" class="magnify" onclick="magnifyFigure(&#39;peppercorn-siri&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="peppercorn-siri-caption" class="caption-frame">
<p>Figure: A peppercorn is a system design failure which is not a bug, but a conformance to design specification that causes problems when the system is deployed in the real world with mischevious and adversarial actors.</p>
</div>
</div>
<p>Asking Siri “What is a trillion to the power of a thousand minus one?” leads to a 30 minute response<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> consisting of only 9s. I found this out because my nine year old grabbed my phone and did it. The only way to stop Siri was to force closure. This is an interesting example of a system feature that’s <em>not</em> a bug, in fact it requires clever processing from Wolfram Alpha. But it’s an unexpected result from the system performing correctly.</p>
<p>This challenge of facing a circumstance that was unenvisaged in design but has consequences in deployment becomes far larger when the environment is uncontrolled. Or in the extreme case, where actions of the intelligent system effect the wider environment and change it.</p>
<p>These unforseen circumstances are likely to lead to need for much more efficient turn-around and update for our intelligent systems. Whether we are correcting for security flaws (which <em>are</em> bugs) or unenvisaged circumstantial challenges: an issue I’m referring to as <em>peppercorns</em>. Rapid deployment of system updates is required. For example, Apple have “fixed” the problem of Siri returning long numbers.</p>
<p>The challenge is particularly acute because of the <em>scale</em> at which we can deploy AI solutions. This means when something does go wrong, it may be going wrong in billions of households simultaneously.</p>
<p>You can also check this blog post on <a href="http://inverseprobability.com/2017/11/15/decision-making">Decision Making and Diversity</a>. and this blog post on <a href="http://inverseprobability.com/2018/02/06/natural-and-artificial-intelligence">Natural vs Artifical Intelligence</a>..</p>
<h2 id="a-man-and-his-dog-edit">A Man and His Dog <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/a-man-and-his-dog.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/a-man-and-his-dog.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="bezos-taking-my-dog-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/bezos_taking_my_dog.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="bezos-taking-my-dog-magnify" class="magnify" onclick="magnifyFigure(&#39;bezos-taking-my-dog&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="bezos-taking-my-dog-caption" class="caption-frame">
<p>Figure: Jeff Bezos walking Boston Dynamics’s SpotMini robot.</p>
</div>
</div>
<p>This picture is from the MARS 2018 conference, it shows Jeff Bezos with SpotMini, Boston Dynamics mini robot dog. It resonates with me in two ways, first of all, despite the life like nature of the dog, it is not using any ‘modern AI’ at all, Marc Raibert is proud of the fact that his robots are using complex cascades of traditional controllers. This allows them to verify performance of the individual controllers which are switched in to different domains.</p>
<p>Classical control emerged from the first wave of work on intelligent systems, a feild known as cybernetics. But it has been redefined to be not an AI technology.</p>
<div class="figure">
<div id="musk-chollet-control-reinforcement-learning-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/musk_chollet_control_reinforcement_learning.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="musk-chollet-control-reinforcement-learning-magnify" class="magnify" onclick="magnifyFigure(&#39;musk-chollet-control-reinforcement-learning&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="musk-chollet-control-reinforcement-learning-caption" class="caption-frame">
<p>Figure: The aims of the field of control, are roughly similar to those of reinforcement learning. Control can be thought of as “reinforcement learning that works”. Importantly, control considers <em>worse case performance</em> whereas much of reinforcement learning will only consider average case performance.</p>
</div>
</div>
<p>Yet, we can see the aims of control engineering in the field of reinforcement learning. There is large overlap between the fields. A major difference is that reinforcement learning researchers accept the fact that they may be unable to establish guarantees around performance that can be proven mathematically. Mathematica guarantees are a mainstay of the field of control which evolved in an era before large scale compute and data was available.</p>
<p>Secondly, the robot dog is missing a major characteristic of our intelligence, one which real dogs do show, empathy and an ability to model us and who we are. The most complex thing in our environment is other humans, and perhaps the most important facet of our intelligence is our social intelligence. Our ability to model other humans. Something that our real-world companions, our dogs and cats, exhibit better than our artificial companions.</p>
<p>The mythology around intelligence centres on an idea of an intelligence that is better than us in all aspects. But what if some aspects of our intelligence, such as our emotional intelligence, are a consequence of our limitations? What if it is not possible to be emotionally intelligent to the same degree as a human being without experiencing the same limitations as that human being. One obvious limitation is death, but there are other limitations including constraints on our ability to communicate our thoughts.</p>
<!--

-->
<h2 id="the-diving-bell-and-the-butterfly-edit">The Diving Bell and the Butterfly <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-diving-bell-butterfly.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-diving-bell-butterfly.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="diving-bell-and-butterfly-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ai/the-diving-bell-and-the-butterfly.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="diving-bell-and-butterfly-magnify" class="magnify" onclick="magnifyFigure(&#39;diving-bell-and-butterfly&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="diving-bell-and-butterfly-caption" class="caption-frame">
<p>Figure: The Diving Bell and the Buttefly is the autobiography of Jean Dominique Bauby.</p>
</div>
</div>
<p>The Diving Bell and the Butterfly is the autobiography of Jean Dominique Bauby. Jean Dominique was the editor of the French Elle magazine, in 1995 at the age of 43, he suffered a major stroke. The stroke paralyzed him and rendered him speechless. He was only able to blink his left eyelid, he became a sufferer of locked in syndrome.</p>
<div class="figure">
<div id="jean-dominique-bauby-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ai/Jean-Dominique_Bauby.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="jean-dominique-bauby-magnify" class="magnify" onclick="magnifyFigure(&#39;jean-dominique-bauby&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="jean-dominique-bauby-caption" class="caption-frame">
<p>Figure: Jean Domionique Bauby was the Editor in Chief of the French Elle Magazine, he suffered a stroke that destroyed his brainstem, leaving him only capable of moving one eye. Jean Dominique became a victim of locked in syndrome.</p>
</div>
</div>
<p>Incredibly, Jean Dominique wrote his book after he became locked in. It took him 10 months of four hours a day to write the book. Each word took two minutes to write.</p>
<p>The idea behind embodiment factors is that we are all in that situation. While not as extreme as for Bauby, we all have somewhat of a locked in intelligence.</p>
<h2 id="embodiment-factors-edit">Embodiment Factors <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-tedx.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-tedx.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="embodiment-factors-table-figure" class="figure-frame">
<table>
<tr>
<td>
</td>
<td align="center">
<object class="svgplot " data="../slides/diagrams/computer.svg" width="100%" style=" ">
</object>
</td>
<td align="center">
<object class="svgplot " data="../slides/diagrams/human.svg" width="100%" style=" ">
</object>
</td>
<td align="center">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ai/Jean-Dominique_Bauby.jpg" width="150%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
<tr>
<td>
bits/min
</td>
<td align="center">
billions
</td>
<td align="center">
2000
</td>
<td align="center">
6
</td>
</tr>
<tr>
<td>
billion<br>calculations/s
</td>
<td align="center">
~100
</td>
<td align="center">
a billion
</td>
<td align="center">
a billion
</td>
</tr>
<tr>
<td>
embodiment
</td>
<td align="center">
20 minutes
</td>
<td align="center">
5 billion years
</td>
<td align="center">
15 trillion years
</td>
</tr>
</table>
</div>
<div id="embodiment-factors-table-magnify" class="magnify" onclick="magnifyFigure(&#39;embodiment-factors-table&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="embodiment-factors-table-caption" class="caption-frame">
<p>Figure: Embodiment factors are the ratio between our ability to compute and our ability to communicate. Jean Dominique Bauby suffered from locked-in syndrome. The embodiment factors show that relative to the machine we are also locked in. In the table we represent embodiment as the length of time it would take to communicate one second’s worth of computation. For computers it is a matter of minutes, but for a human, whether locked in or not, it is a matter of many millions of years.</p>
</div>
</div>
<p>Let me explain what I mean. Claude Shannon introduced a mathematical concept of information for the purposes of understanding telephone exchanges.</p>
<p>Information has many meanings, but mathematically, Shannon defined a bit of information to be the amount of information you get from tossing a coin.</p>
<p>If I toss a coin, and look at it, I know the answer. You don’t. But if I now tell you the answer I communicate to you 1 bit of information. Shannon defined this as the fundamental unit of information.</p>
<p>If I toss the coin twice, and tell you the result of both tosses, I give you two bits of information. Information is additive.</p>
<p>Shannon also estimated the average information associated with the English language. He estimated that the average information in any word is 12 bits, equivalent to twelve coin tosses.</p>
<p>So every two minutes Bauby was able to communicate 12 bits, or six bits per minute.</p>
<p>This is the information transfer rate he was limited to, the rate at which he could communicate.</p>
<p>Compare this to me, talking now. The average speaker for TEDX speaks around 160 words per minute. That’s 320 times faster than Bauby or around a 2000 bits per minute. 2000 coin tosses per minute.</p>
<p>But, just think how much thought Bauby was putting into every sentence. Imagine how carefully chosen each of his words was. Because he was communication constrained he could put more thought into each of his words. Into thinking about his audience.</p>
<p>So, his intelligence became locked in. He thinks as fast as any of us, but can communicate slower. Like the tree falling in the woods with no one there to hear it, his intelligence is embedded inside him.</p>
<p>Two thousand coin tosses per minute sounds pretty impressive, but this talk is not just about us, it’s about our computers, and the type of intelligence we are creating within them.</p>
<p>So how does two thousand compare to our digital companions? When computers talk to each other, they do so with billions of coin tosses per minute.</p>
<p>Let’s imagine for a moment, that instead of talking about communication of information, we are actually talking about money. Bauby would have 6 dollars. I would have 2000 dollars, and my computer has billions of dollars.</p>
<p>The internet has interconnected computers and equipped them with extremely high transfer rates.</p>
<p>However, by our very best estimates, computers actually think slower than us.</p>
<p>How can that be? You might ask, computers calculate much faster than me. That’s true, but underlying your conscious thoughts there are a lot of calculations going on.</p>
<p>Each thought involves many thousands, millions or billions of calculations. How many exactly, we don’t know yet, because we don’t know how the brain turns calculations into thoughts.</p>
<p>Our best estimates suggest that to simulate your brain a computer would have to be as large as the UK Met Office machine here in Exeter. That’s a 250 million pound machine, the fastest in the UK. It can do 16 billion billon calculations per second.</p>
<p>It simulates the weather across the word every day, that’s how much power we think we need to simulate our brains.</p>
<p>So, in terms of our computational power we are extraordinary, but in terms of our ability to explain ourselves, just like Bauby, we are locked in.</p>
<p>For a typical computer, to communicate everything it computes in one second, it would only take it a couple of minutes. For us to do the same would take 15 billion years.</p>
<p>If intelligence is fundamentally about processing and sharing of information. This gives us a fundamental constraint on human intelligence that dictates its nature.</p>
<p>I call this ratio between the time it takes to compute something, and the time it takes to say it, the embodiment factor <span class="citation" data-cites="Lawrence:embodiment17">(Lawrence 2017)</span>. Because it reflects how embodied our cognition is.</p>
<p>If it takes you two minutes to say the thing you have thought in a second, then you are a computer. If it takes you 15 billion years, then you are a human.</p>
<!--include{_ai/includes/sahelanthropus-tchadensis.md}-->
<p>But in terms of our ability to deploy that computation in actual use, to share the results of what we have inferred, we are very limited. So when you imagine the F1 car that represents a psyche, think of an F1 car with bicycle wheels.</p>
<div class="figure">
<div id="marcel-renault-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/640px-Marcel_Renault_1903.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="marcel-renault-magnify" class="magnify" onclick="magnifyFigure(&#39;marcel-renault&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="marcel-renault-caption" class="caption-frame">
<p>Figure: Marcel Renault races a Renault 40 cv during the Paris-Madrid race, an early Grand Prix, in 1903. Marcel died later in the race after missing a warning flag for a sharp corner at Couhé Vérac, likely due to dust reducing visibility.</p>
</div>
</div>
<p>Just think of the control a driver would have to have to deploy such power through such a narrow channel of traction. That is the beauty and the skill of the human mind.</p>
<p>In contrast, our computers are more like go-karts. Underpowered, but with well-matched tires. They can communicate far more fluidly. They are more efficient, but somehow less extraordinary, less beautiful.</p>
<div class="figure">
<div id="caleb-mcduff-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Caleb_McDuff_WIX_Silence_Racing_livery.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="caleb-mcduff-magnify" class="magnify" onclick="magnifyFigure(&#39;caleb-mcduff&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="caleb-mcduff-caption" class="caption-frame">
<p>Figure: Caleb McDuff driving for WIX Silence Racing.</p>
</div>
</div>
<h2 id="human-communication-edit">Human Communication <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>For human conversation to work, we require an internal model of who we are speaking to. We model each other, and combine our sense of who they are, who they think we are, and what has been said. This is our approach to dealing with the limited bandwidth connection we have. Empathy and understanding of intent. Mental dispositional concepts are used to augment our limited communication bandwidth.</p>
<p>Fritz Heider referred to the important point of a conversation as being that they are happenings that are “<em>psychologically represented</em> in each of the participants” (his emphasis) <span class="citation" data-cites="Heider:interpersonal58">(Heider 1958)</span></p>
<h3 id="bandwidth-constrained-conversations">Bandwidth Constrained Conversations</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">import</span> pods</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="im">from</span> ipywidgets <span class="im">import</span> IntSlider</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1">pods.notebook.display_plots(<span class="st">&#39;anne-bob-conversation</span><span class="sc">{sample:0&gt;3}</span><span class="st">.svg&#39;</span>, </a>
<a class="sourceLine" id="cb2-2" data-line-number="2">                            <span class="st">&#39;../slides/diagrams&#39;</span>,  sample<span class="op">=</span>IntSlider(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">1</span>))</a></code></pre></div>
<div class="figure">
<div id="anne-bob-conversation-civil-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-bob-conversation006.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-conversation-civil-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-bob-conversation-civil&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="anne-bob-conversation-civil-caption" class="caption-frame">
<p>Figure: Conversation relies on internal models of other individuals.</p>
</div>
</div>
<div class="figure">
<div id="anne-bob-conversation-argument-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-bob-conversation007.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-conversation-argument-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-bob-conversation-argument&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="anne-bob-conversation-argument-caption" class="caption-frame">
<p>Figure: Misunderstanding of context and who we are talking to leads to arguments.</p>
</div>
</div>
<p>Embodiment factors imply that, in our communication between humans, what is <em>not</em> said is, perhaps, more important than what is said. To communicate with each other we need to have a model of who each of us are.</p>
<p>To aid this, in society, we are required to perform roles. Whether as a parent, a teacher, an employee or a boss. Each of these roles requires that we conform to certain standards of behaviour to facilitate communication between ourselves.</p>
<p>Control of self is vitally important to these communications.</p>
<p>The high availability of data available to humans undermines human-to-human communication channels by providing new routes to undermining our control of self.</p>
<h3 id="a-six-word-novel-edit">A Six Word Novel <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/baby-shoes.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/baby-shoes.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h3>
<div class="figure">
<div id="classic-baby-shoes-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Classic_baby_shoes.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<center>
For sale: baby shoes, never worn
</center>
</div>
<div id="classic-baby-shoes-magnify" class="magnify" onclick="magnifyFigure(&#39;classic-baby-shoes&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="classic-baby-shoes-caption" class="caption-frame">
<p>Figure: Consider the six word novel, apocraphally credited to Ernest Hemingway, “For sale: baby shoes, never worn”. To understand what that means to a human, you need a great deal of additional context. Context that is not directly accessible to a machine that has not got both the evolved and contextual understanding of our own condition to realize both the implication of the advert and what that implication means emotionally to the previous owner.</p>
</div>
</div>
<p>But this is a very different kind of intelligence than ours. A computer cannot understand the depth of the Ernest Hemingway’s apocryphal six word novel: “For Sale, Baby Shoes, Never worn”, because it isn’t equipped with that ability to model the complexity of humanity that underlies that statement.</p>
<h2 id="computer-conversations-edit">Computer Conversations <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="im">import</span> pods</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="im">from</span> ipywidgets <span class="im">import</span> IntSlider</a></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1">pods.notebook.display_plots(<span class="st">&#39;anne-bob-conversation</span><span class="sc">{sample:0&gt;3}</span><span class="st">.svg&#39;</span>, </a>
<a class="sourceLine" id="cb4-2" data-line-number="2">                            <span class="st">&#39;../slides/diagrams&#39;</span>,  sample<span class="op">=</span>IntSlider(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">1</span>))</a></code></pre></div>
<div class="figure">
<div id="anne-computer-conversation-6-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-computer-conversation006.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-6-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-computer-conversation-6&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="anne-computer-conversation-6-caption" class="caption-frame">
<p>Figure: Conversation relies on internal models of other individuals.</p>
</div>
</div>
<div class="figure">
<div id="anne-computer-conversation-8-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/anne-computer-conversation007.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-8-magnify" class="magnify" onclick="magnifyFigure(&#39;anne-computer-conversation-8&#39;)">
<p><img class="img-button" src="{{ "/assets/images/Magnify_Large.svg" | relative_url }}" style="width:1.5ex"></p>
</div>
<div id="anne-computer-conversation-8-caption" class="caption-frame">
<p>Figure: Misunderstanding of context and who we are talking to leads to arguments.</p>
</div>
</div>
<p>Similarly, we find it difficult to comprehend how computers are making decisions. Because they do so with more data than we can possibly imagine.</p>
<p>In many respects, this is not a problem, it’s a good thing. Computers and us are good at different things. But when we interact with a computer, when it acts in a different way to us, we need to remember why.</p>
<p>Just as the first step to getting along with other humans is understanding other humans, so it needs to be with getting along with our computers.</p>
<p>Embodiment factors explain why, at the same time, computers are so impressive in simulating our weather, but so poor at predicting our moods. Our complexity is greater than that of our weather, and each of us is tuned to read and respond to one another.</p>
<p>Their intelligence is different. It is based on very large quantities of data that we cannot absorb. Our computers don’t have a complex internal model of who we are. They don’t understand the human condition. They are not tuned to respond to us as we are to each other.</p>
<p>Embodiment factors encapsulate a profound thing about the nature of humans. Our locked in intelligence means that we are striving to communicate, so we put a lot of thought into what we’re communicating with. And if we’re communicating with something complex, we naturally anthropomorphize them.</p>
<p>We give our dogs, our cats and our cars human motivations. We do the same with our computers. We anthropomorphize them. We assume that they have the same objectives as us and the same constraints. They don’t.</p>
<p>This means, that when we worry about artificial intelligence, we worry about the wrong things. We fear computers that behave like more powerful versions of ourselves that will struggle to outcompete us.</p>
<p>In reality, the challenge is that our computers cannot be human enough. They cannot understand us with the depth we understand one another. They drop below our cognitive radar and operate outside our mental models.</p>
<p>The real danger is that computers don’t anthropomorphize. They’ll make decisions in isolation from us without our supervision, because they can’t communicate truly and deeply with us.</p>
<ul>
<li>blog post on <a href="http://inverseprobability.com/2018/02/06/natural-and-artificial-intelligence">Natural and Artifical Intelligence</a>.</li>
</ul>
<h2 id="transhumanism-edit">Transhumanism <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/transhumanism.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/transhumanism.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Some researchers talk about transhumanism, releasing us from our own limitations, gaining the bandwidth of the computer. Who wouldn’t want the equivalent of billions of dollars of communication that a computer has?</p>
<p>But what if that would destroy the very nature of what it is to be human. What if we are defined by our limitations. What if our consciousness is born out of a need to understand and be understood by others? What if that thing that we value the most is a side effect of our limitations?</p>
<p>AI is a technology, it is not a human being. It doesn’t worry it is being misunderstood, it doesn’t hate us, it doesn’t love us, it doesn’t even have an opinion about us.</p>
<p>Any sense that it does is in that little internal model we have as we anthropomorphize it. AI doesn’t stand for anthropomorphic intelligence, it stands for artificial intelligence. Artificial in the way a plastic plant is artificial.</p>
<p>Of course, like any technology, that doesn’t mean it’s without its dangers. Technological advance has always brought social challenges and likely always will, but if we are to face those challenges head on, we need to acknowledge the difference between our intelligence and that which we create in our computers.</p>
<p>Your cat understands you better than your computer does, your cat understands me better than your computer does, and it hasn’t even met me!</p>
<p>Our lives are defined by our desperate need to be understood: art, music, literature, dance, sport. So many creative ways to try and communicate who we are or what we feel. The computer has no need for this.</p>
<p>When you hear the term Artificial Intelligence, remember that’s precisely what it is. Artificial, like that plastic plant. A plastic plant is convenient, it doesn’t need watering, it doesn’t need to be put in the light, it won’t wilt if you don’t attend to it, and it won’t outgrow the place you put it.</p>
<p>A plastic plant will do some of the jobs that a real plant does, but it isn’t a proper replacement, and never will be. So, it is with our artificial intelligences.</p>
<p>I believe that our fascination with AI is actually a projected fascination with ourselves. A sort of technological narcissism. One of the reasons that the next generation of artificial intelligence solutions excites me is because I think it will lead to a much better understanding of our own intelligence.</p>
<p>But with our self-idolization comes a Icarian fear of what it might mean to emulate those characteristics that we perceive of as uniquely human.</p>
<p>Our fears of AI singularities and superintelligences come from a confused mixing of what we create and what we are.</p>
<p>Do not fool yourselves into thinking these computers are the same thing as us, they never will be. We are a consequence of our limitations, just as Bauby was defined by his. Or maybe limitations is the wrong word, as Bauby described there are always moments when we can explore our inner self and escape into our own imagination:</p>
<blockquote>
<p>My cocoon becomes less oppressive, and my mind takes flight like a butterfly. There is so much to do. You can wander off in space or in time, set out for Tierra del Fuego or King Midas’s court. You can visit the woman you love, slide down beside her and stroke her still-sleeping face. You can build castles in Spain, steal the golden fleece, discover Atlantis, realize your childhood dreams and adult ambitions.<br />
Enough rambling. My main task now is to compose the first of those bedridden travel notes so that I shall be ready when my publisher’s emissary arrives to take my dictation, letter by letter. In my head I churn over every sentence ten times, delete a word, add an adjective, and learn my text by heart, paragraph by paragraph.</p>
</blockquote>
<p>The flower that is this book, that is this fight, can never bud from an artificial plant.</p>
<h1 id="conclusions">Conclusions</h1>
<ul>
<li>We are a <em>long</em> way from emulating human intelligence, animal intelligence, animal motion.</li>
<li>The objectives of <em>cybernetics</em> still have not been reached.</li>
<li><p>The <em>robustness</em> of natural systems is outside the scope of our current design methodologies.</p></li>
<li>There is something quintisential about the <em>human</em> experience.</li>
<li>We are co-evolved to view the world in a certain way to enable collaboration.</li>
<li><p>Our consciousness is a consequence of our limitations. Our <em>locked-in</em> intelligence.</p></li>
</ul>
<h1 id="references" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Heider:interpersonal58">
<p>Heider, Fritz. 1958. <em>The Psychology of Interpersonal Relations</em>. John Wiley.</p>
</div>
<div id="ref-Lawrence:embodiment17">
<p>Lawrence, Neil D. 2017. “Living Together: Mind and Machine Intelligence.” arXiv. <a href="https://arxiv.org/abs/1705.07996" class="uri">https://arxiv.org/abs/1705.07996</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Apple has fixed this issue so that Siri no longer does this.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</section>


