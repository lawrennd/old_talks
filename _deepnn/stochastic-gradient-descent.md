---
layout: lecture
title: Optimization and Stochastic Gradient Descent
week: 2
session: 2
author:
- given: Ferenc
  family: HuszÃ¡r
  institution: University of Cambridge
  url: https://www.inference.vc/about/
abstract: >
  This lecture will cover stochastic gradient descent.
talkscam:
hackmdnotes: fhuszar/rJWAWC7gO
hackmdslides: fhuszar/Hy69Wvrg_
youtube: GDyD8KwSfvk
reveal: false
time: "14:00"
start: "14:00"
end: "15:00"
date: 2021-02-02
---


You can find the [slides here](https://hackmd.io/@fhuszar/Hy69Wvrg_) and the [notes here](https://hackmd.io/@fhuszar/rJWAWC7gO).

<!--No Free Lunch for Optimization: <https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf> <https://link.springer.com/chapter/10.1007%2F978-3-030-12767-1_5>
Survey of Optimization methods for DeepNNs: <https://arxiv.org/abs/2007.01547>


Related publications and links will appear here.

* SGD (why it works, high variance estimator etc)
* Adam
* RMS PropMixed mode-->

