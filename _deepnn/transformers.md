---
layout: lecture
title: Transformers
week: 5
session: 1
date: 2022-02-17
start: "14:00"
end: "15:00"
author:
- given: Nic
  family: Lane
  institution: 
  url: http://niclane.org/
abstract: >
  This lecture will introduce transformers.
googleslides: https://docs.google.com/presentation/d/1VAkvBT2kDKb3ekQgDSA2vD4MUUHAzlnDTAiB0o89ApY/edit?usp=sharing
talkscam:
reveal: true
youtube: Ab1cbUdL50A
oldyoutube:
  code: wXgWXDpVrM4
  year: 2021
talktheme: white
ipynb: false
reveal: false
time: "14:00"
start: "14:00"
end: "15:00"
---

\subsection{Slides}

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vT5yXJwQSBU3DoB9zL6lUlpOsdmy8-3Cw9nHv3Q7PiJYHgTDTxNlIUYQF7bMAlQ9Sgpd_jP8wqThc3L/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

\subsection{Material}


You can find the [Slides here](https://docs.google.com/presentation/d/1VAkvBT2kDKb3ekQgDSA2vD4MUUHAzlnDTAiB0o89ApY/edit?usp=sharing)

And here are three Colab notebooks from Google that you might find interesting. 

* [Vision Transformer Tutorial](https://colab.research.google.com/github/hirotomusiker/schwert_colab_data_storage/blob/master/notebook/Vision_Transformer_Tutorial.ipynb)
* [Transformer model for language understanding](https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb#scrollTo=s_qNSzzyaCbD)
* [Transformers and Multihead Attention](https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/course_UvA-DL/05-transformers-and-MH-attention.ipynb#scrollTo=70711ff5)


