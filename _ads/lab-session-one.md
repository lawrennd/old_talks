---
week: 6
session: 1
title: "Lab Session One"
abstract:  >
  In this lecture we introduce a data science process: access, assess and address. The process Given the landscape we've outlined, in this lecture we will look at the challenges of deploying data science solutions in practice. We categorize them into three groups.
layout: lecture
venue: FW11, William Gates Building
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: University of Cambridge
  twitter: lawrennd
  url: http://inverseprobability.com
time: "15:00"
date: 2021-11-09
transition: None
reveal: false
ipynb: true
---

\include{_data-science/includes/gartner-hype-cycle-ai-bd-dm-dl-ml.md}
\include{_data-science/includes/big-data-paradox.md}
\include{_data-science/includes/big-model-paradox.md}
\installcode{pods}

\include{_mlai/includes/welcome.md}
\include{_mlai/includes/assumed-knowledge.md}
\include{_mlai/includes/environment-python-jupyter.md}

\writeassignment{What is Jupyter and why was it invented? Give some
examples of functionality it gives over standard python. What is the jupyter
project? Name two languages involved in the Jupyter project other than python.}{10}

\include{_datasets/includes/nigeria-nmis-data.md}
\include{_ml/includes/probability-intro.md}

\newslide{}

\figure{\includeyoutube{GX8VLYUYScM}{600}{450}}{MLAI Lecture 2 from 2012.}{mlai-lecture-2012}

\include{_psychology/includes/selective-attention-bias.md}
\include{_data-science/includes/data-inattention-bias.md}

\newslide{Reading}

-   See probability review at end of slides for reminders.

\addreading{@Rogers:book11}{Section 2.2 (pg 41–53)}
\addreading{@Rogers:book11}{Section 2.4 (pg 55–58)}
\addreading{@Rogers:book11}{Section 2.5.1 (pg 58–60)}
\addreading{@Rogers:book11}{Section 2.5.3 (pg 61–62)}

- For other material in Bishop read:

\addreading{@Bishop:book06}{Probability densities: Section 1.2.1 (Pages 17–19)}
\addreading{@Bishop:book06}{Expectations and Covariances: Section 1.2.2 (Pages 19–20)}

\addreading{@Bishop:book06}{The Gaussian density: Section 1.2.4 (Pages 24–28) (don’t worry about material on bias)}
\addreading{@Bishop:book06}{For material on information theory and KL divergence try Section 1.6 & 1.6.1 (pg 48 onwards)}

- If you are unfamiliar with probabilities you should complete the
    following exercises:

\addexercise{@Bishop:book06}{Exercise 1.7}
\addexercise{@Bishop:book06}{Exercise 1.8}
\addexercise{@Bishop:book06}{Exercise 1.9}


\thanks

\reading

\exercises


\references
