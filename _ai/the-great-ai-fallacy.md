---
layout: talk
title: "The Great AI Fallacy"
abstract: >
  Artificial intelligence is a form of intellectual automation. The promise of artificial intelligence is that it will be the first generation of automation that adapts to humans, rather than humans having to adapt to it. I see no evidence that this is true, but this fallacy is having very real effects on the way we think about creating and deploying artificial intelligence solutions.
  
  In this talk I introduce the Great AI Fallacy and discuss strategies for deployment that pre-emptively deal with the problems it will trigger.
reveal: True
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: University of Cambridge
  twitter: lawrennd
  url: http://inverseprobability.com
date: 2020-04-21
venue: The Cambridge Network
transition: None
---

\include{talk-macros.tex}

\include{_ai/includes/the-great-ai-fallacy.md}
\include{_ai/includes/the-promise-of-ai.md}
\include{_ai/includes/centrifugal-governor.md}
\include{_ai/includes/embodiment-factors-tedx.md}
\include{_ai/includes/baby-shoes.md}
\include{_ai/includes/conversation-computer.md}
* \addblog{Natural and Artifical Intelligence}{2018/02/06/natural-and-artificial-intelligence}
\include{_ml/includes/code-data-separation-transgression.md}
\include{_ai/includes/intellectual-debt.md}
\define{mlDataChallenge}
\include{_ml/includes/the-3ds-of-ml-systems-design.md}

\subsection{Conclusion}

\notes{The Great AI Fallacy is an implicit promise behind AI systems that they will be the first generation of automation to adapt to the human, rather than the human having to adapt to the machine. In reality, we have no evidence that we've achieved this. 

What we see in practice is that the humans will have to adadpt even more to the machine.}

\slides{* AI will not (yet) adapt to the human.
* Humans must adapt to the machine.
* Good design more important than ever.}


\thanks

\references
