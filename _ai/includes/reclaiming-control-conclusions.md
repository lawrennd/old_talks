\ifndef{reclaimingControlConclusions}
\define{reclaimingControlConclusions}

\editme

\subsection{Conclusions}

\slides{* Humans view intelligence as embodied, but AI is not embodied.
* Critical decisions are dependent on human nuance to reconcile the tension between $p$-Fairness and $n$-Fairness.
* This implies that AI should only ever be seen as a tool of humans.
* Much of current technology makes us a tool of the AI.}

\newslide{Conclusions Contd}

\slides{* Three interventions to address this.
  * Empower the humans to better use the tools.
  * Develop better standards for creating AI systems.
  * Develop data intermediaries to allow citizens to have a voice in how their data is used.}
  
\notes{Our particular constraints, in terms of our bandwidth, means that our intelligence is embodied, but AI is not embodied. We tend to anthropomorphasise other intelligences, and we view other humans as simple, despite their complexities and nuanced intelligence.}

\notes{When it comes to consequential decision making, there are two properties we might like it to have. The $p$ properties consider clarity of decision making procedure, and the $n$ properties consider the nuance of the decision making. These properties are in tension.}

\notes{The marvelous resolution of these tensions that humans have evolved relies on the fact that despite the fact that other humans are complex and nuanced, we relate to one another. This means that we can have simple decision making processes that exhibit nuance through human intervention. The machine can't emulate this as they operate in ways that are very different to humans and difficult for us to relate to.}

\notes{Where interactions with AI are ocurring, we tend to be the tool of the AI, because it can exploit us through our data. We need to correct this, and change the situation where we are in control of the AI.}

\notes{We've briefly reviewed three interventions at the University of Cambridge which focus on 

1. The Accelerate Programme: Working with domain experts to improve the design and use of AI systems.
2. AutoAI: Developing better technologies for the control, explanation and maintenance of AI systems.
3. Data Trusts Initiative: piloting data intermediaries that give users back control of their data.}

\notes{Finally, we introduced the AI@Cam intiative to encourage interdisciplinary debate about these issues building on the University's strengths across all these areas.}
  
\endif
